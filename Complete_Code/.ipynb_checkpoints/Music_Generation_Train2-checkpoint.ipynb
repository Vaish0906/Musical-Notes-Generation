{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, TimeDistributed, Dense, Activation, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"../Data2/\"\n",
    "data_file = \"Data_Tunes.txt\"\n",
    "charIndex_json = \"char_to_index.json\"\n",
    "model_weights_directory = '../Data2/Model_Weights/'\n",
    "BATCH_SIZE = 16\n",
    "SEQ_LENGTH = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_batches(all_chars, unique_chars):\n",
    "    length = all_chars.shape[0]\n",
    "    batch_chars = int(length / BATCH_SIZE) #155222/16 = 9701\n",
    "    \n",
    "    for start in range(0, batch_chars - SEQ_LENGTH, 64):  #(0, 9637, 64)  #it denotes number of batches. It runs everytime when\n",
    "        #new batch is created. We have a total of 151 batches.\n",
    "        X = np.zeros((BATCH_SIZE, SEQ_LENGTH))    #(16, 64)\n",
    "        Y = np.zeros((BATCH_SIZE, SEQ_LENGTH, unique_chars))   #(16, 64, 87)\n",
    "        for batch_index in range(0, 16):  #it denotes each row in a batch.  \n",
    "            for i in range(0, 64):  #it denotes each column in a batch. Each column represents each character means \n",
    "                #each time-step character in a sequence.\n",
    "                X[batch_index, i] = all_chars[batch_index * batch_chars + start + i]\n",
    "                Y[batch_index, i, all_chars[batch_index * batch_chars + start + i + 1]] = 1 #here we have added '1' because the\n",
    "                #correct label will be the next character in the sequence. So, the next character will be denoted by\n",
    "                #all_chars[batch_index * batch_chars + start + i] + 1. \n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def built_model(batch_size, seq_length, unique_chars):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(input_dim = unique_chars, output_dim = 512, batch_input_shape = (batch_size, seq_length), name = \"embd_1\")) \n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True, name = \"lstm_first\"))\n",
    "    model.add(Dropout(0.2, name = \"drp_1\"))\n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(TimeDistributed(Dense(unique_chars)))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    model.load_weights(\"../Data/Model_Weights/Weights_80.h5\", by_name = True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(data, epochs = 90):\n",
    "    #mapping character to index\n",
    "    char_to_index = {ch: i for (i, ch) in enumerate(sorted(list(set(data))))}\n",
    "    print(\"Number of unique characters in our whole tunes database = {}\".format(len(char_to_index))) #87\n",
    "    \n",
    "    with open(os.path.join(data_directory, charIndex_json), mode = \"w\") as f:\n",
    "        json.dump(char_to_index, f)\n",
    "        \n",
    "    index_to_char = {i: ch for (ch, i) in char_to_index.items()}\n",
    "    unique_chars = len(char_to_index)\n",
    "    \n",
    "    model = built_model(BATCH_SIZE, SEQ_LENGTH, unique_chars)\n",
    "    model.summary()\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    all_characters = np.asarray([char_to_index[c] for c in data], dtype = np.int32)\n",
    "    print(\"Total number of characters = \"+str(all_characters.shape[0])) #155222\n",
    "    \n",
    "    epoch_number, loss, accuracy = [], [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch+1, epochs))\n",
    "        final_epoch_loss, final_epoch_accuracy = 0, 0\n",
    "        epoch_number.append(epoch+1)\n",
    "        \n",
    "        for i, (x, y) in enumerate(read_batches(all_characters, unique_chars)):\n",
    "            final_epoch_loss, final_epoch_accuracy = model.train_on_batch(x, y) #check documentation of train_on_batch here: https://keras.io/models/sequential/\n",
    "            print(\"Batch: {}, Loss: {}, Accuracy: {}\".format(i+1, final_epoch_loss, final_epoch_accuracy))\n",
    "            #here, above we are reading the batches one-by-one and train our model on each batch one-by-one.\n",
    "        loss.append(final_epoch_loss)\n",
    "        accuracy.append(final_epoch_accuracy)\n",
    "        \n",
    "        #saving weights after every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            if not os.path.exists(model_weights_directory):\n",
    "                os.makedirs(model_weights_directory)\n",
    "            model.save_weights(os.path.join(model_weights_directory, \"Weights_{}.h5\".format(epoch+1)))\n",
    "            print('Saved Weights at epoch {} to file Weights_{}.h5'.format(epoch+1, epoch+1))\n",
    "    \n",
    "    #creating dataframe and record all the losses and accuracies at each epoch\n",
    "    log_frame = pd.DataFrame(columns = [\"Epoch\", \"Loss\", \"Accuracy\"])\n",
    "    log_frame[\"Epoch\"] = epoch_number\n",
    "    log_frame[\"Loss\"] = loss\n",
    "    log_frame[\"Accuracy\"] = accuracy\n",
    "    log_frame.to_csv(\"../Data2/log.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters in our whole tunes database = 87\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embd_1 (Embedding)           (16, 64, 512)             44544     \n",
      "_________________________________________________________________\n",
      "lstm_first (LSTM)            (16, 64, 256)             787456    \n",
      "_________________________________________________________________\n",
      "drp_1 (Dropout)              (16, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (16, 64, 256)             525312    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (16, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (16, 64, 256)             525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (16, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (16, 64, 87)              22359     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (16, 64, 87)              0         \n",
      "=================================================================\n",
      "Total params: 1,904,983\n",
      "Trainable params: 1,904,983\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Total number of characters = 155222\n",
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1, Loss: 4.466177940368652, Accuracy: 0.009765625\n",
      "Batch: 2, Loss: 4.439176559448242, Accuracy: 0.1728515625\n",
      "Batch: 3, Loss: 4.378070831298828, Accuracy: 0.134765625\n",
      "Batch: 4, Loss: 4.217364311218262, Accuracy: 0.1025390625\n",
      "Batch: 5, Loss: 3.7815442085266113, Accuracy: 0.1435546875\n",
      "Batch: 6, Loss: 3.4739668369293213, Accuracy: 0.1640625\n",
      "Batch: 7, Loss: 3.450580358505249, Accuracy: 0.09765625\n",
      "Batch: 8, Loss: 3.5620851516723633, Accuracy: 0.1005859375\n",
      "Batch: 9, Loss: 3.6593432426452637, Accuracy: 0.1162109375\n",
      "Batch: 10, Loss: 3.4926178455352783, Accuracy: 0.1494140625\n",
      "Batch: 11, Loss: 3.207913875579834, Accuracy: 0.1845703125\n",
      "Batch: 12, Loss: 3.435727119445801, Accuracy: 0.1533203125\n",
      "Batch: 13, Loss: 3.66355562210083, Accuracy: 0.1328125\n",
      "Batch: 14, Loss: 3.4276208877563477, Accuracy: 0.1455078125\n",
      "Batch: 15, Loss: 3.6425580978393555, Accuracy: 0.1162109375\n",
      "Batch: 16, Loss: 3.402960777282715, Accuracy: 0.1416015625\n",
      "Batch: 17, Loss: 3.3403820991516113, Accuracy: 0.14453125\n",
      "Batch: 18, Loss: 3.3143563270568848, Accuracy: 0.1611328125\n",
      "Batch: 19, Loss: 3.513514995574951, Accuracy: 0.138671875\n",
      "Batch: 20, Loss: 3.824481964111328, Accuracy: 0.1171875\n",
      "Batch: 21, Loss: 3.641758441925049, Accuracy: 0.12890625\n",
      "Batch: 22, Loss: 3.289855718612671, Accuracy: 0.181640625\n",
      "Batch: 23, Loss: 3.318708896636963, Accuracy: 0.1689453125\n",
      "Batch: 24, Loss: 3.487839937210083, Accuracy: 0.142578125\n",
      "Batch: 25, Loss: 3.385094165802002, Accuracy: 0.1494140625\n",
      "Batch: 26, Loss: 3.369635820388794, Accuracy: 0.1513671875\n",
      "Batch: 27, Loss: 3.3063411712646484, Accuracy: 0.1494140625\n",
      "Batch: 28, Loss: 3.1954712867736816, Accuracy: 0.166015625\n",
      "Batch: 29, Loss: 3.3264341354370117, Accuracy: 0.150390625\n",
      "Batch: 30, Loss: 3.5582730770111084, Accuracy: 0.1181640625\n",
      "Batch: 31, Loss: 3.492384910583496, Accuracy: 0.119140625\n",
      "Batch: 32, Loss: 3.297429323196411, Accuracy: 0.13671875\n",
      "Batch: 33, Loss: 3.310378074645996, Accuracy: 0.1591796875\n",
      "Batch: 34, Loss: 3.275408983230591, Accuracy: 0.1640625\n",
      "Batch: 35, Loss: 3.3329663276672363, Accuracy: 0.138671875\n",
      "Batch: 36, Loss: 3.414905309677124, Accuracy: 0.1220703125\n",
      "Batch: 37, Loss: 3.32767915725708, Accuracy: 0.123046875\n",
      "Batch: 38, Loss: 3.268847942352295, Accuracy: 0.154296875\n",
      "Batch: 39, Loss: 3.299614906311035, Accuracy: 0.1435546875\n",
      "Batch: 40, Loss: 3.350612163543701, Accuracy: 0.146484375\n",
      "Batch: 41, Loss: 3.344959259033203, Accuracy: 0.1455078125\n",
      "Batch: 42, Loss: 3.1772193908691406, Accuracy: 0.1748046875\n",
      "Batch: 43, Loss: 3.1169257164001465, Accuracy: 0.189453125\n",
      "Batch: 44, Loss: 3.1092169284820557, Accuracy: 0.177734375\n",
      "Batch: 45, Loss: 3.1216535568237305, Accuracy: 0.171875\n",
      "Batch: 46, Loss: 3.3085131645202637, Accuracy: 0.1455078125\n",
      "Batch: 47, Loss: 3.369619846343994, Accuracy: 0.1298828125\n",
      "Batch: 48, Loss: 3.255250930786133, Accuracy: 0.15625\n",
      "Batch: 49, Loss: 3.1958389282226562, Accuracy: 0.1435546875\n",
      "Batch: 50, Loss: 3.1621642112731934, Accuracy: 0.158203125\n",
      "Batch: 51, Loss: 3.180920124053955, Accuracy: 0.1455078125\n",
      "Batch: 52, Loss: 3.257875442504883, Accuracy: 0.13671875\n",
      "Batch: 53, Loss: 3.170623779296875, Accuracy: 0.142578125\n",
      "Batch: 54, Loss: 3.1951088905334473, Accuracy: 0.140625\n",
      "Batch: 55, Loss: 3.1432812213897705, Accuracy: 0.1630859375\n",
      "Batch: 56, Loss: 3.2316763401031494, Accuracy: 0.1708984375\n",
      "Batch: 57, Loss: 3.22194766998291, Accuracy: 0.15625\n",
      "Batch: 58, Loss: 3.1821770668029785, Accuracy: 0.1591796875\n",
      "Batch: 59, Loss: 3.203171730041504, Accuracy: 0.1630859375\n",
      "Batch: 60, Loss: 3.179978847503662, Accuracy: 0.15625\n",
      "Batch: 61, Loss: 3.1654982566833496, Accuracy: 0.1650390625\n",
      "Batch: 62, Loss: 3.2396340370178223, Accuracy: 0.16015625\n",
      "Batch: 63, Loss: 3.199246406555176, Accuracy: 0.1455078125\n",
      "Batch: 64, Loss: 3.194753646850586, Accuracy: 0.16015625\n",
      "Batch: 65, Loss: 3.1460509300231934, Accuracy: 0.1572265625\n",
      "Batch: 66, Loss: 3.1274664402008057, Accuracy: 0.158203125\n",
      "Batch: 67, Loss: 3.092728853225708, Accuracy: 0.1796875\n",
      "Batch: 68, Loss: 3.108342170715332, Accuracy: 0.1884765625\n",
      "Batch: 69, Loss: 3.162278652191162, Accuracy: 0.1787109375\n",
      "Batch: 70, Loss: 3.1950831413269043, Accuracy: 0.173828125\n",
      "Batch: 71, Loss: 3.1356403827667236, Accuracy: 0.1787109375\n",
      "Batch: 72, Loss: 3.1889541149139404, Accuracy: 0.169921875\n",
      "Batch: 73, Loss: 3.2239246368408203, Accuracy: 0.1650390625\n",
      "Batch: 74, Loss: 3.1413395404815674, Accuracy: 0.166015625\n",
      "Batch: 75, Loss: 3.055943012237549, Accuracy: 0.1826171875\n",
      "Batch: 76, Loss: 3.091059923171997, Accuracy: 0.177734375\n",
      "Batch: 77, Loss: 3.1364927291870117, Accuracy: 0.177734375\n",
      "Batch: 78, Loss: 3.2312934398651123, Accuracy: 0.162109375\n",
      "Batch: 79, Loss: 3.158885955810547, Accuracy: 0.16796875\n",
      "Batch: 80, Loss: 3.0161654949188232, Accuracy: 0.185546875\n",
      "Batch: 81, Loss: 2.9826831817626953, Accuracy: 0.1884765625\n",
      "Batch: 82, Loss: 3.0528950691223145, Accuracy: 0.189453125\n",
      "Batch: 83, Loss: 3.0611960887908936, Accuracy: 0.173828125\n",
      "Batch: 84, Loss: 3.1007559299468994, Accuracy: 0.1748046875\n",
      "Batch: 85, Loss: 3.1072592735290527, Accuracy: 0.18359375\n",
      "Batch: 86, Loss: 3.0765433311462402, Accuracy: 0.1630859375\n",
      "Batch: 87, Loss: 3.040761947631836, Accuracy: 0.185546875\n",
      "Batch: 88, Loss: 3.0700011253356934, Accuracy: 0.1865234375\n",
      "Batch: 89, Loss: 3.1028690338134766, Accuracy: 0.169921875\n",
      "Batch: 90, Loss: 3.0920042991638184, Accuracy: 0.1767578125\n",
      "Batch: 91, Loss: 2.9878251552581787, Accuracy: 0.1728515625\n",
      "Batch: 92, Loss: 3.0615060329437256, Accuracy: 0.1669921875\n",
      "Batch: 93, Loss: 2.9990196228027344, Accuracy: 0.16796875\n",
      "Batch: 94, Loss: 2.960299015045166, Accuracy: 0.19921875\n",
      "Batch: 95, Loss: 2.95290207862854, Accuracy: 0.205078125\n",
      "Batch: 96, Loss: 3.0479116439819336, Accuracy: 0.201171875\n",
      "Batch: 97, Loss: 3.004629135131836, Accuracy: 0.189453125\n",
      "Batch: 98, Loss: 2.9951977729797363, Accuracy: 0.1943359375\n",
      "Batch: 99, Loss: 2.9267053604125977, Accuracy: 0.1875\n",
      "Batch: 100, Loss: 2.8926382064819336, Accuracy: 0.2060546875\n",
      "Batch: 101, Loss: 2.889857769012451, Accuracy: 0.2158203125\n",
      "Batch: 102, Loss: 2.9059205055236816, Accuracy: 0.1943359375\n",
      "Batch: 103, Loss: 2.9908676147460938, Accuracy: 0.197265625\n",
      "Batch: 104, Loss: 2.8826992511749268, Accuracy: 0.21484375\n",
      "Batch: 105, Loss: 2.9268951416015625, Accuracy: 0.197265625\n",
      "Batch: 106, Loss: 2.9518914222717285, Accuracy: 0.203125\n",
      "Batch: 107, Loss: 3.02266263961792, Accuracy: 0.1767578125\n",
      "Batch: 108, Loss: 2.9558122158050537, Accuracy: 0.20703125\n",
      "Batch: 109, Loss: 2.9411354064941406, Accuracy: 0.22265625\n",
      "Batch: 110, Loss: 2.7929489612579346, Accuracy: 0.220703125\n",
      "Batch: 111, Loss: 2.8241963386535645, Accuracy: 0.19140625\n",
      "Batch: 112, Loss: 2.9541001319885254, Accuracy: 0.19140625\n",
      "Batch: 113, Loss: 2.9683167934417725, Accuracy: 0.1875\n",
      "Batch: 114, Loss: 2.8823013305664062, Accuracy: 0.19921875\n",
      "Batch: 115, Loss: 2.8932924270629883, Accuracy: 0.1962890625\n",
      "Batch: 116, Loss: 2.9123435020446777, Accuracy: 0.1923828125\n",
      "Batch: 117, Loss: 2.949154853820801, Accuracy: 0.1826171875\n",
      "Batch: 118, Loss: 2.832101583480835, Accuracy: 0.2080078125\n",
      "Batch: 119, Loss: 2.969991445541382, Accuracy: 0.1884765625\n",
      "Batch: 120, Loss: 2.9156699180603027, Accuracy: 0.20703125\n",
      "Batch: 121, Loss: 2.8977363109588623, Accuracy: 0.2099609375\n",
      "Batch: 122, Loss: 2.943037748336792, Accuracy: 0.1943359375\n",
      "Batch: 123, Loss: 2.8578929901123047, Accuracy: 0.1865234375\n",
      "Batch: 124, Loss: 2.8304665088653564, Accuracy: 0.1982421875\n",
      "Batch: 125, Loss: 2.8781580924987793, Accuracy: 0.2109375\n",
      "Batch: 126, Loss: 2.828033924102783, Accuracy: 0.2138671875\n",
      "Batch: 127, Loss: 2.7889819145202637, Accuracy: 0.2060546875\n",
      "Batch: 128, Loss: 2.8728604316711426, Accuracy: 0.197265625\n",
      "Batch: 129, Loss: 2.7778491973876953, Accuracy: 0.2197265625\n",
      "Batch: 130, Loss: 2.8558013439178467, Accuracy: 0.2275390625\n",
      "Batch: 131, Loss: 2.820188283920288, Accuracy: 0.2197265625\n",
      "Batch: 132, Loss: 2.7988038063049316, Accuracy: 0.2275390625\n",
      "Batch: 133, Loss: 2.850196361541748, Accuracy: 0.2138671875\n",
      "Batch: 134, Loss: 2.785080671310425, Accuracy: 0.244140625\n",
      "Batch: 135, Loss: 2.719266653060913, Accuracy: 0.2421875\n",
      "Batch: 136, Loss: 2.718416452407837, Accuracy: 0.263671875\n",
      "Batch: 137, Loss: 2.566984176635742, Accuracy: 0.3046875\n",
      "Batch: 138, Loss: 2.6227400302886963, Accuracy: 0.2802734375\n",
      "Batch: 139, Loss: 2.5451083183288574, Accuracy: 0.2919921875\n",
      "Batch: 140, Loss: 2.640742301940918, Accuracy: 0.283203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 141, Loss: 2.6402533054351807, Accuracy: 0.267578125\n",
      "Batch: 142, Loss: 2.636270523071289, Accuracy: 0.287109375\n",
      "Batch: 143, Loss: 2.6797573566436768, Accuracy: 0.2841796875\n",
      "Batch: 144, Loss: 2.6163315773010254, Accuracy: 0.3037109375\n",
      "Batch: 145, Loss: 2.523433208465576, Accuracy: 0.3115234375\n",
      "Batch: 146, Loss: 2.7288265228271484, Accuracy: 0.263671875\n",
      "Batch: 147, Loss: 2.704846143722534, Accuracy: 0.2744140625\n",
      "Batch: 148, Loss: 2.6599764823913574, Accuracy: 0.2861328125\n",
      "Batch: 149, Loss: 2.6748974323272705, Accuracy: 0.2783203125\n",
      "Batch: 150, Loss: 2.57561993598938, Accuracy: 0.28515625\n",
      "Batch: 151, Loss: 2.61995267868042, Accuracy: 0.2744140625\n",
      "Epoch 2/90\n",
      "Batch: 1, Loss: 2.652947425842285, Accuracy: 0.306640625\n",
      "Batch: 2, Loss: 2.4051356315612793, Accuracy: 0.33984375\n",
      "Batch: 3, Loss: 2.523824691772461, Accuracy: 0.287109375\n",
      "Batch: 4, Loss: 2.6079511642456055, Accuracy: 0.26171875\n",
      "Batch: 5, Loss: 2.4521965980529785, Accuracy: 0.3271484375\n",
      "Batch: 6, Loss: 2.4196763038635254, Accuracy: 0.333984375\n",
      "Batch: 7, Loss: 2.4296562671661377, Accuracy: 0.328125\n",
      "Batch: 8, Loss: 2.3851726055145264, Accuracy: 0.34375\n",
      "Batch: 9, Loss: 2.3944644927978516, Accuracy: 0.3291015625\n",
      "Batch: 10, Loss: 2.389516592025757, Accuracy: 0.33984375\n",
      "Batch: 11, Loss: 2.308034896850586, Accuracy: 0.3671875\n",
      "Batch: 12, Loss: 2.42325496673584, Accuracy: 0.333984375\n",
      "Batch: 13, Loss: 2.364910364151001, Accuracy: 0.306640625\n",
      "Batch: 14, Loss: 2.3699913024902344, Accuracy: 0.33984375\n",
      "Batch: 15, Loss: 2.490216016769409, Accuracy: 0.3017578125\n",
      "Batch: 16, Loss: 2.3549294471740723, Accuracy: 0.34375\n",
      "Batch: 17, Loss: 2.271660327911377, Accuracy: 0.349609375\n",
      "Batch: 18, Loss: 2.3369884490966797, Accuracy: 0.35546875\n",
      "Batch: 19, Loss: 2.395899534225464, Accuracy: 0.330078125\n",
      "Batch: 20, Loss: 2.4830245971679688, Accuracy: 0.3173828125\n",
      "Batch: 21, Loss: 2.358611583709717, Accuracy: 0.3359375\n",
      "Batch: 22, Loss: 2.4085211753845215, Accuracy: 0.330078125\n",
      "Batch: 23, Loss: 2.280303955078125, Accuracy: 0.357421875\n",
      "Batch: 24, Loss: 2.429642677307129, Accuracy: 0.3251953125\n",
      "Batch: 25, Loss: 2.291822910308838, Accuracy: 0.34375\n",
      "Batch: 26, Loss: 2.1519930362701416, Accuracy: 0.384765625\n",
      "Batch: 27, Loss: 2.331484794616699, Accuracy: 0.34375\n",
      "Batch: 28, Loss: 2.2383484840393066, Accuracy: 0.3583984375\n",
      "Batch: 29, Loss: 2.296509265899658, Accuracy: 0.345703125\n",
      "Batch: 30, Loss: 2.4806416034698486, Accuracy: 0.318359375\n",
      "Batch: 31, Loss: 2.4286675453186035, Accuracy: 0.3310546875\n",
      "Batch: 32, Loss: 2.2455315589904785, Accuracy: 0.3466796875\n",
      "Batch: 33, Loss: 2.354818820953369, Accuracy: 0.33984375\n",
      "Batch: 34, Loss: 2.369194984436035, Accuracy: 0.341796875\n",
      "Batch: 35, Loss: 2.451427459716797, Accuracy: 0.3134765625\n",
      "Batch: 36, Loss: 2.498229503631592, Accuracy: 0.30859375\n",
      "Batch: 37, Loss: 2.431889533996582, Accuracy: 0.3173828125\n",
      "Batch: 38, Loss: 2.3498153686523438, Accuracy: 0.337890625\n",
      "Batch: 39, Loss: 2.4134106636047363, Accuracy: 0.3427734375\n",
      "Batch: 40, Loss: 2.426096200942993, Accuracy: 0.349609375\n",
      "Batch: 41, Loss: 2.3774054050445557, Accuracy: 0.3515625\n",
      "Batch: 42, Loss: 2.1458160877227783, Accuracy: 0.373046875\n",
      "Batch: 43, Loss: 2.1192150115966797, Accuracy: 0.39453125\n",
      "Batch: 44, Loss: 2.0880632400512695, Accuracy: 0.416015625\n",
      "Batch: 45, Loss: 2.071469783782959, Accuracy: 0.416015625\n",
      "Batch: 46, Loss: 2.3541383743286133, Accuracy: 0.33984375\n",
      "Batch: 47, Loss: 2.4582877159118652, Accuracy: 0.328125\n",
      "Batch: 48, Loss: 2.3079781532287598, Accuracy: 0.3642578125\n",
      "Batch: 49, Loss: 2.293877601623535, Accuracy: 0.359375\n",
      "Batch: 50, Loss: 2.3355202674865723, Accuracy: 0.3466796875\n",
      "Batch: 51, Loss: 2.3490428924560547, Accuracy: 0.3408203125\n",
      "Batch: 52, Loss: 2.3030142784118652, Accuracy: 0.3583984375\n",
      "Batch: 53, Loss: 2.1041839122772217, Accuracy: 0.3671875\n",
      "Batch: 54, Loss: 2.215188503265381, Accuracy: 0.3837890625\n",
      "Batch: 55, Loss: 2.1160497665405273, Accuracy: 0.396484375\n",
      "Batch: 56, Loss: 2.2726056575775146, Accuracy: 0.3564453125\n",
      "Batch: 57, Loss: 2.232994556427002, Accuracy: 0.3818359375\n",
      "Batch: 58, Loss: 2.263373851776123, Accuracy: 0.3837890625\n",
      "Batch: 59, Loss: 2.1643333435058594, Accuracy: 0.380859375\n",
      "Batch: 60, Loss: 2.1548287868499756, Accuracy: 0.396484375\n",
      "Batch: 61, Loss: 2.1745543479919434, Accuracy: 0.3916015625\n",
      "Batch: 62, Loss: 2.292727470397949, Accuracy: 0.3779296875\n",
      "Batch: 63, Loss: 2.2114453315734863, Accuracy: 0.3828125\n",
      "Batch: 64, Loss: 2.2089240550994873, Accuracy: 0.392578125\n",
      "Batch: 65, Loss: 2.232079029083252, Accuracy: 0.37109375\n",
      "Batch: 66, Loss: 2.1122827529907227, Accuracy: 0.4091796875\n",
      "Batch: 67, Loss: 2.106717586517334, Accuracy: 0.4169921875\n",
      "Batch: 68, Loss: 2.244412422180176, Accuracy: 0.3828125\n",
      "Batch: 69, Loss: 2.21441650390625, Accuracy: 0.3984375\n",
      "Batch: 70, Loss: 2.311187267303467, Accuracy: 0.3857421875\n",
      "Batch: 71, Loss: 2.1285901069641113, Accuracy: 0.40234375\n",
      "Batch: 72, Loss: 2.119959831237793, Accuracy: 0.4228515625\n",
      "Batch: 73, Loss: 2.269805908203125, Accuracy: 0.37890625\n",
      "Batch: 74, Loss: 2.1763916015625, Accuracy: 0.4091796875\n",
      "Batch: 75, Loss: 2.054556131362915, Accuracy: 0.42578125\n",
      "Batch: 76, Loss: 2.102581262588501, Accuracy: 0.39453125\n",
      "Batch: 77, Loss: 2.144749402999878, Accuracy: 0.3935546875\n",
      "Batch: 78, Loss: 2.216043472290039, Accuracy: 0.3935546875\n",
      "Batch: 79, Loss: 2.091785430908203, Accuracy: 0.435546875\n",
      "Batch: 80, Loss: 1.9472953081130981, Accuracy: 0.4482421875\n",
      "Batch: 81, Loss: 2.00400447845459, Accuracy: 0.43359375\n",
      "Batch: 82, Loss: 2.0134401321411133, Accuracy: 0.4072265625\n",
      "Batch: 83, Loss: 2.0051910877227783, Accuracy: 0.427734375\n",
      "Batch: 84, Loss: 2.0796873569488525, Accuracy: 0.4228515625\n",
      "Batch: 85, Loss: 2.01897931098938, Accuracy: 0.4697265625\n",
      "Batch: 86, Loss: 2.1339669227600098, Accuracy: 0.416015625\n",
      "Batch: 87, Loss: 2.086674213409424, Accuracy: 0.4326171875\n",
      "Batch: 88, Loss: 2.127716302871704, Accuracy: 0.4189453125\n",
      "Batch: 89, Loss: 2.1672749519348145, Accuracy: 0.408203125\n",
      "Batch: 90, Loss: 2.1024551391601562, Accuracy: 0.4111328125\n",
      "Batch: 91, Loss: 2.0580978393554688, Accuracy: 0.4130859375\n",
      "Batch: 92, Loss: 2.0979530811309814, Accuracy: 0.421875\n",
      "Batch: 93, Loss: 2.0555784702301025, Accuracy: 0.419921875\n",
      "Batch: 94, Loss: 2.003774881362915, Accuracy: 0.4375\n",
      "Batch: 95, Loss: 1.9731481075286865, Accuracy: 0.4453125\n",
      "Batch: 96, Loss: 2.096513509750366, Accuracy: 0.4296875\n",
      "Batch: 97, Loss: 2.0566530227661133, Accuracy: 0.412109375\n",
      "Batch: 98, Loss: 1.9710617065429688, Accuracy: 0.451171875\n",
      "Batch: 99, Loss: 1.9130771160125732, Accuracy: 0.4482421875\n",
      "Batch: 100, Loss: 1.9077019691467285, Accuracy: 0.462890625\n",
      "Batch: 101, Loss: 1.9872283935546875, Accuracy: 0.431640625\n",
      "Batch: 102, Loss: 1.9203078746795654, Accuracy: 0.443359375\n",
      "Batch: 103, Loss: 2.1190104484558105, Accuracy: 0.4140625\n",
      "Batch: 104, Loss: 1.8885351419448853, Accuracy: 0.4560546875\n",
      "Batch: 105, Loss: 2.018871784210205, Accuracy: 0.421875\n",
      "Batch: 106, Loss: 2.038243055343628, Accuracy: 0.427734375\n",
      "Batch: 107, Loss: 2.1693432331085205, Accuracy: 0.3974609375\n",
      "Batch: 108, Loss: 2.1544156074523926, Accuracy: 0.4013671875\n",
      "Batch: 109, Loss: 2.109553575515747, Accuracy: 0.41796875\n",
      "Batch: 110, Loss: 1.843178629875183, Accuracy: 0.4775390625\n",
      "Batch: 111, Loss: 1.9113048315048218, Accuracy: 0.4541015625\n",
      "Batch: 112, Loss: 2.050950288772583, Accuracy: 0.4384765625\n",
      "Batch: 113, Loss: 2.1051888465881348, Accuracy: 0.4228515625\n",
      "Batch: 114, Loss: 2.0542054176330566, Accuracy: 0.4267578125\n",
      "Batch: 115, Loss: 2.143799304962158, Accuracy: 0.4306640625\n",
      "Batch: 116, Loss: 2.148970603942871, Accuracy: 0.419921875\n",
      "Batch: 117, Loss: 2.087367534637451, Accuracy: 0.419921875\n",
      "Batch: 118, Loss: 1.9771606922149658, Accuracy: 0.447265625\n",
      "Batch: 119, Loss: 2.0688629150390625, Accuracy: 0.4404296875\n",
      "Batch: 120, Loss: 2.0480332374572754, Accuracy: 0.4365234375\n",
      "Batch: 121, Loss: 2.0987708568573, Accuracy: 0.4287109375\n",
      "Batch: 122, Loss: 2.059873342514038, Accuracy: 0.4287109375\n",
      "Batch: 123, Loss: 2.0660598278045654, Accuracy: 0.4462890625\n",
      "Batch: 124, Loss: 2.0782527923583984, Accuracy: 0.4482421875\n",
      "Batch: 125, Loss: 2.0412683486938477, Accuracy: 0.435546875\n",
      "Batch: 126, Loss: 2.0305304527282715, Accuracy: 0.404296875\n",
      "Batch: 127, Loss: 1.9891347885131836, Accuracy: 0.4580078125\n",
      "Batch: 128, Loss: 2.183990001678467, Accuracy: 0.396484375\n",
      "Batch: 129, Loss: 2.016836166381836, Accuracy: 0.4375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 130, Loss: 2.211928129196167, Accuracy: 0.3984375\n",
      "Batch: 131, Loss: 2.035482406616211, Accuracy: 0.44921875\n",
      "Batch: 132, Loss: 2.101491689682007, Accuracy: 0.421875\n",
      "Batch: 133, Loss: 2.0340890884399414, Accuracy: 0.455078125\n",
      "Batch: 134, Loss: 2.0276424884796143, Accuracy: 0.431640625\n",
      "Batch: 135, Loss: 1.9416983127593994, Accuracy: 0.466796875\n",
      "Batch: 136, Loss: 1.9664585590362549, Accuracy: 0.451171875\n",
      "Batch: 137, Loss: 1.796966552734375, Accuracy: 0.4736328125\n",
      "Batch: 138, Loss: 1.7561113834381104, Accuracy: 0.4833984375\n",
      "Batch: 139, Loss: 1.8145291805267334, Accuracy: 0.4599609375\n",
      "Batch: 140, Loss: 1.9569038152694702, Accuracy: 0.4501953125\n",
      "Batch: 141, Loss: 1.9599132537841797, Accuracy: 0.4541015625\n",
      "Batch: 142, Loss: 1.9849573373794556, Accuracy: 0.443359375\n",
      "Batch: 143, Loss: 2.078253984451294, Accuracy: 0.431640625\n",
      "Batch: 144, Loss: 1.9585435390472412, Accuracy: 0.4501953125\n",
      "Batch: 145, Loss: 1.8804694414138794, Accuracy: 0.462890625\n",
      "Batch: 146, Loss: 2.090473175048828, Accuracy: 0.421875\n",
      "Batch: 147, Loss: 1.9983075857162476, Accuracy: 0.435546875\n",
      "Batch: 148, Loss: 2.0791049003601074, Accuracy: 0.3955078125\n",
      "Batch: 149, Loss: 2.0710978507995605, Accuracy: 0.4208984375\n",
      "Batch: 150, Loss: 1.9233880043029785, Accuracy: 0.439453125\n",
      "Batch: 151, Loss: 1.9527699947357178, Accuracy: 0.4658203125\n",
      "Epoch 3/90\n",
      "Batch: 1, Loss: 2.158318281173706, Accuracy: 0.4033203125\n",
      "Batch: 2, Loss: 1.8625974655151367, Accuracy: 0.443359375\n",
      "Batch: 3, Loss: 1.9449388980865479, Accuracy: 0.4365234375\n",
      "Batch: 4, Loss: 1.8941359519958496, Accuracy: 0.4677734375\n",
      "Batch: 5, Loss: 1.8399066925048828, Accuracy: 0.47265625\n",
      "Batch: 6, Loss: 1.8867394924163818, Accuracy: 0.4443359375\n",
      "Batch: 7, Loss: 1.8905973434448242, Accuracy: 0.4423828125\n",
      "Batch: 8, Loss: 1.8517552614212036, Accuracy: 0.44921875\n",
      "Batch: 9, Loss: 1.8052884340286255, Accuracy: 0.46484375\n",
      "Batch: 10, Loss: 1.8198531866073608, Accuracy: 0.4619140625\n",
      "Batch: 11, Loss: 1.8550677299499512, Accuracy: 0.4462890625\n",
      "Batch: 12, Loss: 2.026366710662842, Accuracy: 0.4140625\n",
      "Batch: 13, Loss: 1.900098443031311, Accuracy: 0.4384765625\n",
      "Batch: 14, Loss: 1.9128730297088623, Accuracy: 0.4521484375\n",
      "Batch: 15, Loss: 1.8936184644699097, Accuracy: 0.470703125\n",
      "Batch: 16, Loss: 1.8148412704467773, Accuracy: 0.4619140625\n",
      "Batch: 17, Loss: 1.904047966003418, Accuracy: 0.43359375\n",
      "Batch: 18, Loss: 1.9293558597564697, Accuracy: 0.4326171875\n",
      "Batch: 19, Loss: 2.028866767883301, Accuracy: 0.400390625\n",
      "Batch: 20, Loss: 1.9651094675064087, Accuracy: 0.435546875\n",
      "Batch: 21, Loss: 1.8248951435089111, Accuracy: 0.462890625\n",
      "Batch: 22, Loss: 1.952934741973877, Accuracy: 0.4365234375\n",
      "Batch: 23, Loss: 1.8459372520446777, Accuracy: 0.4404296875\n",
      "Batch: 24, Loss: 1.9505224227905273, Accuracy: 0.404296875\n",
      "Batch: 25, Loss: 1.8286817073822021, Accuracy: 0.46484375\n",
      "Batch: 26, Loss: 1.7319154739379883, Accuracy: 0.4697265625\n",
      "Batch: 27, Loss: 1.9031245708465576, Accuracy: 0.431640625\n",
      "Batch: 28, Loss: 1.8352441787719727, Accuracy: 0.451171875\n",
      "Batch: 29, Loss: 1.9166179895401, Accuracy: 0.4375\n",
      "Batch: 30, Loss: 1.9522513151168823, Accuracy: 0.451171875\n",
      "Batch: 31, Loss: 1.945528268814087, Accuracy: 0.4609375\n",
      "Batch: 32, Loss: 1.7893528938293457, Accuracy: 0.474609375\n",
      "Batch: 33, Loss: 1.926149606704712, Accuracy: 0.453125\n",
      "Batch: 34, Loss: 2.0230872631073, Accuracy: 0.4267578125\n",
      "Batch: 35, Loss: 1.9516611099243164, Accuracy: 0.4248046875\n",
      "Batch: 36, Loss: 1.9551312923431396, Accuracy: 0.462890625\n",
      "Batch: 37, Loss: 1.9553834199905396, Accuracy: 0.4453125\n",
      "Batch: 38, Loss: 1.892526626586914, Accuracy: 0.4580078125\n",
      "Batch: 39, Loss: 1.9156370162963867, Accuracy: 0.458984375\n",
      "Batch: 40, Loss: 1.9712767601013184, Accuracy: 0.47265625\n",
      "Batch: 41, Loss: 1.998765468597412, Accuracy: 0.4736328125\n",
      "Batch: 42, Loss: 1.6981184482574463, Accuracy: 0.5029296875\n",
      "Batch: 43, Loss: 1.781386137008667, Accuracy: 0.47265625\n",
      "Batch: 44, Loss: 1.794848918914795, Accuracy: 0.4755859375\n",
      "Batch: 45, Loss: 1.6999709606170654, Accuracy: 0.51171875\n",
      "Batch: 46, Loss: 1.9293454885482788, Accuracy: 0.470703125\n",
      "Batch: 47, Loss: 1.9568872451782227, Accuracy: 0.4560546875\n",
      "Batch: 48, Loss: 1.8571381568908691, Accuracy: 0.4853515625\n",
      "Batch: 49, Loss: 1.9461846351623535, Accuracy: 0.44921875\n",
      "Batch: 50, Loss: 1.9242767095565796, Accuracy: 0.435546875\n",
      "Batch: 51, Loss: 2.0150628089904785, Accuracy: 0.41796875\n",
      "Batch: 52, Loss: 1.9426031112670898, Accuracy: 0.4482421875\n",
      "Batch: 53, Loss: 1.6872568130493164, Accuracy: 0.4912109375\n",
      "Batch: 54, Loss: 1.8799633979797363, Accuracy: 0.4794921875\n",
      "Batch: 55, Loss: 1.7951154708862305, Accuracy: 0.4853515625\n",
      "Batch: 56, Loss: 1.9502700567245483, Accuracy: 0.4541015625\n",
      "Batch: 57, Loss: 1.8220460414886475, Accuracy: 0.4931640625\n",
      "Batch: 58, Loss: 1.9193003177642822, Accuracy: 0.4599609375\n",
      "Batch: 59, Loss: 1.7340461015701294, Accuracy: 0.525390625\n",
      "Batch: 60, Loss: 1.7145737409591675, Accuracy: 0.4921875\n",
      "Batch: 61, Loss: 1.839517593383789, Accuracy: 0.4755859375\n",
      "Batch: 62, Loss: 1.8925684690475464, Accuracy: 0.466796875\n",
      "Batch: 63, Loss: 1.8499407768249512, Accuracy: 0.47265625\n",
      "Batch: 64, Loss: 1.8046445846557617, Accuracy: 0.48828125\n",
      "Batch: 65, Loss: 1.8809621334075928, Accuracy: 0.46875\n",
      "Batch: 66, Loss: 1.781304121017456, Accuracy: 0.48828125\n",
      "Batch: 67, Loss: 1.8256943225860596, Accuracy: 0.4814453125\n",
      "Batch: 68, Loss: 1.9331581592559814, Accuracy: 0.46484375\n",
      "Batch: 69, Loss: 1.8715996742248535, Accuracy: 0.4697265625\n",
      "Batch: 70, Loss: 1.916066288948059, Accuracy: 0.48046875\n",
      "Batch: 71, Loss: 1.807081699371338, Accuracy: 0.4736328125\n",
      "Batch: 72, Loss: 1.757387399673462, Accuracy: 0.4921875\n",
      "Batch: 73, Loss: 1.872765064239502, Accuracy: 0.4912109375\n",
      "Batch: 74, Loss: 1.7841373682022095, Accuracy: 0.494140625\n",
      "Batch: 75, Loss: 1.6932532787322998, Accuracy: 0.498046875\n",
      "Batch: 76, Loss: 1.842149257659912, Accuracy: 0.4541015625\n",
      "Batch: 77, Loss: 1.8583147525787354, Accuracy: 0.4638671875\n",
      "Batch: 78, Loss: 1.8304357528686523, Accuracy: 0.482421875\n",
      "Batch: 79, Loss: 1.7031817436218262, Accuracy: 0.5419921875\n",
      "Batch: 80, Loss: 1.6811890602111816, Accuracy: 0.51171875\n",
      "Batch: 81, Loss: 1.8077960014343262, Accuracy: 0.4599609375\n",
      "Batch: 82, Loss: 1.847757339477539, Accuracy: 0.4501953125\n",
      "Batch: 83, Loss: 1.7176158428192139, Accuracy: 0.505859375\n",
      "Batch: 84, Loss: 1.7802696228027344, Accuracy: 0.5107421875\n",
      "Batch: 85, Loss: 1.6494266986846924, Accuracy: 0.53515625\n",
      "Batch: 86, Loss: 1.9366772174835205, Accuracy: 0.4638671875\n",
      "Batch: 87, Loss: 1.7764060497283936, Accuracy: 0.4931640625\n",
      "Batch: 88, Loss: 1.9020601511001587, Accuracy: 0.482421875\n",
      "Batch: 89, Loss: 1.8732993602752686, Accuracy: 0.474609375\n",
      "Batch: 90, Loss: 1.7631821632385254, Accuracy: 0.486328125\n",
      "Batch: 91, Loss: 1.7671196460723877, Accuracy: 0.494140625\n",
      "Batch: 92, Loss: 1.8180420398712158, Accuracy: 0.4736328125\n",
      "Batch: 93, Loss: 1.7435047626495361, Accuracy: 0.5048828125\n",
      "Batch: 94, Loss: 1.7555949687957764, Accuracy: 0.4873046875\n",
      "Batch: 95, Loss: 1.7651698589324951, Accuracy: 0.4755859375\n",
      "Batch: 96, Loss: 1.8135027885437012, Accuracy: 0.4970703125\n",
      "Batch: 97, Loss: 1.6993358135223389, Accuracy: 0.517578125\n",
      "Batch: 98, Loss: 1.6604654788970947, Accuracy: 0.5341796875\n",
      "Batch: 99, Loss: 1.6223595142364502, Accuracy: 0.51953125\n",
      "Batch: 100, Loss: 1.6899477243423462, Accuracy: 0.5087890625\n",
      "Batch: 101, Loss: 1.7230751514434814, Accuracy: 0.50390625\n",
      "Batch: 102, Loss: 1.634124755859375, Accuracy: 0.5166015625\n",
      "Batch: 103, Loss: 1.8237375020980835, Accuracy: 0.5068359375\n",
      "Batch: 104, Loss: 1.6121411323547363, Accuracy: 0.5185546875\n",
      "Batch: 105, Loss: 1.7310398817062378, Accuracy: 0.494140625\n",
      "Batch: 106, Loss: 1.7838900089263916, Accuracy: 0.494140625\n",
      "Batch: 107, Loss: 1.9139361381530762, Accuracy: 0.4619140625\n",
      "Batch: 108, Loss: 1.9113740921020508, Accuracy: 0.4716796875\n",
      "Batch: 109, Loss: 1.942307710647583, Accuracy: 0.44921875\n",
      "Batch: 110, Loss: 1.6017518043518066, Accuracy: 0.5322265625\n",
      "Batch: 111, Loss: 1.7237739562988281, Accuracy: 0.4873046875\n",
      "Batch: 112, Loss: 1.7878955602645874, Accuracy: 0.5087890625\n",
      "Batch: 113, Loss: 1.8159489631652832, Accuracy: 0.49609375\n",
      "Batch: 114, Loss: 1.8565305471420288, Accuracy: 0.4658203125\n",
      "Batch: 115, Loss: 1.9559571743011475, Accuracy: 0.4619140625\n",
      "Batch: 116, Loss: 1.9325916767120361, Accuracy: 0.4619140625\n",
      "Batch: 117, Loss: 1.8817811012268066, Accuracy: 0.48046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 118, Loss: 1.6865535974502563, Accuracy: 0.5205078125\n",
      "Batch: 119, Loss: 1.7420756816864014, Accuracy: 0.521484375\n",
      "Batch: 120, Loss: 1.8445792198181152, Accuracy: 0.4755859375\n",
      "Batch: 121, Loss: 1.894589900970459, Accuracy: 0.47265625\n",
      "Batch: 122, Loss: 1.7747197151184082, Accuracy: 0.5244140625\n",
      "Batch: 123, Loss: 1.7526123523712158, Accuracy: 0.5234375\n",
      "Batch: 124, Loss: 1.8042179346084595, Accuracy: 0.5078125\n",
      "Batch: 125, Loss: 1.823514699935913, Accuracy: 0.4716796875\n",
      "Batch: 126, Loss: 1.8085358142852783, Accuracy: 0.4619140625\n",
      "Batch: 127, Loss: 1.656585931777954, Accuracy: 0.5283203125\n",
      "Batch: 128, Loss: 1.8998464345932007, Accuracy: 0.46484375\n",
      "Batch: 129, Loss: 1.7791211605072021, Accuracy: 0.4833984375\n",
      "Batch: 130, Loss: 1.9833652973175049, Accuracy: 0.443359375\n",
      "Batch: 131, Loss: 1.785548448562622, Accuracy: 0.5\n",
      "Batch: 132, Loss: 1.870718240737915, Accuracy: 0.4853515625\n",
      "Batch: 133, Loss: 1.772282600402832, Accuracy: 0.4990234375\n",
      "Batch: 134, Loss: 1.7981023788452148, Accuracy: 0.4912109375\n",
      "Batch: 135, Loss: 1.7169408798217773, Accuracy: 0.517578125\n",
      "Batch: 136, Loss: 1.7126619815826416, Accuracy: 0.4990234375\n",
      "Batch: 137, Loss: 1.6077144145965576, Accuracy: 0.517578125\n",
      "Batch: 138, Loss: 1.4919085502624512, Accuracy: 0.546875\n",
      "Batch: 139, Loss: 1.583006739616394, Accuracy: 0.5185546875\n",
      "Batch: 140, Loss: 1.7266106605529785, Accuracy: 0.5\n",
      "Batch: 141, Loss: 1.682795763015747, Accuracy: 0.5224609375\n",
      "Batch: 142, Loss: 1.7668826580047607, Accuracy: 0.4990234375\n",
      "Batch: 143, Loss: 1.796068787574768, Accuracy: 0.4853515625\n",
      "Batch: 144, Loss: 1.7197740077972412, Accuracy: 0.5185546875\n",
      "Batch: 145, Loss: 1.6256014108657837, Accuracy: 0.5205078125\n",
      "Batch: 146, Loss: 1.8412344455718994, Accuracy: 0.458984375\n",
      "Batch: 147, Loss: 1.7252135276794434, Accuracy: 0.4990234375\n",
      "Batch: 148, Loss: 1.8705663681030273, Accuracy: 0.4423828125\n",
      "Batch: 149, Loss: 1.8261287212371826, Accuracy: 0.462890625\n",
      "Batch: 150, Loss: 1.6752264499664307, Accuracy: 0.5029296875\n",
      "Batch: 151, Loss: 1.6495996713638306, Accuracy: 0.53515625\n",
      "Epoch 4/90\n",
      "Batch: 1, Loss: 1.9908232688903809, Accuracy: 0.4423828125\n",
      "Batch: 2, Loss: 1.6640756130218506, Accuracy: 0.4892578125\n",
      "Batch: 3, Loss: 1.6647484302520752, Accuracy: 0.515625\n",
      "Batch: 4, Loss: 1.5561423301696777, Accuracy: 0.5693359375\n",
      "Batch: 5, Loss: 1.5912489891052246, Accuracy: 0.53515625\n",
      "Batch: 6, Loss: 1.7006621360778809, Accuracy: 0.4892578125\n",
      "Batch: 7, Loss: 1.6596553325653076, Accuracy: 0.5029296875\n",
      "Batch: 8, Loss: 1.5941115617752075, Accuracy: 0.5185546875\n",
      "Batch: 9, Loss: 1.515820860862732, Accuracy: 0.5458984375\n",
      "Batch: 10, Loss: 1.6282598972320557, Accuracy: 0.501953125\n",
      "Batch: 11, Loss: 1.7050795555114746, Accuracy: 0.478515625\n",
      "Batch: 12, Loss: 1.8161842823028564, Accuracy: 0.4501953125\n",
      "Batch: 13, Loss: 1.5688862800598145, Accuracy: 0.53125\n",
      "Batch: 14, Loss: 1.695275068283081, Accuracy: 0.5107421875\n",
      "Batch: 15, Loss: 1.6861040592193604, Accuracy: 0.501953125\n",
      "Batch: 16, Loss: 1.627445936203003, Accuracy: 0.521484375\n",
      "Batch: 17, Loss: 1.7424938678741455, Accuracy: 0.4658203125\n",
      "Batch: 18, Loss: 1.7239348888397217, Accuracy: 0.4736328125\n",
      "Batch: 19, Loss: 1.7222390174865723, Accuracy: 0.505859375\n",
      "Batch: 20, Loss: 1.6545069217681885, Accuracy: 0.53125\n",
      "Batch: 21, Loss: 1.5590215921401978, Accuracy: 0.5439453125\n",
      "Batch: 22, Loss: 1.7818244695663452, Accuracy: 0.48046875\n",
      "Batch: 23, Loss: 1.6031289100646973, Accuracy: 0.521484375\n",
      "Batch: 24, Loss: 1.6732573509216309, Accuracy: 0.505859375\n",
      "Batch: 25, Loss: 1.602759838104248, Accuracy: 0.509765625\n",
      "Batch: 26, Loss: 1.5123119354248047, Accuracy: 0.5556640625\n",
      "Batch: 27, Loss: 1.6514184474945068, Accuracy: 0.48828125\n",
      "Batch: 28, Loss: 1.6383178234100342, Accuracy: 0.4931640625\n",
      "Batch: 29, Loss: 1.6838338375091553, Accuracy: 0.4931640625\n",
      "Batch: 30, Loss: 1.6241223812103271, Accuracy: 0.5341796875\n",
      "Batch: 31, Loss: 1.6141366958618164, Accuracy: 0.537109375\n",
      "Batch: 32, Loss: 1.529362678527832, Accuracy: 0.544921875\n",
      "Batch: 33, Loss: 1.7486820220947266, Accuracy: 0.494140625\n",
      "Batch: 34, Loss: 1.8198509216308594, Accuracy: 0.4658203125\n",
      "Batch: 35, Loss: 1.703330159187317, Accuracy: 0.5107421875\n",
      "Batch: 36, Loss: 1.66912043094635, Accuracy: 0.5166015625\n",
      "Batch: 37, Loss: 1.6860004663467407, Accuracy: 0.50390625\n",
      "Batch: 38, Loss: 1.6589992046356201, Accuracy: 0.5126953125\n",
      "Batch: 39, Loss: 1.6919810771942139, Accuracy: 0.4970703125\n",
      "Batch: 40, Loss: 1.7116587162017822, Accuracy: 0.5263671875\n",
      "Batch: 41, Loss: 1.7202575206756592, Accuracy: 0.521484375\n",
      "Batch: 42, Loss: 1.454226016998291, Accuracy: 0.548828125\n",
      "Batch: 43, Loss: 1.5825120210647583, Accuracy: 0.5126953125\n",
      "Batch: 44, Loss: 1.5708762407302856, Accuracy: 0.517578125\n",
      "Batch: 45, Loss: 1.454655408859253, Accuracy: 0.55078125\n",
      "Batch: 46, Loss: 1.68632173538208, Accuracy: 0.5302734375\n",
      "Batch: 47, Loss: 1.6526817083358765, Accuracy: 0.53125\n",
      "Batch: 48, Loss: 1.601157307624817, Accuracy: 0.5322265625\n",
      "Batch: 49, Loss: 1.7474043369293213, Accuracy: 0.4677734375\n",
      "Batch: 50, Loss: 1.6968340873718262, Accuracy: 0.4931640625\n",
      "Batch: 51, Loss: 1.7763394117355347, Accuracy: 0.4658203125\n",
      "Batch: 52, Loss: 1.7410025596618652, Accuracy: 0.490234375\n",
      "Batch: 53, Loss: 1.4512189626693726, Accuracy: 0.541015625\n",
      "Batch: 54, Loss: 1.583860993385315, Accuracy: 0.5458984375\n",
      "Batch: 55, Loss: 1.6066174507141113, Accuracy: 0.5126953125\n",
      "Batch: 56, Loss: 1.7231254577636719, Accuracy: 0.4833984375\n",
      "Batch: 57, Loss: 1.5937379598617554, Accuracy: 0.5400390625\n",
      "Batch: 58, Loss: 1.6863296031951904, Accuracy: 0.509765625\n",
      "Batch: 59, Loss: 1.495126485824585, Accuracy: 0.5927734375\n",
      "Batch: 60, Loss: 1.5041542053222656, Accuracy: 0.5498046875\n",
      "Batch: 61, Loss: 1.6282235383987427, Accuracy: 0.5009765625\n",
      "Batch: 62, Loss: 1.6579339504241943, Accuracy: 0.5263671875\n",
      "Batch: 63, Loss: 1.603848934173584, Accuracy: 0.5224609375\n",
      "Batch: 64, Loss: 1.5731923580169678, Accuracy: 0.52734375\n",
      "Batch: 65, Loss: 1.625107765197754, Accuracy: 0.5205078125\n",
      "Batch: 66, Loss: 1.5203795433044434, Accuracy: 0.5546875\n",
      "Batch: 67, Loss: 1.636134386062622, Accuracy: 0.5126953125\n",
      "Batch: 68, Loss: 1.719388723373413, Accuracy: 0.515625\n",
      "Batch: 69, Loss: 1.6553112268447876, Accuracy: 0.5283203125\n",
      "Batch: 70, Loss: 1.6564750671386719, Accuracy: 0.5302734375\n",
      "Batch: 71, Loss: 1.6332471370697021, Accuracy: 0.5068359375\n",
      "Batch: 72, Loss: 1.57914137840271, Accuracy: 0.537109375\n",
      "Batch: 73, Loss: 1.6452686786651611, Accuracy: 0.5244140625\n",
      "Batch: 74, Loss: 1.5302311182022095, Accuracy: 0.5400390625\n",
      "Batch: 75, Loss: 1.4760105609893799, Accuracy: 0.5537109375\n",
      "Batch: 76, Loss: 1.610548973083496, Accuracy: 0.4912109375\n",
      "Batch: 77, Loss: 1.6221396923065186, Accuracy: 0.49609375\n",
      "Batch: 78, Loss: 1.6091554164886475, Accuracy: 0.541015625\n",
      "Batch: 79, Loss: 1.4417860507965088, Accuracy: 0.609375\n",
      "Batch: 80, Loss: 1.45524001121521, Accuracy: 0.5556640625\n",
      "Batch: 81, Loss: 1.6201841831207275, Accuracy: 0.4853515625\n",
      "Batch: 82, Loss: 1.592187762260437, Accuracy: 0.49609375\n",
      "Batch: 83, Loss: 1.453753113746643, Accuracy: 0.5732421875\n",
      "Batch: 84, Loss: 1.5543756484985352, Accuracy: 0.5625\n",
      "Batch: 85, Loss: 1.4336473941802979, Accuracy: 0.58984375\n",
      "Batch: 86, Loss: 1.7666983604431152, Accuracy: 0.4931640625\n",
      "Batch: 87, Loss: 1.4961514472961426, Accuracy: 0.568359375\n",
      "Batch: 88, Loss: 1.6542353630065918, Accuracy: 0.5166015625\n",
      "Batch: 89, Loss: 1.654547929763794, Accuracy: 0.515625\n",
      "Batch: 90, Loss: 1.5059614181518555, Accuracy: 0.5498046875\n",
      "Batch: 91, Loss: 1.5169947147369385, Accuracy: 0.54296875\n",
      "Batch: 92, Loss: 1.5956661701202393, Accuracy: 0.5126953125\n",
      "Batch: 93, Loss: 1.469853401184082, Accuracy: 0.5625\n",
      "Batch: 94, Loss: 1.52714204788208, Accuracy: 0.529296875\n",
      "Batch: 95, Loss: 1.56709885597229, Accuracy: 0.5078125\n",
      "Batch: 96, Loss: 1.5744149684906006, Accuracy: 0.541015625\n",
      "Batch: 97, Loss: 1.4317796230316162, Accuracy: 0.568359375\n",
      "Batch: 98, Loss: 1.4152114391326904, Accuracy: 0.5908203125\n",
      "Batch: 99, Loss: 1.409101128578186, Accuracy: 0.572265625\n",
      "Batch: 100, Loss: 1.5401484966278076, Accuracy: 0.54296875\n",
      "Batch: 101, Loss: 1.542741298675537, Accuracy: 0.521484375\n",
      "Batch: 102, Loss: 1.429502248764038, Accuracy: 0.5546875\n",
      "Batch: 103, Loss: 1.5738539695739746, Accuracy: 0.5673828125\n",
      "Batch: 104, Loss: 1.428097128868103, Accuracy: 0.556640625\n",
      "Batch: 105, Loss: 1.5615187883377075, Accuracy: 0.52734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 106, Loss: 1.5832279920578003, Accuracy: 0.51171875\n",
      "Batch: 107, Loss: 1.7433273792266846, Accuracy: 0.4912109375\n",
      "Batch: 108, Loss: 1.692933201789856, Accuracy: 0.513671875\n",
      "Batch: 109, Loss: 1.7399611473083496, Accuracy: 0.4814453125\n",
      "Batch: 110, Loss: 1.357405185699463, Accuracy: 0.5791015625\n",
      "Batch: 111, Loss: 1.565030813217163, Accuracy: 0.521484375\n",
      "Batch: 112, Loss: 1.5054984092712402, Accuracy: 0.5615234375\n",
      "Batch: 113, Loss: 1.5402617454528809, Accuracy: 0.556640625\n",
      "Batch: 114, Loss: 1.665706992149353, Accuracy: 0.50390625\n",
      "Batch: 115, Loss: 1.7220489978790283, Accuracy: 0.509765625\n",
      "Batch: 116, Loss: 1.6934767961502075, Accuracy: 0.498046875\n",
      "Batch: 117, Loss: 1.632995843887329, Accuracy: 0.53515625\n",
      "Batch: 118, Loss: 1.4306846857070923, Accuracy: 0.5830078125\n",
      "Batch: 119, Loss: 1.4608755111694336, Accuracy: 0.572265625\n",
      "Batch: 120, Loss: 1.6254637241363525, Accuracy: 0.5126953125\n",
      "Batch: 121, Loss: 1.7021427154541016, Accuracy: 0.5078125\n",
      "Batch: 122, Loss: 1.5086036920547485, Accuracy: 0.560546875\n",
      "Batch: 123, Loss: 1.5258476734161377, Accuracy: 0.5478515625\n",
      "Batch: 124, Loss: 1.5598483085632324, Accuracy: 0.560546875\n",
      "Batch: 125, Loss: 1.6043663024902344, Accuracy: 0.5234375\n",
      "Batch: 126, Loss: 1.5727043151855469, Accuracy: 0.5087890625\n",
      "Batch: 127, Loss: 1.4422175884246826, Accuracy: 0.591796875\n",
      "Batch: 128, Loss: 1.640312910079956, Accuracy: 0.5341796875\n",
      "Batch: 129, Loss: 1.5298067331314087, Accuracy: 0.5283203125\n",
      "Batch: 130, Loss: 1.7604234218597412, Accuracy: 0.4833984375\n",
      "Batch: 131, Loss: 1.5833665132522583, Accuracy: 0.5322265625\n",
      "Batch: 132, Loss: 1.6485211849212646, Accuracy: 0.515625\n",
      "Batch: 133, Loss: 1.5588926076889038, Accuracy: 0.5439453125\n",
      "Batch: 134, Loss: 1.5682353973388672, Accuracy: 0.5126953125\n",
      "Batch: 135, Loss: 1.4941260814666748, Accuracy: 0.5654296875\n",
      "Batch: 136, Loss: 1.5128344297409058, Accuracy: 0.529296875\n",
      "Batch: 137, Loss: 1.4392778873443604, Accuracy: 0.525390625\n",
      "Batch: 138, Loss: 1.3102669715881348, Accuracy: 0.5859375\n",
      "Batch: 139, Loss: 1.3710639476776123, Accuracy: 0.5615234375\n",
      "Batch: 140, Loss: 1.5227677822113037, Accuracy: 0.5224609375\n",
      "Batch: 141, Loss: 1.5107295513153076, Accuracy: 0.5595703125\n",
      "Batch: 142, Loss: 1.5579683780670166, Accuracy: 0.529296875\n",
      "Batch: 143, Loss: 1.5655925273895264, Accuracy: 0.51953125\n",
      "Batch: 144, Loss: 1.4984376430511475, Accuracy: 0.5341796875\n",
      "Batch: 145, Loss: 1.4117246866226196, Accuracy: 0.552734375\n",
      "Batch: 146, Loss: 1.6254189014434814, Accuracy: 0.501953125\n",
      "Batch: 147, Loss: 1.5299932956695557, Accuracy: 0.5419921875\n",
      "Batch: 148, Loss: 1.6851686239242554, Accuracy: 0.482421875\n",
      "Batch: 149, Loss: 1.5990734100341797, Accuracy: 0.5048828125\n",
      "Batch: 150, Loss: 1.4679784774780273, Accuracy: 0.56640625\n",
      "Batch: 151, Loss: 1.4505410194396973, Accuracy: 0.5693359375\n",
      "Epoch 5/90\n",
      "Batch: 1, Loss: 1.8101298809051514, Accuracy: 0.47265625\n",
      "Batch: 2, Loss: 1.4864253997802734, Accuracy: 0.5419921875\n",
      "Batch: 3, Loss: 1.4521652460098267, Accuracy: 0.55078125\n",
      "Batch: 4, Loss: 1.375624656677246, Accuracy: 0.5859375\n",
      "Batch: 5, Loss: 1.4085876941680908, Accuracy: 0.5751953125\n",
      "Batch: 6, Loss: 1.5475800037384033, Accuracy: 0.509765625\n",
      "Batch: 7, Loss: 1.440651535987854, Accuracy: 0.541015625\n",
      "Batch: 8, Loss: 1.4175374507904053, Accuracy: 0.5458984375\n",
      "Batch: 9, Loss: 1.3619440793991089, Accuracy: 0.5791015625\n",
      "Batch: 10, Loss: 1.40510892868042, Accuracy: 0.5478515625\n",
      "Batch: 11, Loss: 1.5794389247894287, Accuracy: 0.50390625\n",
      "Batch: 12, Loss: 1.6377689838409424, Accuracy: 0.50390625\n",
      "Batch: 13, Loss: 1.3169914484024048, Accuracy: 0.599609375\n",
      "Batch: 14, Loss: 1.5554454326629639, Accuracy: 0.5244140625\n",
      "Batch: 15, Loss: 1.4469587802886963, Accuracy: 0.5654296875\n",
      "Batch: 16, Loss: 1.4343342781066895, Accuracy: 0.5595703125\n",
      "Batch: 17, Loss: 1.5445994138717651, Accuracy: 0.51171875\n",
      "Batch: 18, Loss: 1.5405066013336182, Accuracy: 0.5166015625\n",
      "Batch: 19, Loss: 1.5676864385604858, Accuracy: 0.513671875\n",
      "Batch: 20, Loss: 1.4812874794006348, Accuracy: 0.5576171875\n",
      "Batch: 21, Loss: 1.409778118133545, Accuracy: 0.5595703125\n",
      "Batch: 22, Loss: 1.6294188499450684, Accuracy: 0.505859375\n",
      "Batch: 23, Loss: 1.432653784751892, Accuracy: 0.5361328125\n",
      "Batch: 24, Loss: 1.488673448562622, Accuracy: 0.529296875\n",
      "Batch: 25, Loss: 1.4419175386428833, Accuracy: 0.56640625\n",
      "Batch: 26, Loss: 1.353774905204773, Accuracy: 0.58984375\n",
      "Batch: 27, Loss: 1.4766058921813965, Accuracy: 0.5380859375\n",
      "Batch: 28, Loss: 1.5045920610427856, Accuracy: 0.5341796875\n",
      "Batch: 29, Loss: 1.5376110076904297, Accuracy: 0.505859375\n",
      "Batch: 30, Loss: 1.4607771635055542, Accuracy: 0.5791015625\n",
      "Batch: 31, Loss: 1.4615672826766968, Accuracy: 0.57421875\n",
      "Batch: 32, Loss: 1.3830769062042236, Accuracy: 0.560546875\n",
      "Batch: 33, Loss: 1.6066553592681885, Accuracy: 0.509765625\n",
      "Batch: 34, Loss: 1.658715009689331, Accuracy: 0.51171875\n",
      "Batch: 35, Loss: 1.5517299175262451, Accuracy: 0.521484375\n",
      "Batch: 36, Loss: 1.4887850284576416, Accuracy: 0.5478515625\n",
      "Batch: 37, Loss: 1.5685174465179443, Accuracy: 0.5126953125\n",
      "Batch: 38, Loss: 1.5140793323516846, Accuracy: 0.525390625\n",
      "Batch: 39, Loss: 1.5248160362243652, Accuracy: 0.544921875\n",
      "Batch: 40, Loss: 1.5358704328536987, Accuracy: 0.556640625\n",
      "Batch: 41, Loss: 1.5457346439361572, Accuracy: 0.548828125\n",
      "Batch: 42, Loss: 1.30913245677948, Accuracy: 0.6044921875\n",
      "Batch: 43, Loss: 1.4511239528656006, Accuracy: 0.521484375\n",
      "Batch: 44, Loss: 1.4270706176757812, Accuracy: 0.54296875\n",
      "Batch: 45, Loss: 1.305710792541504, Accuracy: 0.5751953125\n",
      "Batch: 46, Loss: 1.5424152612686157, Accuracy: 0.5576171875\n",
      "Batch: 47, Loss: 1.5062463283538818, Accuracy: 0.55859375\n",
      "Batch: 48, Loss: 1.432154655456543, Accuracy: 0.5576171875\n",
      "Batch: 49, Loss: 1.5828315019607544, Accuracy: 0.515625\n",
      "Batch: 50, Loss: 1.5287222862243652, Accuracy: 0.5224609375\n",
      "Batch: 51, Loss: 1.610624074935913, Accuracy: 0.5048828125\n",
      "Batch: 52, Loss: 1.5856215953826904, Accuracy: 0.51953125\n",
      "Batch: 53, Loss: 1.325583577156067, Accuracy: 0.5703125\n",
      "Batch: 54, Loss: 1.4504811763763428, Accuracy: 0.5556640625\n",
      "Batch: 55, Loss: 1.4866008758544922, Accuracy: 0.5380859375\n",
      "Batch: 56, Loss: 1.5736351013183594, Accuracy: 0.521484375\n",
      "Batch: 57, Loss: 1.4738655090332031, Accuracy: 0.55078125\n",
      "Batch: 58, Loss: 1.5834139585494995, Accuracy: 0.53125\n",
      "Batch: 59, Loss: 1.3653030395507812, Accuracy: 0.6083984375\n",
      "Batch: 60, Loss: 1.3750131130218506, Accuracy: 0.58203125\n",
      "Batch: 61, Loss: 1.5072298049926758, Accuracy: 0.5439453125\n",
      "Batch: 62, Loss: 1.4756500720977783, Accuracy: 0.5546875\n",
      "Batch: 63, Loss: 1.4551434516906738, Accuracy: 0.552734375\n",
      "Batch: 64, Loss: 1.4412117004394531, Accuracy: 0.5546875\n",
      "Batch: 65, Loss: 1.4867281913757324, Accuracy: 0.541015625\n",
      "Batch: 66, Loss: 1.380248785018921, Accuracy: 0.5869140625\n",
      "Batch: 67, Loss: 1.5294811725616455, Accuracy: 0.54296875\n",
      "Batch: 68, Loss: 1.5985541343688965, Accuracy: 0.53125\n",
      "Batch: 69, Loss: 1.5156655311584473, Accuracy: 0.529296875\n",
      "Batch: 70, Loss: 1.5125370025634766, Accuracy: 0.5419921875\n",
      "Batch: 71, Loss: 1.4919116497039795, Accuracy: 0.537109375\n",
      "Batch: 72, Loss: 1.4109065532684326, Accuracy: 0.5517578125\n",
      "Batch: 73, Loss: 1.4823925495147705, Accuracy: 0.55859375\n",
      "Batch: 74, Loss: 1.3624005317687988, Accuracy: 0.5791015625\n",
      "Batch: 75, Loss: 1.3459911346435547, Accuracy: 0.5947265625\n",
      "Batch: 76, Loss: 1.5160977840423584, Accuracy: 0.505859375\n",
      "Batch: 77, Loss: 1.4915603399276733, Accuracy: 0.53125\n",
      "Batch: 78, Loss: 1.4548232555389404, Accuracy: 0.57421875\n",
      "Batch: 79, Loss: 1.3420002460479736, Accuracy: 0.6162109375\n",
      "Batch: 80, Loss: 1.3542964458465576, Accuracy: 0.5673828125\n",
      "Batch: 81, Loss: 1.5121034383773804, Accuracy: 0.5068359375\n",
      "Batch: 82, Loss: 1.4778144359588623, Accuracy: 0.5263671875\n",
      "Batch: 83, Loss: 1.3363193273544312, Accuracy: 0.57421875\n",
      "Batch: 84, Loss: 1.4022812843322754, Accuracy: 0.583984375\n",
      "Batch: 85, Loss: 1.3061842918395996, Accuracy: 0.5947265625\n",
      "Batch: 86, Loss: 1.616646409034729, Accuracy: 0.51171875\n",
      "Batch: 87, Loss: 1.3808351755142212, Accuracy: 0.591796875\n",
      "Batch: 88, Loss: 1.526322364807129, Accuracy: 0.5439453125\n",
      "Batch: 89, Loss: 1.5518455505371094, Accuracy: 0.5390625\n",
      "Batch: 90, Loss: 1.3979642391204834, Accuracy: 0.568359375\n",
      "Batch: 91, Loss: 1.3839929103851318, Accuracy: 0.564453125\n",
      "Batch: 92, Loss: 1.4915006160736084, Accuracy: 0.533203125\n",
      "Batch: 93, Loss: 1.3633923530578613, Accuracy: 0.5673828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 94, Loss: 1.415561318397522, Accuracy: 0.5478515625\n",
      "Batch: 95, Loss: 1.4555542469024658, Accuracy: 0.5302734375\n",
      "Batch: 96, Loss: 1.451815128326416, Accuracy: 0.5576171875\n",
      "Batch: 97, Loss: 1.2946041822433472, Accuracy: 0.59375\n",
      "Batch: 98, Loss: 1.3053315877914429, Accuracy: 0.6083984375\n",
      "Batch: 99, Loss: 1.3032159805297852, Accuracy: 0.5869140625\n",
      "Batch: 100, Loss: 1.415733814239502, Accuracy: 0.5517578125\n",
      "Batch: 101, Loss: 1.4523382186889648, Accuracy: 0.55859375\n",
      "Batch: 102, Loss: 1.3171100616455078, Accuracy: 0.58203125\n",
      "Batch: 103, Loss: 1.4449186325073242, Accuracy: 0.59375\n",
      "Batch: 104, Loss: 1.3266332149505615, Accuracy: 0.5791015625\n",
      "Batch: 105, Loss: 1.4562667608261108, Accuracy: 0.5400390625\n",
      "Batch: 106, Loss: 1.4825152158737183, Accuracy: 0.5458984375\n",
      "Batch: 107, Loss: 1.623518705368042, Accuracy: 0.5126953125\n",
      "Batch: 108, Loss: 1.5603713989257812, Accuracy: 0.5234375\n",
      "Batch: 109, Loss: 1.6282083988189697, Accuracy: 0.5107421875\n",
      "Batch: 110, Loss: 1.2781705856323242, Accuracy: 0.5927734375\n",
      "Batch: 111, Loss: 1.501391887664795, Accuracy: 0.5244140625\n",
      "Batch: 112, Loss: 1.429746150970459, Accuracy: 0.583984375\n",
      "Batch: 113, Loss: 1.4404088258743286, Accuracy: 0.57421875\n",
      "Batch: 114, Loss: 1.5903657674789429, Accuracy: 0.5146484375\n",
      "Batch: 115, Loss: 1.6136873960494995, Accuracy: 0.5380859375\n",
      "Batch: 116, Loss: 1.5768834352493286, Accuracy: 0.5087890625\n",
      "Batch: 117, Loss: 1.5216643810272217, Accuracy: 0.54296875\n",
      "Batch: 118, Loss: 1.3027416467666626, Accuracy: 0.6181640625\n",
      "Batch: 119, Loss: 1.3580915927886963, Accuracy: 0.599609375\n",
      "Batch: 120, Loss: 1.5268993377685547, Accuracy: 0.5302734375\n",
      "Batch: 121, Loss: 1.5943762063980103, Accuracy: 0.5126953125\n",
      "Batch: 122, Loss: 1.4025564193725586, Accuracy: 0.5849609375\n",
      "Batch: 123, Loss: 1.4038803577423096, Accuracy: 0.5751953125\n",
      "Batch: 124, Loss: 1.4420063495635986, Accuracy: 0.5693359375\n",
      "Batch: 125, Loss: 1.4805104732513428, Accuracy: 0.5478515625\n",
      "Batch: 126, Loss: 1.4692257642745972, Accuracy: 0.5205078125\n",
      "Batch: 127, Loss: 1.3251121044158936, Accuracy: 0.6123046875\n",
      "Batch: 128, Loss: 1.5440068244934082, Accuracy: 0.5556640625\n",
      "Batch: 129, Loss: 1.4223829507827759, Accuracy: 0.5634765625\n",
      "Batch: 130, Loss: 1.6648225784301758, Accuracy: 0.5029296875\n",
      "Batch: 131, Loss: 1.4900128841400146, Accuracy: 0.5380859375\n",
      "Batch: 132, Loss: 1.543363094329834, Accuracy: 0.5341796875\n",
      "Batch: 133, Loss: 1.4175958633422852, Accuracy: 0.55859375\n",
      "Batch: 134, Loss: 1.4607230424880981, Accuracy: 0.5439453125\n",
      "Batch: 135, Loss: 1.3903707265853882, Accuracy: 0.576171875\n",
      "Batch: 136, Loss: 1.4262168407440186, Accuracy: 0.5625\n",
      "Batch: 137, Loss: 1.3282212018966675, Accuracy: 0.5556640625\n",
      "Batch: 138, Loss: 1.2199978828430176, Accuracy: 0.611328125\n",
      "Batch: 139, Loss: 1.3047115802764893, Accuracy: 0.5576171875\n",
      "Batch: 140, Loss: 1.4220234155654907, Accuracy: 0.5478515625\n",
      "Batch: 141, Loss: 1.4224117994308472, Accuracy: 0.56640625\n",
      "Batch: 142, Loss: 1.4602046012878418, Accuracy: 0.5439453125\n",
      "Batch: 143, Loss: 1.45100736618042, Accuracy: 0.552734375\n",
      "Batch: 144, Loss: 1.43416428565979, Accuracy: 0.5595703125\n",
      "Batch: 145, Loss: 1.3338913917541504, Accuracy: 0.5634765625\n",
      "Batch: 146, Loss: 1.507408618927002, Accuracy: 0.525390625\n",
      "Batch: 147, Loss: 1.4423972368240356, Accuracy: 0.5546875\n",
      "Batch: 148, Loss: 1.6129292249679565, Accuracy: 0.49609375\n",
      "Batch: 149, Loss: 1.5099250078201294, Accuracy: 0.521484375\n",
      "Batch: 150, Loss: 1.4000303745269775, Accuracy: 0.5732421875\n",
      "Batch: 151, Loss: 1.355667233467102, Accuracy: 0.5810546875\n",
      "Epoch 6/90\n",
      "Batch: 1, Loss: 1.6709920167922974, Accuracy: 0.4873046875\n",
      "Batch: 2, Loss: 1.4214668273925781, Accuracy: 0.5361328125\n",
      "Batch: 3, Loss: 1.3657279014587402, Accuracy: 0.578125\n",
      "Batch: 4, Loss: 1.250214695930481, Accuracy: 0.6220703125\n",
      "Batch: 5, Loss: 1.3177578449249268, Accuracy: 0.5947265625\n",
      "Batch: 6, Loss: 1.4425233602523804, Accuracy: 0.5341796875\n",
      "Batch: 7, Loss: 1.370322585105896, Accuracy: 0.5458984375\n",
      "Batch: 8, Loss: 1.3176062107086182, Accuracy: 0.580078125\n",
      "Batch: 9, Loss: 1.2613468170166016, Accuracy: 0.603515625\n",
      "Batch: 10, Loss: 1.3279902935028076, Accuracy: 0.578125\n",
      "Batch: 11, Loss: 1.5112441778182983, Accuracy: 0.521484375\n",
      "Batch: 12, Loss: 1.5365138053894043, Accuracy: 0.5263671875\n",
      "Batch: 13, Loss: 1.2256388664245605, Accuracy: 0.6162109375\n",
      "Batch: 14, Loss: 1.4553611278533936, Accuracy: 0.5419921875\n",
      "Batch: 15, Loss: 1.3713133335113525, Accuracy: 0.58203125\n",
      "Batch: 16, Loss: 1.338691234588623, Accuracy: 0.587890625\n",
      "Batch: 17, Loss: 1.4601764678955078, Accuracy: 0.5234375\n",
      "Batch: 18, Loss: 1.4651811122894287, Accuracy: 0.5283203125\n",
      "Batch: 19, Loss: 1.4723223447799683, Accuracy: 0.5419921875\n",
      "Batch: 20, Loss: 1.3877320289611816, Accuracy: 0.583984375\n",
      "Batch: 21, Loss: 1.331780195236206, Accuracy: 0.5791015625\n",
      "Batch: 22, Loss: 1.5166478157043457, Accuracy: 0.52734375\n",
      "Batch: 23, Loss: 1.3542733192443848, Accuracy: 0.560546875\n",
      "Batch: 24, Loss: 1.4147565364837646, Accuracy: 0.5537109375\n",
      "Batch: 25, Loss: 1.3609414100646973, Accuracy: 0.55859375\n",
      "Batch: 26, Loss: 1.305708885192871, Accuracy: 0.599609375\n",
      "Batch: 27, Loss: 1.3991485834121704, Accuracy: 0.552734375\n",
      "Batch: 28, Loss: 1.4100574254989624, Accuracy: 0.54296875\n",
      "Batch: 29, Loss: 1.4363163709640503, Accuracy: 0.5322265625\n",
      "Batch: 30, Loss: 1.3749446868896484, Accuracy: 0.59375\n",
      "Batch: 31, Loss: 1.342666506767273, Accuracy: 0.5966796875\n",
      "Batch: 32, Loss: 1.3014299869537354, Accuracy: 0.5791015625\n",
      "Batch: 33, Loss: 1.5255718231201172, Accuracy: 0.5224609375\n",
      "Batch: 34, Loss: 1.5925278663635254, Accuracy: 0.515625\n",
      "Batch: 35, Loss: 1.4502707719802856, Accuracy: 0.54296875\n",
      "Batch: 36, Loss: 1.4195665121078491, Accuracy: 0.564453125\n",
      "Batch: 37, Loss: 1.410661220550537, Accuracy: 0.546875\n",
      "Batch: 38, Loss: 1.4262077808380127, Accuracy: 0.5234375\n",
      "Batch: 39, Loss: 1.459022879600525, Accuracy: 0.5400390625\n",
      "Batch: 40, Loss: 1.4768110513687134, Accuracy: 0.56640625\n",
      "Batch: 41, Loss: 1.4835715293884277, Accuracy: 0.5546875\n",
      "Batch: 42, Loss: 1.2010554075241089, Accuracy: 0.625\n",
      "Batch: 43, Loss: 1.376157283782959, Accuracy: 0.548828125\n",
      "Batch: 44, Loss: 1.359302043914795, Accuracy: 0.552734375\n",
      "Batch: 45, Loss: 1.2097141742706299, Accuracy: 0.6064453125\n",
      "Batch: 46, Loss: 1.4252817630767822, Accuracy: 0.5791015625\n",
      "Batch: 47, Loss: 1.404693603515625, Accuracy: 0.576171875\n",
      "Batch: 48, Loss: 1.342269778251648, Accuracy: 0.578125\n",
      "Batch: 49, Loss: 1.538136601448059, Accuracy: 0.53125\n",
      "Batch: 50, Loss: 1.471039891242981, Accuracy: 0.5419921875\n",
      "Batch: 51, Loss: 1.5609383583068848, Accuracy: 0.533203125\n",
      "Batch: 52, Loss: 1.5039547681808472, Accuracy: 0.5556640625\n",
      "Batch: 53, Loss: 1.2473063468933105, Accuracy: 0.5849609375\n",
      "Batch: 54, Loss: 1.3490068912506104, Accuracy: 0.595703125\n",
      "Batch: 55, Loss: 1.40287446975708, Accuracy: 0.560546875\n",
      "Batch: 56, Loss: 1.4901340007781982, Accuracy: 0.533203125\n",
      "Batch: 57, Loss: 1.3946480751037598, Accuracy: 0.56640625\n",
      "Batch: 58, Loss: 1.4926241636276245, Accuracy: 0.5546875\n",
      "Batch: 59, Loss: 1.285308837890625, Accuracy: 0.6220703125\n",
      "Batch: 60, Loss: 1.29317045211792, Accuracy: 0.6162109375\n",
      "Batch: 61, Loss: 1.423490285873413, Accuracy: 0.5380859375\n",
      "Batch: 62, Loss: 1.3919780254364014, Accuracy: 0.5654296875\n",
      "Batch: 63, Loss: 1.3854296207427979, Accuracy: 0.548828125\n",
      "Batch: 64, Loss: 1.3507037162780762, Accuracy: 0.5673828125\n",
      "Batch: 65, Loss: 1.419992208480835, Accuracy: 0.564453125\n",
      "Batch: 66, Loss: 1.2810089588165283, Accuracy: 0.6201171875\n",
      "Batch: 67, Loss: 1.4720911979675293, Accuracy: 0.552734375\n",
      "Batch: 68, Loss: 1.4901342391967773, Accuracy: 0.5625\n",
      "Batch: 69, Loss: 1.4054648876190186, Accuracy: 0.5576171875\n",
      "Batch: 70, Loss: 1.424162745475769, Accuracy: 0.56640625\n",
      "Batch: 71, Loss: 1.4254728555679321, Accuracy: 0.54296875\n",
      "Batch: 72, Loss: 1.3313953876495361, Accuracy: 0.59765625\n",
      "Batch: 73, Loss: 1.3997076749801636, Accuracy: 0.5751953125\n",
      "Batch: 74, Loss: 1.3303742408752441, Accuracy: 0.59765625\n",
      "Batch: 75, Loss: 1.2674669027328491, Accuracy: 0.611328125\n",
      "Batch: 76, Loss: 1.4244869947433472, Accuracy: 0.53125\n",
      "Batch: 77, Loss: 1.4336965084075928, Accuracy: 0.53125\n",
      "Batch: 78, Loss: 1.3709690570831299, Accuracy: 0.5947265625\n",
      "Batch: 79, Loss: 1.242171049118042, Accuracy: 0.6357421875\n",
      "Batch: 80, Loss: 1.2936104536056519, Accuracy: 0.5830078125\n",
      "Batch: 81, Loss: 1.446120262145996, Accuracy: 0.5341796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 82, Loss: 1.4270298480987549, Accuracy: 0.5341796875\n",
      "Batch: 83, Loss: 1.2505440711975098, Accuracy: 0.6064453125\n",
      "Batch: 84, Loss: 1.3226635456085205, Accuracy: 0.5927734375\n",
      "Batch: 85, Loss: 1.2533843517303467, Accuracy: 0.6044921875\n",
      "Batch: 86, Loss: 1.5594336986541748, Accuracy: 0.51171875\n",
      "Batch: 87, Loss: 1.315216302871704, Accuracy: 0.595703125\n",
      "Batch: 88, Loss: 1.4380167722702026, Accuracy: 0.572265625\n",
      "Batch: 89, Loss: 1.4650564193725586, Accuracy: 0.546875\n",
      "Batch: 90, Loss: 1.3233705759048462, Accuracy: 0.58203125\n",
      "Batch: 91, Loss: 1.3410861492156982, Accuracy: 0.572265625\n",
      "Batch: 92, Loss: 1.4011197090148926, Accuracy: 0.5654296875\n",
      "Batch: 93, Loss: 1.2874506711959839, Accuracy: 0.5927734375\n",
      "Batch: 94, Loss: 1.336362600326538, Accuracy: 0.5595703125\n",
      "Batch: 95, Loss: 1.3951600790023804, Accuracy: 0.5458984375\n",
      "Batch: 96, Loss: 1.3775596618652344, Accuracy: 0.5791015625\n",
      "Batch: 97, Loss: 1.2289512157440186, Accuracy: 0.6064453125\n",
      "Batch: 98, Loss: 1.260292649269104, Accuracy: 0.61328125\n",
      "Batch: 99, Loss: 1.2245677709579468, Accuracy: 0.6181640625\n",
      "Batch: 100, Loss: 1.3466781377792358, Accuracy: 0.578125\n",
      "Batch: 101, Loss: 1.3835973739624023, Accuracy: 0.55859375\n",
      "Batch: 102, Loss: 1.267951488494873, Accuracy: 0.6025390625\n",
      "Batch: 103, Loss: 1.389855146408081, Accuracy: 0.59375\n",
      "Batch: 104, Loss: 1.2560269832611084, Accuracy: 0.60546875\n",
      "Batch: 105, Loss: 1.395826816558838, Accuracy: 0.5546875\n",
      "Batch: 106, Loss: 1.4252777099609375, Accuracy: 0.5625\n",
      "Batch: 107, Loss: 1.5535812377929688, Accuracy: 0.533203125\n",
      "Batch: 108, Loss: 1.481609582901001, Accuracy: 0.556640625\n",
      "Batch: 109, Loss: 1.5462605953216553, Accuracy: 0.5166015625\n",
      "Batch: 110, Loss: 1.2033565044403076, Accuracy: 0.6123046875\n",
      "Batch: 111, Loss: 1.414907693862915, Accuracy: 0.537109375\n",
      "Batch: 112, Loss: 1.3635191917419434, Accuracy: 0.59375\n",
      "Batch: 113, Loss: 1.3711888790130615, Accuracy: 0.5966796875\n",
      "Batch: 114, Loss: 1.5021460056304932, Accuracy: 0.537109375\n",
      "Batch: 115, Loss: 1.5258114337921143, Accuracy: 0.544921875\n",
      "Batch: 116, Loss: 1.4864511489868164, Accuracy: 0.5234375\n",
      "Batch: 117, Loss: 1.464806079864502, Accuracy: 0.564453125\n",
      "Batch: 118, Loss: 1.2346396446228027, Accuracy: 0.6220703125\n",
      "Batch: 119, Loss: 1.2820286750793457, Accuracy: 0.60546875\n",
      "Batch: 120, Loss: 1.451704502105713, Accuracy: 0.5390625\n",
      "Batch: 121, Loss: 1.5061349868774414, Accuracy: 0.5341796875\n",
      "Batch: 122, Loss: 1.3262064456939697, Accuracy: 0.5908203125\n",
      "Batch: 123, Loss: 1.33293616771698, Accuracy: 0.5869140625\n",
      "Batch: 124, Loss: 1.3809642791748047, Accuracy: 0.5791015625\n",
      "Batch: 125, Loss: 1.409646987915039, Accuracy: 0.5654296875\n",
      "Batch: 126, Loss: 1.4096572399139404, Accuracy: 0.5400390625\n",
      "Batch: 127, Loss: 1.2595057487487793, Accuracy: 0.62109375\n",
      "Batch: 128, Loss: 1.5073546171188354, Accuracy: 0.5537109375\n",
      "Batch: 129, Loss: 1.34763503074646, Accuracy: 0.5693359375\n",
      "Batch: 130, Loss: 1.5953102111816406, Accuracy: 0.5283203125\n",
      "Batch: 131, Loss: 1.431934118270874, Accuracy: 0.552734375\n",
      "Batch: 132, Loss: 1.494924783706665, Accuracy: 0.5458984375\n",
      "Batch: 133, Loss: 1.3382971286773682, Accuracy: 0.58203125\n",
      "Batch: 134, Loss: 1.3919345140457153, Accuracy: 0.5546875\n",
      "Batch: 135, Loss: 1.3135173320770264, Accuracy: 0.6044921875\n",
      "Batch: 136, Loss: 1.367647647857666, Accuracy: 0.5615234375\n",
      "Batch: 137, Loss: 1.2851474285125732, Accuracy: 0.580078125\n",
      "Batch: 138, Loss: 1.156011939048767, Accuracy: 0.6259765625\n",
      "Batch: 139, Loss: 1.238313913345337, Accuracy: 0.599609375\n",
      "Batch: 140, Loss: 1.35280442237854, Accuracy: 0.5634765625\n",
      "Batch: 141, Loss: 1.3651750087738037, Accuracy: 0.572265625\n",
      "Batch: 142, Loss: 1.3934295177459717, Accuracy: 0.5732421875\n",
      "Batch: 143, Loss: 1.3999454975128174, Accuracy: 0.5703125\n",
      "Batch: 144, Loss: 1.3576608896255493, Accuracy: 0.5791015625\n",
      "Batch: 145, Loss: 1.2578327655792236, Accuracy: 0.5947265625\n",
      "Batch: 146, Loss: 1.4268969297409058, Accuracy: 0.5478515625\n",
      "Batch: 147, Loss: 1.369281530380249, Accuracy: 0.5595703125\n",
      "Batch: 148, Loss: 1.5314562320709229, Accuracy: 0.51953125\n",
      "Batch: 149, Loss: 1.4208710193634033, Accuracy: 0.5361328125\n",
      "Batch: 150, Loss: 1.3171814680099487, Accuracy: 0.576171875\n",
      "Batch: 151, Loss: 1.2784225940704346, Accuracy: 0.603515625\n",
      "Epoch 7/90\n",
      "Batch: 1, Loss: 1.6598470211029053, Accuracy: 0.5009765625\n",
      "Batch: 2, Loss: 1.3371410369873047, Accuracy: 0.5595703125\n",
      "Batch: 3, Loss: 1.3015631437301636, Accuracy: 0.591796875\n",
      "Batch: 4, Loss: 1.2006773948669434, Accuracy: 0.6337890625\n",
      "Batch: 5, Loss: 1.2437007427215576, Accuracy: 0.61328125\n",
      "Batch: 6, Loss: 1.3785879611968994, Accuracy: 0.5458984375\n",
      "Batch: 7, Loss: 1.3067306280136108, Accuracy: 0.5595703125\n",
      "Batch: 8, Loss: 1.2641385793685913, Accuracy: 0.5859375\n",
      "Batch: 9, Loss: 1.213516116142273, Accuracy: 0.6103515625\n",
      "Batch: 10, Loss: 1.256892442703247, Accuracy: 0.599609375\n",
      "Batch: 11, Loss: 1.4448161125183105, Accuracy: 0.5400390625\n",
      "Batch: 12, Loss: 1.4926731586456299, Accuracy: 0.5322265625\n",
      "Batch: 13, Loss: 1.1538342237472534, Accuracy: 0.6474609375\n",
      "Batch: 14, Loss: 1.4228401184082031, Accuracy: 0.5556640625\n",
      "Batch: 15, Loss: 1.3080477714538574, Accuracy: 0.5947265625\n",
      "Batch: 16, Loss: 1.2892130613327026, Accuracy: 0.5849609375\n",
      "Batch: 17, Loss: 1.4124064445495605, Accuracy: 0.5478515625\n",
      "Batch: 18, Loss: 1.3956868648529053, Accuracy: 0.5625\n",
      "Batch: 19, Loss: 1.437941074371338, Accuracy: 0.54296875\n",
      "Batch: 20, Loss: 1.3074170351028442, Accuracy: 0.59765625\n",
      "Batch: 21, Loss: 1.2759451866149902, Accuracy: 0.5947265625\n",
      "Batch: 22, Loss: 1.4493123292922974, Accuracy: 0.55859375\n",
      "Batch: 23, Loss: 1.3078341484069824, Accuracy: 0.5849609375\n",
      "Batch: 24, Loss: 1.3388699293136597, Accuracy: 0.564453125\n",
      "Batch: 25, Loss: 1.2998545169830322, Accuracy: 0.5859375\n",
      "Batch: 26, Loss: 1.2171756029129028, Accuracy: 0.6259765625\n",
      "Batch: 27, Loss: 1.297135591506958, Accuracy: 0.568359375\n",
      "Batch: 28, Loss: 1.3641239404678345, Accuracy: 0.560546875\n",
      "Batch: 29, Loss: 1.3865866661071777, Accuracy: 0.5400390625\n",
      "Batch: 30, Loss: 1.3085453510284424, Accuracy: 0.615234375\n",
      "Batch: 31, Loss: 1.2952158451080322, Accuracy: 0.607421875\n",
      "Batch: 32, Loss: 1.2346760034561157, Accuracy: 0.607421875\n",
      "Batch: 33, Loss: 1.4512732028961182, Accuracy: 0.54296875\n",
      "Batch: 34, Loss: 1.4992942810058594, Accuracy: 0.5390625\n",
      "Batch: 35, Loss: 1.3918709754943848, Accuracy: 0.546875\n",
      "Batch: 36, Loss: 1.3788697719573975, Accuracy: 0.5712890625\n",
      "Batch: 37, Loss: 1.3387045860290527, Accuracy: 0.5654296875\n",
      "Batch: 38, Loss: 1.356175184249878, Accuracy: 0.560546875\n",
      "Batch: 39, Loss: 1.3911479711532593, Accuracy: 0.576171875\n",
      "Batch: 40, Loss: 1.4036118984222412, Accuracy: 0.5810546875\n",
      "Batch: 41, Loss: 1.3850693702697754, Accuracy: 0.5693359375\n",
      "Batch: 42, Loss: 1.13451087474823, Accuracy: 0.6328125\n",
      "Batch: 43, Loss: 1.3164923191070557, Accuracy: 0.5693359375\n",
      "Batch: 44, Loss: 1.2940270900726318, Accuracy: 0.576171875\n",
      "Batch: 45, Loss: 1.1802241802215576, Accuracy: 0.609375\n",
      "Batch: 46, Loss: 1.3568196296691895, Accuracy: 0.5986328125\n",
      "Batch: 47, Loss: 1.3237409591674805, Accuracy: 0.5927734375\n",
      "Batch: 48, Loss: 1.2617019414901733, Accuracy: 0.6103515625\n",
      "Batch: 49, Loss: 1.4497748613357544, Accuracy: 0.541015625\n",
      "Batch: 50, Loss: 1.4055637121200562, Accuracy: 0.5380859375\n",
      "Batch: 51, Loss: 1.4797135591506958, Accuracy: 0.5263671875\n",
      "Batch: 52, Loss: 1.447840929031372, Accuracy: 0.5517578125\n",
      "Batch: 53, Loss: 1.1842575073242188, Accuracy: 0.619140625\n",
      "Batch: 54, Loss: 1.2941339015960693, Accuracy: 0.6123046875\n",
      "Batch: 55, Loss: 1.3543879985809326, Accuracy: 0.5693359375\n",
      "Batch: 56, Loss: 1.3972582817077637, Accuracy: 0.5634765625\n",
      "Batch: 57, Loss: 1.3272509574890137, Accuracy: 0.591796875\n",
      "Batch: 58, Loss: 1.4324369430541992, Accuracy: 0.5673828125\n",
      "Batch: 59, Loss: 1.2309057712554932, Accuracy: 0.625\n",
      "Batch: 60, Loss: 1.2395052909851074, Accuracy: 0.611328125\n",
      "Batch: 61, Loss: 1.3634569644927979, Accuracy: 0.5703125\n",
      "Batch: 62, Loss: 1.313929796218872, Accuracy: 0.57421875\n",
      "Batch: 63, Loss: 1.298010230064392, Accuracy: 0.57421875\n",
      "Batch: 64, Loss: 1.2971844673156738, Accuracy: 0.5830078125\n",
      "Batch: 65, Loss: 1.3500714302062988, Accuracy: 0.5751953125\n",
      "Batch: 66, Loss: 1.2451833486557007, Accuracy: 0.623046875\n",
      "Batch: 67, Loss: 1.413600206375122, Accuracy: 0.57421875\n",
      "Batch: 68, Loss: 1.459327220916748, Accuracy: 0.5693359375\n",
      "Batch: 69, Loss: 1.3494291305541992, Accuracy: 0.5751953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 70, Loss: 1.3539056777954102, Accuracy: 0.583984375\n",
      "Batch: 71, Loss: 1.3680980205535889, Accuracy: 0.564453125\n",
      "Batch: 72, Loss: 1.2507911920547485, Accuracy: 0.6064453125\n",
      "Batch: 73, Loss: 1.327341079711914, Accuracy: 0.59765625\n",
      "Batch: 74, Loss: 1.2592980861663818, Accuracy: 0.607421875\n",
      "Batch: 75, Loss: 1.2263875007629395, Accuracy: 0.62109375\n",
      "Batch: 76, Loss: 1.365214467048645, Accuracy: 0.5537109375\n",
      "Batch: 77, Loss: 1.3587009906768799, Accuracy: 0.5673828125\n",
      "Batch: 78, Loss: 1.3155272006988525, Accuracy: 0.6064453125\n",
      "Batch: 79, Loss: 1.1826183795928955, Accuracy: 0.65234375\n",
      "Batch: 80, Loss: 1.2156883478164673, Accuracy: 0.6123046875\n",
      "Batch: 81, Loss: 1.4154460430145264, Accuracy: 0.5244140625\n",
      "Batch: 82, Loss: 1.3773624897003174, Accuracy: 0.5400390625\n",
      "Batch: 83, Loss: 1.2117891311645508, Accuracy: 0.6162109375\n",
      "Batch: 84, Loss: 1.2729182243347168, Accuracy: 0.6171875\n",
      "Batch: 85, Loss: 1.1944141387939453, Accuracy: 0.6201171875\n",
      "Batch: 86, Loss: 1.4994316101074219, Accuracy: 0.5390625\n",
      "Batch: 87, Loss: 1.2370911836624146, Accuracy: 0.625\n",
      "Batch: 88, Loss: 1.3868193626403809, Accuracy: 0.58203125\n",
      "Batch: 89, Loss: 1.390538215637207, Accuracy: 0.58203125\n",
      "Batch: 90, Loss: 1.271658182144165, Accuracy: 0.603515625\n",
      "Batch: 91, Loss: 1.3057283163070679, Accuracy: 0.5966796875\n",
      "Batch: 92, Loss: 1.3317017555236816, Accuracy: 0.5751953125\n",
      "Batch: 93, Loss: 1.211634635925293, Accuracy: 0.626953125\n",
      "Batch: 94, Loss: 1.2635242938995361, Accuracy: 0.58203125\n",
      "Batch: 95, Loss: 1.344449520111084, Accuracy: 0.5615234375\n",
      "Batch: 96, Loss: 1.3142858743667603, Accuracy: 0.5908203125\n",
      "Batch: 97, Loss: 1.1539942026138306, Accuracy: 0.6318359375\n",
      "Batch: 98, Loss: 1.1954046487808228, Accuracy: 0.646484375\n",
      "Batch: 99, Loss: 1.1639213562011719, Accuracy: 0.6162109375\n",
      "Batch: 100, Loss: 1.309645175933838, Accuracy: 0.57421875\n",
      "Batch: 101, Loss: 1.344141960144043, Accuracy: 0.5634765625\n",
      "Batch: 102, Loss: 1.229598045349121, Accuracy: 0.609375\n",
      "Batch: 103, Loss: 1.3124127388000488, Accuracy: 0.607421875\n",
      "Batch: 104, Loss: 1.1882929801940918, Accuracy: 0.6083984375\n",
      "Batch: 105, Loss: 1.345844030380249, Accuracy: 0.5615234375\n",
      "Batch: 106, Loss: 1.3527534008026123, Accuracy: 0.60546875\n",
      "Batch: 107, Loss: 1.475854754447937, Accuracy: 0.55859375\n",
      "Batch: 108, Loss: 1.4110844135284424, Accuracy: 0.5517578125\n",
      "Batch: 109, Loss: 1.5045299530029297, Accuracy: 0.5283203125\n",
      "Batch: 110, Loss: 1.1500396728515625, Accuracy: 0.6220703125\n",
      "Batch: 111, Loss: 1.3577630519866943, Accuracy: 0.55859375\n",
      "Batch: 112, Loss: 1.279550552368164, Accuracy: 0.61328125\n",
      "Batch: 113, Loss: 1.314721941947937, Accuracy: 0.603515625\n",
      "Batch: 114, Loss: 1.46101713180542, Accuracy: 0.5556640625\n",
      "Batch: 115, Loss: 1.4717223644256592, Accuracy: 0.556640625\n",
      "Batch: 116, Loss: 1.4150986671447754, Accuracy: 0.552734375\n",
      "Batch: 117, Loss: 1.401911735534668, Accuracy: 0.576171875\n",
      "Batch: 118, Loss: 1.1722333431243896, Accuracy: 0.638671875\n",
      "Batch: 119, Loss: 1.2176443338394165, Accuracy: 0.6318359375\n",
      "Batch: 120, Loss: 1.3745702505111694, Accuracy: 0.5458984375\n",
      "Batch: 121, Loss: 1.426261067390442, Accuracy: 0.54296875\n",
      "Batch: 122, Loss: 1.2717132568359375, Accuracy: 0.6123046875\n",
      "Batch: 123, Loss: 1.259081482887268, Accuracy: 0.603515625\n",
      "Batch: 124, Loss: 1.3160223960876465, Accuracy: 0.59765625\n",
      "Batch: 125, Loss: 1.3599987030029297, Accuracy: 0.576171875\n",
      "Batch: 126, Loss: 1.3615174293518066, Accuracy: 0.556640625\n",
      "Batch: 127, Loss: 1.2172101736068726, Accuracy: 0.6259765625\n",
      "Batch: 128, Loss: 1.4308197498321533, Accuracy: 0.5654296875\n",
      "Batch: 129, Loss: 1.2872984409332275, Accuracy: 0.5908203125\n",
      "Batch: 130, Loss: 1.520438551902771, Accuracy: 0.5302734375\n",
      "Batch: 131, Loss: 1.379174828529358, Accuracy: 0.576171875\n",
      "Batch: 132, Loss: 1.4480407238006592, Accuracy: 0.5556640625\n",
      "Batch: 133, Loss: 1.2741317749023438, Accuracy: 0.595703125\n",
      "Batch: 134, Loss: 1.3251385688781738, Accuracy: 0.5859375\n",
      "Batch: 135, Loss: 1.2657363414764404, Accuracy: 0.61328125\n",
      "Batch: 136, Loss: 1.311192512512207, Accuracy: 0.5771484375\n",
      "Batch: 137, Loss: 1.217644453048706, Accuracy: 0.5986328125\n",
      "Batch: 138, Loss: 1.094128966331482, Accuracy: 0.634765625\n",
      "Batch: 139, Loss: 1.1701483726501465, Accuracy: 0.6142578125\n",
      "Batch: 140, Loss: 1.3075587749481201, Accuracy: 0.568359375\n",
      "Batch: 141, Loss: 1.3035441637039185, Accuracy: 0.5966796875\n",
      "Batch: 142, Loss: 1.3397414684295654, Accuracy: 0.576171875\n",
      "Batch: 143, Loss: 1.3442456722259521, Accuracy: 0.568359375\n",
      "Batch: 144, Loss: 1.3144084215164185, Accuracy: 0.5849609375\n",
      "Batch: 145, Loss: 1.2126033306121826, Accuracy: 0.591796875\n",
      "Batch: 146, Loss: 1.3592019081115723, Accuracy: 0.572265625\n",
      "Batch: 147, Loss: 1.3210251331329346, Accuracy: 0.583984375\n",
      "Batch: 148, Loss: 1.4795113801956177, Accuracy: 0.5263671875\n",
      "Batch: 149, Loss: 1.3479375839233398, Accuracy: 0.5654296875\n",
      "Batch: 150, Loss: 1.2747677564620972, Accuracy: 0.576171875\n",
      "Batch: 151, Loss: 1.2165286540985107, Accuracy: 0.623046875\n",
      "Epoch 8/90\n",
      "Batch: 1, Loss: 1.5915825366973877, Accuracy: 0.4970703125\n",
      "Batch: 2, Loss: 1.3159990310668945, Accuracy: 0.5537109375\n",
      "Batch: 3, Loss: 1.255108118057251, Accuracy: 0.5908203125\n",
      "Batch: 4, Loss: 1.1541775465011597, Accuracy: 0.6435546875\n",
      "Batch: 5, Loss: 1.2023394107818604, Accuracy: 0.619140625\n",
      "Batch: 6, Loss: 1.3283500671386719, Accuracy: 0.5732421875\n",
      "Batch: 7, Loss: 1.2381747961044312, Accuracy: 0.595703125\n",
      "Batch: 8, Loss: 1.2262017726898193, Accuracy: 0.5947265625\n",
      "Batch: 9, Loss: 1.1624879837036133, Accuracy: 0.630859375\n",
      "Batch: 10, Loss: 1.188814640045166, Accuracy: 0.619140625\n",
      "Batch: 11, Loss: 1.3914024829864502, Accuracy: 0.552734375\n",
      "Batch: 12, Loss: 1.426207184791565, Accuracy: 0.54296875\n",
      "Batch: 13, Loss: 1.108825445175171, Accuracy: 0.654296875\n",
      "Batch: 14, Loss: 1.3752297163009644, Accuracy: 0.55078125\n",
      "Batch: 15, Loss: 1.2385315895080566, Accuracy: 0.634765625\n",
      "Batch: 16, Loss: 1.240518569946289, Accuracy: 0.6103515625\n",
      "Batch: 17, Loss: 1.3528279066085815, Accuracy: 0.55859375\n",
      "Batch: 18, Loss: 1.3311352729797363, Accuracy: 0.5732421875\n",
      "Batch: 19, Loss: 1.3815809488296509, Accuracy: 0.5673828125\n",
      "Batch: 20, Loss: 1.2520999908447266, Accuracy: 0.603515625\n",
      "Batch: 21, Loss: 1.2376978397369385, Accuracy: 0.6025390625\n",
      "Batch: 22, Loss: 1.3712012767791748, Accuracy: 0.580078125\n",
      "Batch: 23, Loss: 1.2350425720214844, Accuracy: 0.603515625\n",
      "Batch: 24, Loss: 1.2953206300735474, Accuracy: 0.58203125\n",
      "Batch: 25, Loss: 1.2457098960876465, Accuracy: 0.599609375\n",
      "Batch: 26, Loss: 1.1681747436523438, Accuracy: 0.62890625\n",
      "Batch: 27, Loss: 1.2314763069152832, Accuracy: 0.595703125\n",
      "Batch: 28, Loss: 1.298121452331543, Accuracy: 0.5810546875\n",
      "Batch: 29, Loss: 1.3256804943084717, Accuracy: 0.5576171875\n",
      "Batch: 30, Loss: 1.2412493228912354, Accuracy: 0.625\n",
      "Batch: 31, Loss: 1.2148425579071045, Accuracy: 0.615234375\n",
      "Batch: 32, Loss: 1.1902097463607788, Accuracy: 0.6220703125\n",
      "Batch: 33, Loss: 1.4154144525527954, Accuracy: 0.5537109375\n",
      "Batch: 34, Loss: 1.458133578300476, Accuracy: 0.548828125\n",
      "Batch: 35, Loss: 1.3257269859313965, Accuracy: 0.5595703125\n",
      "Batch: 36, Loss: 1.2940654754638672, Accuracy: 0.59765625\n",
      "Batch: 37, Loss: 1.2837616205215454, Accuracy: 0.580078125\n",
      "Batch: 38, Loss: 1.3012200593948364, Accuracy: 0.5732421875\n",
      "Batch: 39, Loss: 1.3361554145812988, Accuracy: 0.58203125\n",
      "Batch: 40, Loss: 1.351507544517517, Accuracy: 0.5859375\n",
      "Batch: 41, Loss: 1.3367345333099365, Accuracy: 0.5908203125\n",
      "Batch: 42, Loss: 1.0687668323516846, Accuracy: 0.654296875\n",
      "Batch: 43, Loss: 1.274333119392395, Accuracy: 0.583984375\n",
      "Batch: 44, Loss: 1.2552791833877563, Accuracy: 0.572265625\n",
      "Batch: 45, Loss: 1.1051864624023438, Accuracy: 0.6240234375\n",
      "Batch: 46, Loss: 1.283339023590088, Accuracy: 0.6259765625\n",
      "Batch: 47, Loss: 1.2565587759017944, Accuracy: 0.62109375\n",
      "Batch: 48, Loss: 1.1906757354736328, Accuracy: 0.6123046875\n",
      "Batch: 49, Loss: 1.3971495628356934, Accuracy: 0.5517578125\n",
      "Batch: 50, Loss: 1.349877119064331, Accuracy: 0.556640625\n",
      "Batch: 51, Loss: 1.4306479692459106, Accuracy: 0.5380859375\n",
      "Batch: 52, Loss: 1.3907525539398193, Accuracy: 0.5712890625\n",
      "Batch: 53, Loss: 1.1376841068267822, Accuracy: 0.6357421875\n",
      "Batch: 54, Loss: 1.2296359539031982, Accuracy: 0.6220703125\n",
      "Batch: 55, Loss: 1.3096177577972412, Accuracy: 0.576171875\n",
      "Batch: 56, Loss: 1.357093334197998, Accuracy: 0.5859375\n",
      "Batch: 57, Loss: 1.2600152492523193, Accuracy: 0.6083984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 58, Loss: 1.3813509941101074, Accuracy: 0.576171875\n",
      "Batch: 59, Loss: 1.1735992431640625, Accuracy: 0.6484375\n",
      "Batch: 60, Loss: 1.1785613298416138, Accuracy: 0.6318359375\n",
      "Batch: 61, Loss: 1.3179682493209839, Accuracy: 0.576171875\n",
      "Batch: 62, Loss: 1.2608883380889893, Accuracy: 0.59375\n",
      "Batch: 63, Loss: 1.2661460638046265, Accuracy: 0.5986328125\n",
      "Batch: 64, Loss: 1.2401862144470215, Accuracy: 0.609375\n",
      "Batch: 65, Loss: 1.3025926351547241, Accuracy: 0.5849609375\n",
      "Batch: 66, Loss: 1.1973875761032104, Accuracy: 0.638671875\n",
      "Batch: 67, Loss: 1.356940507888794, Accuracy: 0.56640625\n",
      "Batch: 68, Loss: 1.3943058252334595, Accuracy: 0.5751953125\n",
      "Batch: 69, Loss: 1.3030505180358887, Accuracy: 0.5927734375\n",
      "Batch: 70, Loss: 1.294426679611206, Accuracy: 0.6083984375\n",
      "Batch: 71, Loss: 1.3177363872528076, Accuracy: 0.5810546875\n",
      "Batch: 72, Loss: 1.1876118183135986, Accuracy: 0.6328125\n",
      "Batch: 73, Loss: 1.2572442293167114, Accuracy: 0.62109375\n",
      "Batch: 74, Loss: 1.2179296016693115, Accuracy: 0.61328125\n",
      "Batch: 75, Loss: 1.1766374111175537, Accuracy: 0.6181640625\n",
      "Batch: 76, Loss: 1.3227922916412354, Accuracy: 0.56640625\n",
      "Batch: 77, Loss: 1.2861747741699219, Accuracy: 0.5830078125\n",
      "Batch: 78, Loss: 1.2609171867370605, Accuracy: 0.62109375\n",
      "Batch: 79, Loss: 1.136857509613037, Accuracy: 0.654296875\n",
      "Batch: 80, Loss: 1.1890661716461182, Accuracy: 0.615234375\n",
      "Batch: 81, Loss: 1.3721613883972168, Accuracy: 0.5419921875\n",
      "Batch: 82, Loss: 1.3271163702011108, Accuracy: 0.5625\n",
      "Batch: 83, Loss: 1.1591978073120117, Accuracy: 0.626953125\n",
      "Batch: 84, Loss: 1.2271450757980347, Accuracy: 0.6279296875\n",
      "Batch: 85, Loss: 1.1503665447235107, Accuracy: 0.6201171875\n",
      "Batch: 86, Loss: 1.4250696897506714, Accuracy: 0.5498046875\n",
      "Batch: 87, Loss: 1.1801564693450928, Accuracy: 0.6455078125\n",
      "Batch: 88, Loss: 1.3294392824172974, Accuracy: 0.6015625\n",
      "Batch: 89, Loss: 1.3357787132263184, Accuracy: 0.583984375\n",
      "Batch: 90, Loss: 1.1958739757537842, Accuracy: 0.625\n",
      "Batch: 91, Loss: 1.2749179601669312, Accuracy: 0.6044921875\n",
      "Batch: 92, Loss: 1.3008733987808228, Accuracy: 0.595703125\n",
      "Batch: 93, Loss: 1.1799054145812988, Accuracy: 0.6201171875\n",
      "Batch: 94, Loss: 1.2091195583343506, Accuracy: 0.6015625\n",
      "Batch: 95, Loss: 1.30560302734375, Accuracy: 0.5859375\n",
      "Batch: 96, Loss: 1.238013744354248, Accuracy: 0.611328125\n",
      "Batch: 97, Loss: 1.1075910329818726, Accuracy: 0.6484375\n",
      "Batch: 98, Loss: 1.1724849939346313, Accuracy: 0.63671875\n",
      "Batch: 99, Loss: 1.128282070159912, Accuracy: 0.6201171875\n",
      "Batch: 100, Loss: 1.2366609573364258, Accuracy: 0.5908203125\n",
      "Batch: 101, Loss: 1.2968264818191528, Accuracy: 0.591796875\n",
      "Batch: 102, Loss: 1.1703636646270752, Accuracy: 0.615234375\n",
      "Batch: 103, Loss: 1.2899013757705688, Accuracy: 0.615234375\n",
      "Batch: 104, Loss: 1.1340558528900146, Accuracy: 0.630859375\n",
      "Batch: 105, Loss: 1.2965271472930908, Accuracy: 0.5849609375\n",
      "Batch: 106, Loss: 1.294681191444397, Accuracy: 0.5908203125\n",
      "Batch: 107, Loss: 1.4012043476104736, Accuracy: 0.560546875\n",
      "Batch: 108, Loss: 1.3376617431640625, Accuracy: 0.5771484375\n",
      "Batch: 109, Loss: 1.4355132579803467, Accuracy: 0.53515625\n",
      "Batch: 110, Loss: 1.0926952362060547, Accuracy: 0.642578125\n",
      "Batch: 111, Loss: 1.324406623840332, Accuracy: 0.55859375\n",
      "Batch: 112, Loss: 1.2414355278015137, Accuracy: 0.6142578125\n",
      "Batch: 113, Loss: 1.258147954940796, Accuracy: 0.6318359375\n",
      "Batch: 114, Loss: 1.4121623039245605, Accuracy: 0.5673828125\n",
      "Batch: 115, Loss: 1.416900634765625, Accuracy: 0.5810546875\n",
      "Batch: 116, Loss: 1.3411633968353271, Accuracy: 0.568359375\n",
      "Batch: 117, Loss: 1.3365527391433716, Accuracy: 0.5966796875\n",
      "Batch: 118, Loss: 1.126671552658081, Accuracy: 0.650390625\n",
      "Batch: 119, Loss: 1.1602692604064941, Accuracy: 0.6416015625\n",
      "Batch: 120, Loss: 1.31999933719635, Accuracy: 0.5703125\n",
      "Batch: 121, Loss: 1.3673803806304932, Accuracy: 0.5771484375\n",
      "Batch: 122, Loss: 1.2273168563842773, Accuracy: 0.623046875\n",
      "Batch: 123, Loss: 1.2022032737731934, Accuracy: 0.62109375\n",
      "Batch: 124, Loss: 1.2741625308990479, Accuracy: 0.599609375\n",
      "Batch: 125, Loss: 1.3228819370269775, Accuracy: 0.5830078125\n",
      "Batch: 126, Loss: 1.332667589187622, Accuracy: 0.56640625\n",
      "Batch: 127, Loss: 1.1897850036621094, Accuracy: 0.63671875\n",
      "Batch: 128, Loss: 1.4129621982574463, Accuracy: 0.5673828125\n",
      "Batch: 129, Loss: 1.2403440475463867, Accuracy: 0.59765625\n",
      "Batch: 130, Loss: 1.463748574256897, Accuracy: 0.552734375\n",
      "Batch: 131, Loss: 1.338510274887085, Accuracy: 0.583984375\n",
      "Batch: 132, Loss: 1.393103837966919, Accuracy: 0.5654296875\n",
      "Batch: 133, Loss: 1.234375, Accuracy: 0.599609375\n",
      "Batch: 134, Loss: 1.2638542652130127, Accuracy: 0.5986328125\n",
      "Batch: 135, Loss: 1.1893576383590698, Accuracy: 0.62890625\n",
      "Batch: 136, Loss: 1.2457211017608643, Accuracy: 0.599609375\n",
      "Batch: 137, Loss: 1.1824235916137695, Accuracy: 0.6123046875\n",
      "Batch: 138, Loss: 1.064794659614563, Accuracy: 0.6474609375\n",
      "Batch: 139, Loss: 1.1453046798706055, Accuracy: 0.611328125\n",
      "Batch: 140, Loss: 1.277998685836792, Accuracy: 0.580078125\n",
      "Batch: 141, Loss: 1.2832820415496826, Accuracy: 0.591796875\n",
      "Batch: 142, Loss: 1.2882224321365356, Accuracy: 0.5966796875\n",
      "Batch: 143, Loss: 1.3133844137191772, Accuracy: 0.5986328125\n",
      "Batch: 144, Loss: 1.27627694606781, Accuracy: 0.5966796875\n",
      "Batch: 145, Loss: 1.1701053380966187, Accuracy: 0.6005859375\n",
      "Batch: 146, Loss: 1.3361377716064453, Accuracy: 0.5712890625\n",
      "Batch: 147, Loss: 1.2962448596954346, Accuracy: 0.580078125\n",
      "Batch: 148, Loss: 1.4260683059692383, Accuracy: 0.5263671875\n",
      "Batch: 149, Loss: 1.3100703954696655, Accuracy: 0.5712890625\n",
      "Batch: 150, Loss: 1.2092539072036743, Accuracy: 0.607421875\n",
      "Batch: 151, Loss: 1.1411329507827759, Accuracy: 0.62890625\n",
      "Epoch 9/90\n",
      "Batch: 1, Loss: 1.517479419708252, Accuracy: 0.5029296875\n",
      "Batch: 2, Loss: 1.2723489999771118, Accuracy: 0.5654296875\n",
      "Batch: 3, Loss: 1.200828194618225, Accuracy: 0.6064453125\n",
      "Batch: 4, Loss: 1.1223196983337402, Accuracy: 0.654296875\n",
      "Batch: 5, Loss: 1.1395528316497803, Accuracy: 0.646484375\n",
      "Batch: 6, Loss: 1.2584500312805176, Accuracy: 0.6025390625\n",
      "Batch: 7, Loss: 1.209914207458496, Accuracy: 0.6015625\n",
      "Batch: 8, Loss: 1.1618731021881104, Accuracy: 0.6181640625\n",
      "Batch: 9, Loss: 1.1244210004806519, Accuracy: 0.6435546875\n",
      "Batch: 10, Loss: 1.133152961730957, Accuracy: 0.62890625\n",
      "Batch: 11, Loss: 1.3488197326660156, Accuracy: 0.544921875\n",
      "Batch: 12, Loss: 1.3861808776855469, Accuracy: 0.5576171875\n",
      "Batch: 13, Loss: 1.0795968770980835, Accuracy: 0.6591796875\n",
      "Batch: 14, Loss: 1.324678659439087, Accuracy: 0.5771484375\n",
      "Batch: 15, Loss: 1.1929841041564941, Accuracy: 0.6416015625\n",
      "Batch: 16, Loss: 1.1983352899551392, Accuracy: 0.6142578125\n",
      "Batch: 17, Loss: 1.2956178188323975, Accuracy: 0.5859375\n",
      "Batch: 18, Loss: 1.2956874370574951, Accuracy: 0.572265625\n",
      "Batch: 19, Loss: 1.3498156070709229, Accuracy: 0.57421875\n",
      "Batch: 20, Loss: 1.2011542320251465, Accuracy: 0.6298828125\n",
      "Batch: 21, Loss: 1.179520845413208, Accuracy: 0.61328125\n",
      "Batch: 22, Loss: 1.3376247882843018, Accuracy: 0.5693359375\n",
      "Batch: 23, Loss: 1.2187044620513916, Accuracy: 0.60546875\n",
      "Batch: 24, Loss: 1.2468523979187012, Accuracy: 0.60546875\n",
      "Batch: 25, Loss: 1.2262263298034668, Accuracy: 0.603515625\n",
      "Batch: 26, Loss: 1.115537405014038, Accuracy: 0.642578125\n",
      "Batch: 27, Loss: 1.2004446983337402, Accuracy: 0.6005859375\n",
      "Batch: 28, Loss: 1.267471194267273, Accuracy: 0.57421875\n",
      "Batch: 29, Loss: 1.2914679050445557, Accuracy: 0.58984375\n",
      "Batch: 30, Loss: 1.1822590827941895, Accuracy: 0.6484375\n",
      "Batch: 31, Loss: 1.1834235191345215, Accuracy: 0.634765625\n",
      "Batch: 32, Loss: 1.1395680904388428, Accuracy: 0.6171875\n",
      "Batch: 33, Loss: 1.3377128839492798, Accuracy: 0.5693359375\n",
      "Batch: 34, Loss: 1.41709566116333, Accuracy: 0.564453125\n",
      "Batch: 35, Loss: 1.290299654006958, Accuracy: 0.572265625\n",
      "Batch: 36, Loss: 1.2576136589050293, Accuracy: 0.6015625\n",
      "Batch: 37, Loss: 1.236846685409546, Accuracy: 0.5830078125\n",
      "Batch: 38, Loss: 1.235518455505371, Accuracy: 0.5703125\n",
      "Batch: 39, Loss: 1.270792007446289, Accuracy: 0.6044921875\n",
      "Batch: 40, Loss: 1.2971060276031494, Accuracy: 0.6171875\n",
      "Batch: 41, Loss: 1.274937629699707, Accuracy: 0.603515625\n",
      "Batch: 42, Loss: 1.0396862030029297, Accuracy: 0.65234375\n",
      "Batch: 43, Loss: 1.2480210065841675, Accuracy: 0.587890625\n",
      "Batch: 44, Loss: 1.2350215911865234, Accuracy: 0.5859375\n",
      "Batch: 45, Loss: 1.074806571006775, Accuracy: 0.642578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 46, Loss: 1.2582643032073975, Accuracy: 0.6220703125\n",
      "Batch: 47, Loss: 1.190674901008606, Accuracy: 0.6181640625\n",
      "Batch: 48, Loss: 1.1525218486785889, Accuracy: 0.6298828125\n",
      "Batch: 49, Loss: 1.3581702709197998, Accuracy: 0.5517578125\n",
      "Batch: 50, Loss: 1.2960178852081299, Accuracy: 0.5830078125\n",
      "Batch: 51, Loss: 1.3869013786315918, Accuracy: 0.5478515625\n",
      "Batch: 52, Loss: 1.3120248317718506, Accuracy: 0.5966796875\n",
      "Batch: 53, Loss: 1.0952047109603882, Accuracy: 0.6376953125\n",
      "Batch: 54, Loss: 1.2010300159454346, Accuracy: 0.6259765625\n",
      "Batch: 55, Loss: 1.2367810010910034, Accuracy: 0.5888671875\n",
      "Batch: 56, Loss: 1.3039374351501465, Accuracy: 0.5888671875\n",
      "Batch: 57, Loss: 1.2063171863555908, Accuracy: 0.6318359375\n",
      "Batch: 58, Loss: 1.2991106510162354, Accuracy: 0.5908203125\n",
      "Batch: 59, Loss: 1.1482211351394653, Accuracy: 0.6533203125\n",
      "Batch: 60, Loss: 1.1453444957733154, Accuracy: 0.63671875\n",
      "Batch: 61, Loss: 1.2521811723709106, Accuracy: 0.5908203125\n",
      "Batch: 62, Loss: 1.2456711530685425, Accuracy: 0.60546875\n",
      "Batch: 63, Loss: 1.2333577871322632, Accuracy: 0.587890625\n",
      "Batch: 64, Loss: 1.1906049251556396, Accuracy: 0.6201171875\n",
      "Batch: 65, Loss: 1.2611985206604004, Accuracy: 0.6064453125\n",
      "Batch: 66, Loss: 1.1499176025390625, Accuracy: 0.634765625\n",
      "Batch: 67, Loss: 1.3324050903320312, Accuracy: 0.58984375\n",
      "Batch: 68, Loss: 1.364395022392273, Accuracy: 0.599609375\n",
      "Batch: 69, Loss: 1.2733938694000244, Accuracy: 0.5966796875\n",
      "Batch: 70, Loss: 1.2626186609268188, Accuracy: 0.611328125\n",
      "Batch: 71, Loss: 1.2830084562301636, Accuracy: 0.591796875\n",
      "Batch: 72, Loss: 1.1313942670822144, Accuracy: 0.6337890625\n",
      "Batch: 73, Loss: 1.2017321586608887, Accuracy: 0.6162109375\n",
      "Batch: 74, Loss: 1.1656620502471924, Accuracy: 0.6416015625\n",
      "Batch: 75, Loss: 1.1342477798461914, Accuracy: 0.6181640625\n",
      "Batch: 76, Loss: 1.283327341079712, Accuracy: 0.5830078125\n",
      "Batch: 77, Loss: 1.2613046169281006, Accuracy: 0.58203125\n",
      "Batch: 78, Loss: 1.2143001556396484, Accuracy: 0.6171875\n",
      "Batch: 79, Loss: 1.1047478914260864, Accuracy: 0.6767578125\n",
      "Batch: 80, Loss: 1.1343026161193848, Accuracy: 0.6142578125\n",
      "Batch: 81, Loss: 1.3223332166671753, Accuracy: 0.546875\n",
      "Batch: 82, Loss: 1.2883789539337158, Accuracy: 0.5810546875\n",
      "Batch: 83, Loss: 1.1273853778839111, Accuracy: 0.640625\n",
      "Batch: 84, Loss: 1.1561371088027954, Accuracy: 0.66015625\n",
      "Batch: 85, Loss: 1.1133031845092773, Accuracy: 0.64453125\n",
      "Batch: 86, Loss: 1.3810977935791016, Accuracy: 0.576171875\n",
      "Batch: 87, Loss: 1.132204532623291, Accuracy: 0.6708984375\n",
      "Batch: 88, Loss: 1.2752139568328857, Accuracy: 0.626953125\n",
      "Batch: 89, Loss: 1.2957432270050049, Accuracy: 0.59765625\n",
      "Batch: 90, Loss: 1.1609479188919067, Accuracy: 0.60546875\n",
      "Batch: 91, Loss: 1.2107927799224854, Accuracy: 0.615234375\n",
      "Batch: 92, Loss: 1.2430387735366821, Accuracy: 0.58984375\n",
      "Batch: 93, Loss: 1.1607699394226074, Accuracy: 0.6201171875\n",
      "Batch: 94, Loss: 1.1883469820022583, Accuracy: 0.6142578125\n",
      "Batch: 95, Loss: 1.2495499849319458, Accuracy: 0.5947265625\n",
      "Batch: 96, Loss: 1.189735770225525, Accuracy: 0.615234375\n",
      "Batch: 97, Loss: 1.0826963186264038, Accuracy: 0.640625\n",
      "Batch: 98, Loss: 1.118840217590332, Accuracy: 0.65234375\n",
      "Batch: 99, Loss: 1.0917552709579468, Accuracy: 0.634765625\n",
      "Batch: 100, Loss: 1.2058066129684448, Accuracy: 0.615234375\n",
      "Batch: 101, Loss: 1.2589831352233887, Accuracy: 0.5888671875\n",
      "Batch: 102, Loss: 1.154225468635559, Accuracy: 0.619140625\n",
      "Batch: 103, Loss: 1.2578210830688477, Accuracy: 0.6201171875\n",
      "Batch: 104, Loss: 1.1281046867370605, Accuracy: 0.630859375\n",
      "Batch: 105, Loss: 1.2775635719299316, Accuracy: 0.5927734375\n",
      "Batch: 106, Loss: 1.2470276355743408, Accuracy: 0.603515625\n",
      "Batch: 107, Loss: 1.3337788581848145, Accuracy: 0.5791015625\n",
      "Batch: 108, Loss: 1.2959686517715454, Accuracy: 0.576171875\n",
      "Batch: 109, Loss: 1.3929336071014404, Accuracy: 0.5546875\n",
      "Batch: 110, Loss: 1.0632215738296509, Accuracy: 0.640625\n",
      "Batch: 111, Loss: 1.2650790214538574, Accuracy: 0.5556640625\n",
      "Batch: 112, Loss: 1.2134242057800293, Accuracy: 0.6162109375\n",
      "Batch: 113, Loss: 1.2234464883804321, Accuracy: 0.6298828125\n",
      "Batch: 114, Loss: 1.3491514921188354, Accuracy: 0.576171875\n",
      "Batch: 115, Loss: 1.388434886932373, Accuracy: 0.5771484375\n",
      "Batch: 116, Loss: 1.3283369541168213, Accuracy: 0.5595703125\n",
      "Batch: 117, Loss: 1.3093006610870361, Accuracy: 0.595703125\n",
      "Batch: 118, Loss: 1.1042091846466064, Accuracy: 0.658203125\n",
      "Batch: 119, Loss: 1.153712272644043, Accuracy: 0.640625\n",
      "Batch: 120, Loss: 1.2758851051330566, Accuracy: 0.5791015625\n",
      "Batch: 121, Loss: 1.317899227142334, Accuracy: 0.572265625\n",
      "Batch: 122, Loss: 1.1727054119110107, Accuracy: 0.6318359375\n",
      "Batch: 123, Loss: 1.1699612140655518, Accuracy: 0.626953125\n",
      "Batch: 124, Loss: 1.2477209568023682, Accuracy: 0.615234375\n",
      "Batch: 125, Loss: 1.2873468399047852, Accuracy: 0.58203125\n",
      "Batch: 126, Loss: 1.2811750173568726, Accuracy: 0.5791015625\n",
      "Batch: 127, Loss: 1.1189849376678467, Accuracy: 0.6513671875\n",
      "Batch: 128, Loss: 1.34004545211792, Accuracy: 0.591796875\n",
      "Batch: 129, Loss: 1.2048403024673462, Accuracy: 0.6171875\n",
      "Batch: 130, Loss: 1.4396579265594482, Accuracy: 0.560546875\n",
      "Batch: 131, Loss: 1.280322790145874, Accuracy: 0.591796875\n",
      "Batch: 132, Loss: 1.3508304357528687, Accuracy: 0.5791015625\n",
      "Batch: 133, Loss: 1.180582880973816, Accuracy: 0.6123046875\n",
      "Batch: 134, Loss: 1.2256214618682861, Accuracy: 0.6044921875\n",
      "Batch: 135, Loss: 1.1583409309387207, Accuracy: 0.6513671875\n",
      "Batch: 136, Loss: 1.188920259475708, Accuracy: 0.6298828125\n",
      "Batch: 137, Loss: 1.1504452228546143, Accuracy: 0.619140625\n",
      "Batch: 138, Loss: 1.029855728149414, Accuracy: 0.6513671875\n",
      "Batch: 139, Loss: 1.0948333740234375, Accuracy: 0.6220703125\n",
      "Batch: 140, Loss: 1.2272887229919434, Accuracy: 0.5966796875\n",
      "Batch: 141, Loss: 1.2205531597137451, Accuracy: 0.6142578125\n",
      "Batch: 142, Loss: 1.2247495651245117, Accuracy: 0.611328125\n",
      "Batch: 143, Loss: 1.270950436592102, Accuracy: 0.5966796875\n",
      "Batch: 144, Loss: 1.2382962703704834, Accuracy: 0.599609375\n",
      "Batch: 145, Loss: 1.1478328704833984, Accuracy: 0.6005859375\n",
      "Batch: 146, Loss: 1.2687606811523438, Accuracy: 0.5830078125\n",
      "Batch: 147, Loss: 1.2416679859161377, Accuracy: 0.59375\n",
      "Batch: 148, Loss: 1.3428950309753418, Accuracy: 0.5654296875\n",
      "Batch: 149, Loss: 1.2484493255615234, Accuracy: 0.578125\n",
      "Batch: 150, Loss: 1.1497071981430054, Accuracy: 0.62109375\n",
      "Batch: 151, Loss: 1.077099323272705, Accuracy: 0.6572265625\n",
      "Epoch 10/90\n",
      "Batch: 1, Loss: 1.4728825092315674, Accuracy: 0.5185546875\n",
      "Batch: 2, Loss: 1.23729407787323, Accuracy: 0.580078125\n",
      "Batch: 3, Loss: 1.1384994983673096, Accuracy: 0.6162109375\n",
      "Batch: 4, Loss: 1.0700230598449707, Accuracy: 0.65234375\n",
      "Batch: 5, Loss: 1.1028461456298828, Accuracy: 0.6513671875\n",
      "Batch: 6, Loss: 1.22114098072052, Accuracy: 0.5859375\n",
      "Batch: 7, Loss: 1.1464011669158936, Accuracy: 0.6201171875\n",
      "Batch: 8, Loss: 1.139337420463562, Accuracy: 0.6083984375\n",
      "Batch: 9, Loss: 1.0799217224121094, Accuracy: 0.642578125\n",
      "Batch: 10, Loss: 1.0727527141571045, Accuracy: 0.6484375\n",
      "Batch: 11, Loss: 1.3079020977020264, Accuracy: 0.5732421875\n",
      "Batch: 12, Loss: 1.318162202835083, Accuracy: 0.564453125\n",
      "Batch: 13, Loss: 0.9979903101921082, Accuracy: 0.67578125\n",
      "Batch: 14, Loss: 1.286135196685791, Accuracy: 0.5859375\n",
      "Batch: 15, Loss: 1.139756679534912, Accuracy: 0.6591796875\n",
      "Batch: 16, Loss: 1.1372437477111816, Accuracy: 0.634765625\n",
      "Batch: 17, Loss: 1.2431704998016357, Accuracy: 0.5986328125\n",
      "Batch: 18, Loss: 1.2350331544876099, Accuracy: 0.6015625\n",
      "Batch: 19, Loss: 1.3143529891967773, Accuracy: 0.5830078125\n",
      "Batch: 20, Loss: 1.1647138595581055, Accuracy: 0.6328125\n",
      "Batch: 21, Loss: 1.1362462043762207, Accuracy: 0.619140625\n",
      "Batch: 22, Loss: 1.273740291595459, Accuracy: 0.5908203125\n",
      "Batch: 23, Loss: 1.1610291004180908, Accuracy: 0.609375\n",
      "Batch: 24, Loss: 1.1670535802841187, Accuracy: 0.6298828125\n",
      "Batch: 25, Loss: 1.1690537929534912, Accuracy: 0.6201171875\n",
      "Batch: 26, Loss: 1.0757946968078613, Accuracy: 0.654296875\n",
      "Batch: 27, Loss: 1.151647686958313, Accuracy: 0.6123046875\n",
      "Batch: 28, Loss: 1.2310339212417603, Accuracy: 0.5751953125\n",
      "Batch: 29, Loss: 1.224233627319336, Accuracy: 0.6025390625\n",
      "Batch: 30, Loss: 1.171142816543579, Accuracy: 0.6396484375\n",
      "Batch: 31, Loss: 1.1438109874725342, Accuracy: 0.6337890625\n",
      "Batch: 32, Loss: 1.0868263244628906, Accuracy: 0.626953125\n",
      "Batch: 33, Loss: 1.2708455324172974, Accuracy: 0.576171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 34, Loss: 1.3457443714141846, Accuracy: 0.58203125\n",
      "Batch: 35, Loss: 1.2818677425384521, Accuracy: 0.5771484375\n",
      "Batch: 36, Loss: 1.2289327383041382, Accuracy: 0.607421875\n",
      "Batch: 37, Loss: 1.1899281740188599, Accuracy: 0.6123046875\n",
      "Batch: 38, Loss: 1.2112948894500732, Accuracy: 0.611328125\n",
      "Batch: 39, Loss: 1.2352757453918457, Accuracy: 0.6103515625\n",
      "Batch: 40, Loss: 1.2632023096084595, Accuracy: 0.62109375\n",
      "Batch: 41, Loss: 1.2397456169128418, Accuracy: 0.61328125\n",
      "Batch: 42, Loss: 1.0006799697875977, Accuracy: 0.6630859375\n",
      "Batch: 43, Loss: 1.2202894687652588, Accuracy: 0.59375\n",
      "Batch: 44, Loss: 1.1745253801345825, Accuracy: 0.583984375\n",
      "Batch: 45, Loss: 1.0525919198989868, Accuracy: 0.6435546875\n",
      "Batch: 46, Loss: 1.2022989988327026, Accuracy: 0.634765625\n",
      "Batch: 47, Loss: 1.1613953113555908, Accuracy: 0.6416015625\n",
      "Batch: 48, Loss: 1.1281615495681763, Accuracy: 0.6455078125\n",
      "Batch: 49, Loss: 1.3344429731369019, Accuracy: 0.5732421875\n",
      "Batch: 50, Loss: 1.2599868774414062, Accuracy: 0.5927734375\n",
      "Batch: 51, Loss: 1.3409855365753174, Accuracy: 0.56640625\n",
      "Batch: 52, Loss: 1.2979793548583984, Accuracy: 0.587890625\n",
      "Batch: 53, Loss: 1.0508832931518555, Accuracy: 0.65234375\n",
      "Batch: 54, Loss: 1.1621909141540527, Accuracy: 0.63671875\n",
      "Batch: 55, Loss: 1.2264273166656494, Accuracy: 0.6123046875\n",
      "Batch: 56, Loss: 1.2511714696884155, Accuracy: 0.6103515625\n",
      "Batch: 57, Loss: 1.1744863986968994, Accuracy: 0.6357421875\n",
      "Batch: 58, Loss: 1.3012045621871948, Accuracy: 0.5908203125\n",
      "Batch: 59, Loss: 1.0948009490966797, Accuracy: 0.6650390625\n",
      "Batch: 60, Loss: 1.0898150205612183, Accuracy: 0.6494140625\n",
      "Batch: 61, Loss: 1.2099993228912354, Accuracy: 0.61328125\n",
      "Batch: 62, Loss: 1.1783699989318848, Accuracy: 0.62109375\n",
      "Batch: 63, Loss: 1.1748218536376953, Accuracy: 0.6162109375\n",
      "Batch: 64, Loss: 1.1615843772888184, Accuracy: 0.6220703125\n",
      "Batch: 65, Loss: 1.2168450355529785, Accuracy: 0.61328125\n",
      "Batch: 66, Loss: 1.1083214282989502, Accuracy: 0.64453125\n",
      "Batch: 67, Loss: 1.2818665504455566, Accuracy: 0.607421875\n",
      "Batch: 68, Loss: 1.2785019874572754, Accuracy: 0.6201171875\n",
      "Batch: 69, Loss: 1.1884348392486572, Accuracy: 0.6259765625\n",
      "Batch: 70, Loss: 1.2243422269821167, Accuracy: 0.619140625\n",
      "Batch: 71, Loss: 1.221468210220337, Accuracy: 0.6083984375\n",
      "Batch: 72, Loss: 1.0883915424346924, Accuracy: 0.642578125\n",
      "Batch: 73, Loss: 1.1660629510879517, Accuracy: 0.638671875\n",
      "Batch: 74, Loss: 1.125864028930664, Accuracy: 0.6455078125\n",
      "Batch: 75, Loss: 1.0973944664001465, Accuracy: 0.6484375\n",
      "Batch: 76, Loss: 1.2452020645141602, Accuracy: 0.58984375\n",
      "Batch: 77, Loss: 1.1841219663619995, Accuracy: 0.5908203125\n",
      "Batch: 78, Loss: 1.173661708831787, Accuracy: 0.630859375\n",
      "Batch: 79, Loss: 1.0763598680496216, Accuracy: 0.662109375\n",
      "Batch: 80, Loss: 1.117353081703186, Accuracy: 0.6298828125\n",
      "Batch: 81, Loss: 1.2730308771133423, Accuracy: 0.5673828125\n",
      "Batch: 82, Loss: 1.2433550357818604, Accuracy: 0.5966796875\n",
      "Batch: 83, Loss: 1.070607304573059, Accuracy: 0.6572265625\n",
      "Batch: 84, Loss: 1.1265616416931152, Accuracy: 0.6533203125\n",
      "Batch: 85, Loss: 1.071736216545105, Accuracy: 0.6572265625\n",
      "Batch: 86, Loss: 1.3311468362808228, Accuracy: 0.5849609375\n",
      "Batch: 87, Loss: 1.1013665199279785, Accuracy: 0.6748046875\n",
      "Batch: 88, Loss: 1.240157127380371, Accuracy: 0.625\n",
      "Batch: 89, Loss: 1.2598214149475098, Accuracy: 0.6064453125\n",
      "Batch: 90, Loss: 1.1051437854766846, Accuracy: 0.640625\n",
      "Batch: 91, Loss: 1.1900205612182617, Accuracy: 0.6162109375\n",
      "Batch: 92, Loss: 1.2046388387680054, Accuracy: 0.60546875\n",
      "Batch: 93, Loss: 1.1249876022338867, Accuracy: 0.642578125\n",
      "Batch: 94, Loss: 1.1312049627304077, Accuracy: 0.6484375\n",
      "Batch: 95, Loss: 1.196838140487671, Accuracy: 0.623046875\n",
      "Batch: 96, Loss: 1.1763293743133545, Accuracy: 0.6181640625\n",
      "Batch: 97, Loss: 1.0412044525146484, Accuracy: 0.6611328125\n",
      "Batch: 98, Loss: 1.0880358219146729, Accuracy: 0.6513671875\n",
      "Batch: 99, Loss: 1.0568132400512695, Accuracy: 0.6591796875\n",
      "Batch: 100, Loss: 1.1540621519088745, Accuracy: 0.6259765625\n",
      "Batch: 101, Loss: 1.2236576080322266, Accuracy: 0.6025390625\n",
      "Batch: 102, Loss: 1.1090439558029175, Accuracy: 0.6435546875\n",
      "Batch: 103, Loss: 1.2280466556549072, Accuracy: 0.62109375\n",
      "Batch: 104, Loss: 1.086064338684082, Accuracy: 0.642578125\n",
      "Batch: 105, Loss: 1.210641622543335, Accuracy: 0.619140625\n",
      "Batch: 106, Loss: 1.190474510192871, Accuracy: 0.619140625\n",
      "Batch: 107, Loss: 1.2756614685058594, Accuracy: 0.5927734375\n",
      "Batch: 108, Loss: 1.223929524421692, Accuracy: 0.591796875\n",
      "Batch: 109, Loss: 1.3353195190429688, Accuracy: 0.56640625\n",
      "Batch: 110, Loss: 1.0218037366867065, Accuracy: 0.6650390625\n",
      "Batch: 111, Loss: 1.260453462600708, Accuracy: 0.5791015625\n",
      "Batch: 112, Loss: 1.1696231365203857, Accuracy: 0.6318359375\n",
      "Batch: 113, Loss: 1.1710855960845947, Accuracy: 0.638671875\n",
      "Batch: 114, Loss: 1.3133554458618164, Accuracy: 0.5830078125\n",
      "Batch: 115, Loss: 1.3506121635437012, Accuracy: 0.595703125\n",
      "Batch: 116, Loss: 1.2947217226028442, Accuracy: 0.5849609375\n",
      "Batch: 117, Loss: 1.247499942779541, Accuracy: 0.607421875\n",
      "Batch: 118, Loss: 1.038275957107544, Accuracy: 0.669921875\n",
      "Batch: 119, Loss: 1.0817861557006836, Accuracy: 0.666015625\n",
      "Batch: 120, Loss: 1.2299973964691162, Accuracy: 0.59375\n",
      "Batch: 121, Loss: 1.264432668685913, Accuracy: 0.6064453125\n",
      "Batch: 122, Loss: 1.14870285987854, Accuracy: 0.6474609375\n",
      "Batch: 123, Loss: 1.1342346668243408, Accuracy: 0.630859375\n",
      "Batch: 124, Loss: 1.206146478652954, Accuracy: 0.626953125\n",
      "Batch: 125, Loss: 1.241055965423584, Accuracy: 0.5927734375\n",
      "Batch: 126, Loss: 1.2188628911972046, Accuracy: 0.5986328125\n",
      "Batch: 127, Loss: 1.093113899230957, Accuracy: 0.66015625\n",
      "Batch: 128, Loss: 1.32492995262146, Accuracy: 0.578125\n",
      "Batch: 129, Loss: 1.1644160747528076, Accuracy: 0.6240234375\n",
      "Batch: 130, Loss: 1.3806989192962646, Accuracy: 0.568359375\n",
      "Batch: 131, Loss: 1.246946096420288, Accuracy: 0.6025390625\n",
      "Batch: 132, Loss: 1.283712387084961, Accuracy: 0.5947265625\n",
      "Batch: 133, Loss: 1.1462063789367676, Accuracy: 0.6318359375\n",
      "Batch: 134, Loss: 1.1912014484405518, Accuracy: 0.623046875\n",
      "Batch: 135, Loss: 1.1176674365997314, Accuracy: 0.646484375\n",
      "Batch: 136, Loss: 1.1712067127227783, Accuracy: 0.62890625\n",
      "Batch: 137, Loss: 1.0926101207733154, Accuracy: 0.638671875\n",
      "Batch: 138, Loss: 0.981818437576294, Accuracy: 0.6650390625\n",
      "Batch: 139, Loss: 1.05525541305542, Accuracy: 0.6484375\n",
      "Batch: 140, Loss: 1.1804518699645996, Accuracy: 0.62109375\n",
      "Batch: 141, Loss: 1.1782920360565186, Accuracy: 0.6064453125\n",
      "Batch: 142, Loss: 1.2105555534362793, Accuracy: 0.6123046875\n",
      "Batch: 143, Loss: 1.2098631858825684, Accuracy: 0.607421875\n",
      "Batch: 144, Loss: 1.1685141324996948, Accuracy: 0.634765625\n",
      "Batch: 145, Loss: 1.1154813766479492, Accuracy: 0.619140625\n",
      "Batch: 146, Loss: 1.2441415786743164, Accuracy: 0.591796875\n",
      "Batch: 147, Loss: 1.189342975616455, Accuracy: 0.625\n",
      "Batch: 148, Loss: 1.3095674514770508, Accuracy: 0.5615234375\n",
      "Batch: 149, Loss: 1.2028230428695679, Accuracy: 0.59765625\n",
      "Batch: 150, Loss: 1.1175854206085205, Accuracy: 0.6318359375\n",
      "Batch: 151, Loss: 1.0526102781295776, Accuracy: 0.6533203125\n",
      "Saved Weights at epoch 10 to file Weights_10.h5\n",
      "Epoch 11/90\n",
      "Batch: 1, Loss: 1.4466607570648193, Accuracy: 0.5498046875\n",
      "Batch: 2, Loss: 1.2225546836853027, Accuracy: 0.576171875\n",
      "Batch: 3, Loss: 1.1085275411605835, Accuracy: 0.6279296875\n",
      "Batch: 4, Loss: 1.0399820804595947, Accuracy: 0.6748046875\n",
      "Batch: 5, Loss: 1.0623668432235718, Accuracy: 0.6689453125\n",
      "Batch: 6, Loss: 1.1597709655761719, Accuracy: 0.6279296875\n",
      "Batch: 7, Loss: 1.102871060371399, Accuracy: 0.6357421875\n",
      "Batch: 8, Loss: 1.0781221389770508, Accuracy: 0.638671875\n",
      "Batch: 9, Loss: 1.033035159111023, Accuracy: 0.669921875\n",
      "Batch: 10, Loss: 1.0485451221466064, Accuracy: 0.650390625\n",
      "Batch: 11, Loss: 1.2697117328643799, Accuracy: 0.576171875\n",
      "Batch: 12, Loss: 1.2804652452468872, Accuracy: 0.5888671875\n",
      "Batch: 13, Loss: 0.9787304401397705, Accuracy: 0.6669921875\n",
      "Batch: 14, Loss: 1.2082313299179077, Accuracy: 0.607421875\n",
      "Batch: 15, Loss: 1.1050913333892822, Accuracy: 0.654296875\n",
      "Batch: 16, Loss: 1.0927155017852783, Accuracy: 0.6552734375\n",
      "Batch: 17, Loss: 1.193892002105713, Accuracy: 0.60546875\n",
      "Batch: 18, Loss: 1.1811808347702026, Accuracy: 0.6162109375\n",
      "Batch: 19, Loss: 1.278296709060669, Accuracy: 0.591796875\n",
      "Batch: 20, Loss: 1.1119396686553955, Accuracy: 0.642578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 21, Loss: 1.1047359704971313, Accuracy: 0.6337890625\n",
      "Batch: 22, Loss: 1.2249596118927002, Accuracy: 0.619140625\n",
      "Batch: 23, Loss: 1.1267684698104858, Accuracy: 0.626953125\n",
      "Batch: 24, Loss: 1.1556177139282227, Accuracy: 0.6162109375\n",
      "Batch: 25, Loss: 1.1345473527908325, Accuracy: 0.6181640625\n",
      "Batch: 26, Loss: 1.0362883806228638, Accuracy: 0.6669921875\n",
      "Batch: 27, Loss: 1.1103630065917969, Accuracy: 0.6171875\n",
      "Batch: 28, Loss: 1.1962841749191284, Accuracy: 0.5986328125\n",
      "Batch: 29, Loss: 1.188065767288208, Accuracy: 0.6103515625\n",
      "Batch: 30, Loss: 1.1241203546524048, Accuracy: 0.6572265625\n",
      "Batch: 31, Loss: 1.1048706769943237, Accuracy: 0.66015625\n",
      "Batch: 32, Loss: 1.0610947608947754, Accuracy: 0.640625\n",
      "Batch: 33, Loss: 1.232133150100708, Accuracy: 0.5986328125\n",
      "Batch: 34, Loss: 1.323380470275879, Accuracy: 0.5830078125\n",
      "Batch: 35, Loss: 1.1993465423583984, Accuracy: 0.6142578125\n",
      "Batch: 36, Loss: 1.1984658241271973, Accuracy: 0.626953125\n",
      "Batch: 37, Loss: 1.1555535793304443, Accuracy: 0.62109375\n",
      "Batch: 38, Loss: 1.1671013832092285, Accuracy: 0.623046875\n",
      "Batch: 39, Loss: 1.2368965148925781, Accuracy: 0.61328125\n",
      "Batch: 40, Loss: 1.2379207611083984, Accuracy: 0.626953125\n",
      "Batch: 41, Loss: 1.1924042701721191, Accuracy: 0.63671875\n",
      "Batch: 42, Loss: 0.9594302177429199, Accuracy: 0.67578125\n",
      "Batch: 43, Loss: 1.1880717277526855, Accuracy: 0.587890625\n",
      "Batch: 44, Loss: 1.1471235752105713, Accuracy: 0.599609375\n",
      "Batch: 45, Loss: 1.0187216997146606, Accuracy: 0.66015625\n",
      "Batch: 46, Loss: 1.1562445163726807, Accuracy: 0.6474609375\n",
      "Batch: 47, Loss: 1.118976354598999, Accuracy: 0.6630859375\n",
      "Batch: 48, Loss: 1.0661475658416748, Accuracy: 0.6552734375\n",
      "Batch: 49, Loss: 1.262965202331543, Accuracy: 0.6025390625\n",
      "Batch: 50, Loss: 1.2120754718780518, Accuracy: 0.6005859375\n",
      "Batch: 51, Loss: 1.302180290222168, Accuracy: 0.5869140625\n",
      "Batch: 52, Loss: 1.2452023029327393, Accuracy: 0.607421875\n",
      "Batch: 53, Loss: 1.0320119857788086, Accuracy: 0.65234375\n",
      "Batch: 54, Loss: 1.1325490474700928, Accuracy: 0.6533203125\n",
      "Batch: 55, Loss: 1.1897940635681152, Accuracy: 0.603515625\n",
      "Batch: 56, Loss: 1.2095417976379395, Accuracy: 0.6298828125\n",
      "Batch: 57, Loss: 1.1309022903442383, Accuracy: 0.640625\n",
      "Batch: 58, Loss: 1.2401477098464966, Accuracy: 0.615234375\n",
      "Batch: 59, Loss: 1.0643789768218994, Accuracy: 0.677734375\n",
      "Batch: 60, Loss: 1.0597074031829834, Accuracy: 0.6552734375\n",
      "Batch: 61, Loss: 1.153177261352539, Accuracy: 0.62890625\n",
      "Batch: 62, Loss: 1.1267938613891602, Accuracy: 0.646484375\n",
      "Batch: 63, Loss: 1.1411538124084473, Accuracy: 0.6376953125\n",
      "Batch: 64, Loss: 1.1291248798370361, Accuracy: 0.6328125\n",
      "Batch: 65, Loss: 1.1437463760375977, Accuracy: 0.6484375\n",
      "Batch: 66, Loss: 1.1019946336746216, Accuracy: 0.6650390625\n",
      "Batch: 67, Loss: 1.2446353435516357, Accuracy: 0.61328125\n",
      "Batch: 68, Loss: 1.2621428966522217, Accuracy: 0.6142578125\n",
      "Batch: 69, Loss: 1.1815571784973145, Accuracy: 0.6171875\n",
      "Batch: 70, Loss: 1.1457723379135132, Accuracy: 0.6435546875\n",
      "Batch: 71, Loss: 1.1879690885543823, Accuracy: 0.6259765625\n",
      "Batch: 72, Loss: 1.050180435180664, Accuracy: 0.6513671875\n",
      "Batch: 73, Loss: 1.1443898677825928, Accuracy: 0.62890625\n",
      "Batch: 74, Loss: 1.0798711776733398, Accuracy: 0.6513671875\n",
      "Batch: 75, Loss: 1.0456809997558594, Accuracy: 0.6669921875\n",
      "Batch: 76, Loss: 1.1982595920562744, Accuracy: 0.599609375\n",
      "Batch: 77, Loss: 1.1385948657989502, Accuracy: 0.6162109375\n",
      "Batch: 78, Loss: 1.1338343620300293, Accuracy: 0.6416015625\n",
      "Batch: 79, Loss: 1.052774429321289, Accuracy: 0.68359375\n",
      "Batch: 80, Loss: 1.0817303657531738, Accuracy: 0.6337890625\n",
      "Batch: 81, Loss: 1.224771499633789, Accuracy: 0.576171875\n",
      "Batch: 82, Loss: 1.1856558322906494, Accuracy: 0.6181640625\n",
      "Batch: 83, Loss: 1.0292609930038452, Accuracy: 0.6728515625\n",
      "Batch: 84, Loss: 1.0982831716537476, Accuracy: 0.6708984375\n",
      "Batch: 85, Loss: 1.03032386302948, Accuracy: 0.666015625\n",
      "Batch: 86, Loss: 1.2756692171096802, Accuracy: 0.5908203125\n",
      "Batch: 87, Loss: 1.0666251182556152, Accuracy: 0.6650390625\n",
      "Batch: 88, Loss: 1.2130622863769531, Accuracy: 0.638671875\n",
      "Batch: 89, Loss: 1.2104854583740234, Accuracy: 0.6298828125\n",
      "Batch: 90, Loss: 1.0953412055969238, Accuracy: 0.6552734375\n",
      "Batch: 91, Loss: 1.1441216468811035, Accuracy: 0.6357421875\n",
      "Batch: 92, Loss: 1.1302025318145752, Accuracy: 0.630859375\n",
      "Batch: 93, Loss: 1.0793124437332153, Accuracy: 0.65234375\n",
      "Batch: 94, Loss: 1.086164951324463, Accuracy: 0.650390625\n",
      "Batch: 95, Loss: 1.172931432723999, Accuracy: 0.6142578125\n",
      "Batch: 96, Loss: 1.1450908184051514, Accuracy: 0.6435546875\n",
      "Batch: 97, Loss: 1.0183093547821045, Accuracy: 0.65625\n",
      "Batch: 98, Loss: 1.0415751934051514, Accuracy: 0.669921875\n",
      "Batch: 99, Loss: 1.044496774673462, Accuracy: 0.654296875\n",
      "Batch: 100, Loss: 1.1097545623779297, Accuracy: 0.6455078125\n",
      "Batch: 101, Loss: 1.189297080039978, Accuracy: 0.6123046875\n",
      "Batch: 102, Loss: 1.0781424045562744, Accuracy: 0.6435546875\n",
      "Batch: 103, Loss: 1.176470398902893, Accuracy: 0.6376953125\n",
      "Batch: 104, Loss: 1.04715096950531, Accuracy: 0.6552734375\n",
      "Batch: 105, Loss: 1.1667029857635498, Accuracy: 0.6103515625\n",
      "Batch: 106, Loss: 1.1390658617019653, Accuracy: 0.6376953125\n",
      "Batch: 107, Loss: 1.2127697467803955, Accuracy: 0.6162109375\n",
      "Batch: 108, Loss: 1.1620079278945923, Accuracy: 0.611328125\n",
      "Batch: 109, Loss: 1.314278244972229, Accuracy: 0.576171875\n",
      "Batch: 110, Loss: 0.9973872900009155, Accuracy: 0.669921875\n",
      "Batch: 111, Loss: 1.2328689098358154, Accuracy: 0.5830078125\n",
      "Batch: 112, Loss: 1.1337251663208008, Accuracy: 0.642578125\n",
      "Batch: 113, Loss: 1.1468706130981445, Accuracy: 0.6533203125\n",
      "Batch: 114, Loss: 1.2837285995483398, Accuracy: 0.5908203125\n",
      "Batch: 115, Loss: 1.3110153675079346, Accuracy: 0.5966796875\n",
      "Batch: 116, Loss: 1.2447082996368408, Accuracy: 0.5927734375\n",
      "Batch: 117, Loss: 1.2382806539535522, Accuracy: 0.6083984375\n",
      "Batch: 118, Loss: 1.029111385345459, Accuracy: 0.6806640625\n",
      "Batch: 119, Loss: 1.0529571771621704, Accuracy: 0.666015625\n",
      "Batch: 120, Loss: 1.2205617427825928, Accuracy: 0.599609375\n",
      "Batch: 121, Loss: 1.2237471342086792, Accuracy: 0.6123046875\n",
      "Batch: 122, Loss: 1.117203950881958, Accuracy: 0.65234375\n",
      "Batch: 123, Loss: 1.1074471473693848, Accuracy: 0.64453125\n",
      "Batch: 124, Loss: 1.1848827600479126, Accuracy: 0.6181640625\n",
      "Batch: 125, Loss: 1.2121193408966064, Accuracy: 0.6103515625\n",
      "Batch: 126, Loss: 1.193080186843872, Accuracy: 0.625\n",
      "Batch: 127, Loss: 1.0525634288787842, Accuracy: 0.669921875\n",
      "Batch: 128, Loss: 1.2741143703460693, Accuracy: 0.59375\n",
      "Batch: 129, Loss: 1.1120026111602783, Accuracy: 0.6474609375\n",
      "Batch: 130, Loss: 1.3384370803833008, Accuracy: 0.56640625\n",
      "Batch: 131, Loss: 1.2230123281478882, Accuracy: 0.6005859375\n",
      "Batch: 132, Loss: 1.2543034553527832, Accuracy: 0.6025390625\n",
      "Batch: 133, Loss: 1.099514365196228, Accuracy: 0.634765625\n",
      "Batch: 134, Loss: 1.1533489227294922, Accuracy: 0.619140625\n",
      "Batch: 135, Loss: 1.0732331275939941, Accuracy: 0.6552734375\n",
      "Batch: 136, Loss: 1.1258494853973389, Accuracy: 0.6357421875\n",
      "Batch: 137, Loss: 1.079742431640625, Accuracy: 0.6337890625\n",
      "Batch: 138, Loss: 0.9464021921157837, Accuracy: 0.681640625\n",
      "Batch: 139, Loss: 1.0422983169555664, Accuracy: 0.654296875\n",
      "Batch: 140, Loss: 1.131622552871704, Accuracy: 0.63671875\n",
      "Batch: 141, Loss: 1.162866234779358, Accuracy: 0.62890625\n",
      "Batch: 142, Loss: 1.166304588317871, Accuracy: 0.615234375\n",
      "Batch: 143, Loss: 1.1667319536209106, Accuracy: 0.6240234375\n",
      "Batch: 144, Loss: 1.1449353694915771, Accuracy: 0.638671875\n",
      "Batch: 145, Loss: 1.0681040287017822, Accuracy: 0.6318359375\n",
      "Batch: 146, Loss: 1.1917991638183594, Accuracy: 0.623046875\n",
      "Batch: 147, Loss: 1.1537659168243408, Accuracy: 0.630859375\n",
      "Batch: 148, Loss: 1.278237223625183, Accuracy: 0.5791015625\n",
      "Batch: 149, Loss: 1.1509277820587158, Accuracy: 0.6083984375\n",
      "Batch: 150, Loss: 1.0926928520202637, Accuracy: 0.6337890625\n",
      "Batch: 151, Loss: 0.9936079978942871, Accuracy: 0.6767578125\n",
      "Epoch 12/90\n",
      "Batch: 1, Loss: 1.3789241313934326, Accuracy: 0.5634765625\n",
      "Batch: 2, Loss: 1.171207308769226, Accuracy: 0.60546875\n",
      "Batch: 3, Loss: 1.0816975831985474, Accuracy: 0.6337890625\n",
      "Batch: 4, Loss: 0.9970285892486572, Accuracy: 0.677734375\n",
      "Batch: 5, Loss: 1.0212128162384033, Accuracy: 0.681640625\n",
      "Batch: 6, Loss: 1.1448321342468262, Accuracy: 0.6328125\n",
      "Batch: 7, Loss: 1.0766072273254395, Accuracy: 0.634765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 8, Loss: 1.0413613319396973, Accuracy: 0.6416015625\n",
      "Batch: 9, Loss: 1.013985514640808, Accuracy: 0.6796875\n",
      "Batch: 10, Loss: 1.0179500579833984, Accuracy: 0.6650390625\n",
      "Batch: 11, Loss: 1.2242913246154785, Accuracy: 0.599609375\n",
      "Batch: 12, Loss: 1.2565861940383911, Accuracy: 0.5859375\n",
      "Batch: 13, Loss: 0.9340919256210327, Accuracy: 0.685546875\n",
      "Batch: 14, Loss: 1.194854497909546, Accuracy: 0.60546875\n",
      "Batch: 15, Loss: 1.0587265491485596, Accuracy: 0.677734375\n",
      "Batch: 16, Loss: 1.0652190446853638, Accuracy: 0.6708984375\n",
      "Batch: 17, Loss: 1.1780178546905518, Accuracy: 0.62109375\n",
      "Batch: 18, Loss: 1.130711555480957, Accuracy: 0.642578125\n",
      "Batch: 19, Loss: 1.234768271446228, Accuracy: 0.6015625\n",
      "Batch: 20, Loss: 1.080074429512024, Accuracy: 0.65234375\n",
      "Batch: 21, Loss: 1.0590882301330566, Accuracy: 0.6533203125\n",
      "Batch: 22, Loss: 1.2041168212890625, Accuracy: 0.625\n",
      "Batch: 23, Loss: 1.103368878364563, Accuracy: 0.6376953125\n",
      "Batch: 24, Loss: 1.097555160522461, Accuracy: 0.6357421875\n",
      "Batch: 25, Loss: 1.1019790172576904, Accuracy: 0.640625\n",
      "Batch: 26, Loss: 1.0103586912155151, Accuracy: 0.669921875\n",
      "Batch: 27, Loss: 1.073734998703003, Accuracy: 0.6318359375\n",
      "Batch: 28, Loss: 1.1638127565383911, Accuracy: 0.5966796875\n",
      "Batch: 29, Loss: 1.1614084243774414, Accuracy: 0.6162109375\n",
      "Batch: 30, Loss: 1.0911777019500732, Accuracy: 0.6650390625\n",
      "Batch: 31, Loss: 1.0529744625091553, Accuracy: 0.677734375\n",
      "Batch: 32, Loss: 1.016388177871704, Accuracy: 0.6572265625\n",
      "Batch: 33, Loss: 1.2054665088653564, Accuracy: 0.6083984375\n",
      "Batch: 34, Loss: 1.275607943534851, Accuracy: 0.5927734375\n",
      "Batch: 35, Loss: 1.1682835817337036, Accuracy: 0.6357421875\n",
      "Batch: 36, Loss: 1.1575536727905273, Accuracy: 0.62890625\n",
      "Batch: 37, Loss: 1.1140854358673096, Accuracy: 0.6318359375\n",
      "Batch: 38, Loss: 1.1418781280517578, Accuracy: 0.6259765625\n",
      "Batch: 39, Loss: 1.1812553405761719, Accuracy: 0.6328125\n",
      "Batch: 40, Loss: 1.1922112703323364, Accuracy: 0.62890625\n",
      "Batch: 41, Loss: 1.135942816734314, Accuracy: 0.6552734375\n",
      "Batch: 42, Loss: 0.9394285678863525, Accuracy: 0.677734375\n",
      "Batch: 43, Loss: 1.1603596210479736, Accuracy: 0.625\n",
      "Batch: 44, Loss: 1.1286404132843018, Accuracy: 0.6103515625\n",
      "Batch: 45, Loss: 1.0024679899215698, Accuracy: 0.669921875\n",
      "Batch: 46, Loss: 1.0923480987548828, Accuracy: 0.662109375\n",
      "Batch: 47, Loss: 1.0913543701171875, Accuracy: 0.6650390625\n",
      "Batch: 48, Loss: 1.0324400663375854, Accuracy: 0.6611328125\n",
      "Batch: 49, Loss: 1.2310549020767212, Accuracy: 0.5927734375\n",
      "Batch: 50, Loss: 1.187943696975708, Accuracy: 0.6142578125\n",
      "Batch: 51, Loss: 1.274329423904419, Accuracy: 0.5859375\n",
      "Batch: 52, Loss: 1.2099435329437256, Accuracy: 0.6220703125\n",
      "Batch: 53, Loss: 1.0238544940948486, Accuracy: 0.666015625\n",
      "Batch: 54, Loss: 1.0960969924926758, Accuracy: 0.6455078125\n",
      "Batch: 55, Loss: 1.144827127456665, Accuracy: 0.6015625\n",
      "Batch: 56, Loss: 1.1626873016357422, Accuracy: 0.6416015625\n",
      "Batch: 57, Loss: 1.1046953201293945, Accuracy: 0.646484375\n",
      "Batch: 58, Loss: 1.220914602279663, Accuracy: 0.6240234375\n",
      "Batch: 59, Loss: 1.0393056869506836, Accuracy: 0.6904296875\n",
      "Batch: 60, Loss: 1.0158921480178833, Accuracy: 0.6650390625\n",
      "Batch: 61, Loss: 1.1416456699371338, Accuracy: 0.640625\n",
      "Batch: 62, Loss: 1.1182341575622559, Accuracy: 0.6435546875\n",
      "Batch: 63, Loss: 1.1123881340026855, Accuracy: 0.638671875\n",
      "Batch: 64, Loss: 1.0934386253356934, Accuracy: 0.6455078125\n",
      "Batch: 65, Loss: 1.122922658920288, Accuracy: 0.66015625\n",
      "Batch: 66, Loss: 1.064815878868103, Accuracy: 0.6640625\n",
      "Batch: 67, Loss: 1.2258193492889404, Accuracy: 0.6220703125\n",
      "Batch: 68, Loss: 1.252450942993164, Accuracy: 0.6240234375\n",
      "Batch: 69, Loss: 1.1416659355163574, Accuracy: 0.6328125\n",
      "Batch: 70, Loss: 1.1197044849395752, Accuracy: 0.658203125\n",
      "Batch: 71, Loss: 1.169647455215454, Accuracy: 0.6279296875\n",
      "Batch: 72, Loss: 1.027854561805725, Accuracy: 0.671875\n",
      "Batch: 73, Loss: 1.108818531036377, Accuracy: 0.650390625\n",
      "Batch: 74, Loss: 1.073191523551941, Accuracy: 0.673828125\n",
      "Batch: 75, Loss: 0.9923503398895264, Accuracy: 0.681640625\n",
      "Batch: 76, Loss: 1.1585584878921509, Accuracy: 0.6220703125\n",
      "Batch: 77, Loss: 1.0885339975357056, Accuracy: 0.6484375\n",
      "Batch: 78, Loss: 1.1056632995605469, Accuracy: 0.6416015625\n",
      "Batch: 79, Loss: 1.0006463527679443, Accuracy: 0.6923828125\n",
      "Batch: 80, Loss: 1.061915397644043, Accuracy: 0.64453125\n",
      "Batch: 81, Loss: 1.1939958333969116, Accuracy: 0.5791015625\n",
      "Batch: 82, Loss: 1.1441360712051392, Accuracy: 0.6279296875\n",
      "Batch: 83, Loss: 1.011870265007019, Accuracy: 0.67578125\n",
      "Batch: 84, Loss: 1.0746383666992188, Accuracy: 0.6728515625\n",
      "Batch: 85, Loss: 0.9957530498504639, Accuracy: 0.693359375\n",
      "Batch: 86, Loss: 1.2707403898239136, Accuracy: 0.59765625\n",
      "Batch: 87, Loss: 1.0252883434295654, Accuracy: 0.689453125\n",
      "Batch: 88, Loss: 1.1622393131256104, Accuracy: 0.634765625\n",
      "Batch: 89, Loss: 1.1773275136947632, Accuracy: 0.6357421875\n",
      "Batch: 90, Loss: 1.0718917846679688, Accuracy: 0.666015625\n",
      "Batch: 91, Loss: 1.1003090143203735, Accuracy: 0.6572265625\n",
      "Batch: 92, Loss: 1.0936870574951172, Accuracy: 0.6455078125\n",
      "Batch: 93, Loss: 1.0646896362304688, Accuracy: 0.662109375\n",
      "Batch: 94, Loss: 1.0454061031341553, Accuracy: 0.66015625\n",
      "Batch: 95, Loss: 1.1202540397644043, Accuracy: 0.630859375\n",
      "Batch: 96, Loss: 1.095139980316162, Accuracy: 0.666015625\n",
      "Batch: 97, Loss: 0.9909106492996216, Accuracy: 0.673828125\n",
      "Batch: 98, Loss: 1.0195574760437012, Accuracy: 0.673828125\n",
      "Batch: 99, Loss: 0.9923897385597229, Accuracy: 0.6865234375\n",
      "Batch: 100, Loss: 1.0662081241607666, Accuracy: 0.65234375\n",
      "Batch: 101, Loss: 1.152250051498413, Accuracy: 0.6240234375\n",
      "Batch: 102, Loss: 1.0638113021850586, Accuracy: 0.64453125\n",
      "Batch: 103, Loss: 1.1586647033691406, Accuracy: 0.65234375\n",
      "Batch: 104, Loss: 1.0182222127914429, Accuracy: 0.6689453125\n",
      "Batch: 105, Loss: 1.1302440166473389, Accuracy: 0.6259765625\n",
      "Batch: 106, Loss: 1.1261489391326904, Accuracy: 0.6357421875\n",
      "Batch: 107, Loss: 1.174940586090088, Accuracy: 0.62109375\n",
      "Batch: 108, Loss: 1.1439173221588135, Accuracy: 0.642578125\n",
      "Batch: 109, Loss: 1.2632005214691162, Accuracy: 0.5859375\n",
      "Batch: 110, Loss: 0.9604426026344299, Accuracy: 0.6787109375\n",
      "Batch: 111, Loss: 1.1757335662841797, Accuracy: 0.591796875\n",
      "Batch: 112, Loss: 1.1115095615386963, Accuracy: 0.6513671875\n",
      "Batch: 113, Loss: 1.10756254196167, Accuracy: 0.65234375\n",
      "Batch: 114, Loss: 1.227937936782837, Accuracy: 0.609375\n",
      "Batch: 115, Loss: 1.2563807964324951, Accuracy: 0.623046875\n",
      "Batch: 116, Loss: 1.2005411386489868, Accuracy: 0.6201171875\n",
      "Batch: 117, Loss: 1.1737390756607056, Accuracy: 0.6318359375\n",
      "Batch: 118, Loss: 0.9922087788581848, Accuracy: 0.6767578125\n",
      "Batch: 119, Loss: 1.0330827236175537, Accuracy: 0.6845703125\n",
      "Batch: 120, Loss: 1.1989784240722656, Accuracy: 0.611328125\n",
      "Batch: 121, Loss: 1.1809160709381104, Accuracy: 0.6171875\n",
      "Batch: 122, Loss: 1.0808823108673096, Accuracy: 0.646484375\n",
      "Batch: 123, Loss: 1.0643000602722168, Accuracy: 0.666015625\n",
      "Batch: 124, Loss: 1.1345669031143188, Accuracy: 0.640625\n",
      "Batch: 125, Loss: 1.1729681491851807, Accuracy: 0.6171875\n",
      "Batch: 126, Loss: 1.1406232118606567, Accuracy: 0.626953125\n",
      "Batch: 127, Loss: 1.0523183345794678, Accuracy: 0.671875\n",
      "Batch: 128, Loss: 1.2595763206481934, Accuracy: 0.6171875\n",
      "Batch: 129, Loss: 1.064453363418579, Accuracy: 0.6630859375\n",
      "Batch: 130, Loss: 1.2966639995574951, Accuracy: 0.5947265625\n",
      "Batch: 131, Loss: 1.175687313079834, Accuracy: 0.6240234375\n",
      "Batch: 132, Loss: 1.2013132572174072, Accuracy: 0.611328125\n",
      "Batch: 133, Loss: 1.0623325109481812, Accuracy: 0.65234375\n",
      "Batch: 134, Loss: 1.1362072229385376, Accuracy: 0.6279296875\n",
      "Batch: 135, Loss: 1.0394659042358398, Accuracy: 0.6650390625\n",
      "Batch: 136, Loss: 1.0863194465637207, Accuracy: 0.64453125\n",
      "Batch: 137, Loss: 1.0423121452331543, Accuracy: 0.65234375\n",
      "Batch: 138, Loss: 0.923085629940033, Accuracy: 0.6845703125\n",
      "Batch: 139, Loss: 0.9835053086280823, Accuracy: 0.673828125\n",
      "Batch: 140, Loss: 1.121306300163269, Accuracy: 0.6318359375\n",
      "Batch: 141, Loss: 1.1390451192855835, Accuracy: 0.640625\n",
      "Batch: 142, Loss: 1.1492773294448853, Accuracy: 0.625\n",
      "Batch: 143, Loss: 1.1377196311950684, Accuracy: 0.6162109375\n",
      "Batch: 144, Loss: 1.1097235679626465, Accuracy: 0.6416015625\n",
      "Batch: 145, Loss: 1.0464280843734741, Accuracy: 0.6328125\n",
      "Batch: 146, Loss: 1.159290075302124, Accuracy: 0.6240234375\n",
      "Batch: 147, Loss: 1.1248583793640137, Accuracy: 0.6376953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 148, Loss: 1.233903169631958, Accuracy: 0.595703125\n",
      "Batch: 149, Loss: 1.0841946601867676, Accuracy: 0.6484375\n",
      "Batch: 150, Loss: 1.035994052886963, Accuracy: 0.6611328125\n",
      "Batch: 151, Loss: 0.949373722076416, Accuracy: 0.69921875\n",
      "Epoch 13/90\n",
      "Batch: 1, Loss: 1.3559666872024536, Accuracy: 0.5712890625\n",
      "Batch: 2, Loss: 1.176220178604126, Accuracy: 0.58984375\n",
      "Batch: 3, Loss: 1.0431088209152222, Accuracy: 0.6494140625\n",
      "Batch: 4, Loss: 0.9709852933883667, Accuracy: 0.6806640625\n",
      "Batch: 5, Loss: 0.9770073890686035, Accuracy: 0.677734375\n",
      "Batch: 6, Loss: 1.112414836883545, Accuracy: 0.64453125\n",
      "Batch: 7, Loss: 1.0603845119476318, Accuracy: 0.6484375\n",
      "Batch: 8, Loss: 0.9874168634414673, Accuracy: 0.681640625\n",
      "Batch: 9, Loss: 0.9816666841506958, Accuracy: 0.6875\n",
      "Batch: 10, Loss: 0.9917927980422974, Accuracy: 0.6728515625\n",
      "Batch: 11, Loss: 1.2070372104644775, Accuracy: 0.5869140625\n",
      "Batch: 12, Loss: 1.2092158794403076, Accuracy: 0.61328125\n",
      "Batch: 13, Loss: 0.8939383625984192, Accuracy: 0.697265625\n",
      "Batch: 14, Loss: 1.166782259941101, Accuracy: 0.6162109375\n",
      "Batch: 15, Loss: 1.0118054151535034, Accuracy: 0.689453125\n",
      "Batch: 16, Loss: 1.0340402126312256, Accuracy: 0.6728515625\n",
      "Batch: 17, Loss: 1.116804599761963, Accuracy: 0.64453125\n",
      "Batch: 18, Loss: 1.1214255094528198, Accuracy: 0.634765625\n",
      "Batch: 19, Loss: 1.1709203720092773, Accuracy: 0.6298828125\n",
      "Batch: 20, Loss: 1.01346755027771, Accuracy: 0.6748046875\n",
      "Batch: 21, Loss: 1.0011422634124756, Accuracy: 0.6728515625\n",
      "Batch: 22, Loss: 1.1499242782592773, Accuracy: 0.6376953125\n",
      "Batch: 23, Loss: 1.0640203952789307, Accuracy: 0.6630859375\n",
      "Batch: 24, Loss: 1.0724352598190308, Accuracy: 0.6337890625\n",
      "Batch: 25, Loss: 1.0747876167297363, Accuracy: 0.6455078125\n",
      "Batch: 26, Loss: 0.9661310911178589, Accuracy: 0.6767578125\n",
      "Batch: 27, Loss: 1.0196739435195923, Accuracy: 0.65234375\n",
      "Batch: 28, Loss: 1.118793249130249, Accuracy: 0.6240234375\n",
      "Batch: 29, Loss: 1.1235202550888062, Accuracy: 0.630859375\n",
      "Batch: 30, Loss: 1.0612306594848633, Accuracy: 0.669921875\n",
      "Batch: 31, Loss: 1.0172314643859863, Accuracy: 0.6728515625\n",
      "Batch: 32, Loss: 1.0033056735992432, Accuracy: 0.6796875\n",
      "Batch: 33, Loss: 1.1681911945343018, Accuracy: 0.6123046875\n",
      "Batch: 34, Loss: 1.2347776889801025, Accuracy: 0.6005859375\n",
      "Batch: 35, Loss: 1.140897274017334, Accuracy: 0.6396484375\n",
      "Batch: 36, Loss: 1.13865065574646, Accuracy: 0.6552734375\n",
      "Batch: 37, Loss: 1.0917302370071411, Accuracy: 0.6376953125\n",
      "Batch: 38, Loss: 1.1284397840499878, Accuracy: 0.619140625\n",
      "Batch: 39, Loss: 1.1252970695495605, Accuracy: 0.654296875\n",
      "Batch: 40, Loss: 1.1519176959991455, Accuracy: 0.65625\n",
      "Batch: 41, Loss: 1.1170483827590942, Accuracy: 0.6416015625\n",
      "Batch: 42, Loss: 0.8964300751686096, Accuracy: 0.6904296875\n",
      "Batch: 43, Loss: 1.1126580238342285, Accuracy: 0.638671875\n",
      "Batch: 44, Loss: 1.0842750072479248, Accuracy: 0.6396484375\n",
      "Batch: 45, Loss: 0.9491354823112488, Accuracy: 0.689453125\n",
      "Batch: 46, Loss: 1.0763945579528809, Accuracy: 0.6591796875\n",
      "Batch: 47, Loss: 1.0856817960739136, Accuracy: 0.6650390625\n",
      "Batch: 48, Loss: 1.0002385377883911, Accuracy: 0.6650390625\n",
      "Batch: 49, Loss: 1.2263588905334473, Accuracy: 0.59765625\n",
      "Batch: 50, Loss: 1.144632339477539, Accuracy: 0.6220703125\n",
      "Batch: 51, Loss: 1.225258469581604, Accuracy: 0.5947265625\n",
      "Batch: 52, Loss: 1.1695919036865234, Accuracy: 0.6318359375\n",
      "Batch: 53, Loss: 1.0031200647354126, Accuracy: 0.6611328125\n",
      "Batch: 54, Loss: 1.0927650928497314, Accuracy: 0.6572265625\n",
      "Batch: 55, Loss: 1.1340227127075195, Accuracy: 0.6279296875\n",
      "Batch: 56, Loss: 1.1469852924346924, Accuracy: 0.6328125\n",
      "Batch: 57, Loss: 1.0653140544891357, Accuracy: 0.671875\n",
      "Batch: 58, Loss: 1.143231987953186, Accuracy: 0.650390625\n",
      "Batch: 59, Loss: 1.0110801458358765, Accuracy: 0.69140625\n",
      "Batch: 60, Loss: 0.9932055473327637, Accuracy: 0.689453125\n",
      "Batch: 61, Loss: 1.0691624879837036, Accuracy: 0.6484375\n",
      "Batch: 62, Loss: 1.052962303161621, Accuracy: 0.658203125\n",
      "Batch: 63, Loss: 1.0753304958343506, Accuracy: 0.6513671875\n",
      "Batch: 64, Loss: 1.059044599533081, Accuracy: 0.6689453125\n",
      "Batch: 65, Loss: 1.0915039777755737, Accuracy: 0.6474609375\n",
      "Batch: 66, Loss: 1.0297091007232666, Accuracy: 0.662109375\n",
      "Batch: 67, Loss: 1.1746108531951904, Accuracy: 0.6240234375\n",
      "Batch: 68, Loss: 1.2034335136413574, Accuracy: 0.619140625\n",
      "Batch: 69, Loss: 1.126594066619873, Accuracy: 0.630859375\n",
      "Batch: 70, Loss: 1.0882418155670166, Accuracy: 0.6513671875\n",
      "Batch: 71, Loss: 1.129084587097168, Accuracy: 0.630859375\n",
      "Batch: 72, Loss: 0.9856740236282349, Accuracy: 0.6787109375\n",
      "Batch: 73, Loss: 1.0487864017486572, Accuracy: 0.6708984375\n",
      "Batch: 74, Loss: 1.0068120956420898, Accuracy: 0.6826171875\n",
      "Batch: 75, Loss: 0.9704598188400269, Accuracy: 0.6767578125\n",
      "Batch: 76, Loss: 1.0944726467132568, Accuracy: 0.6435546875\n",
      "Batch: 77, Loss: 1.0510072708129883, Accuracy: 0.6533203125\n",
      "Batch: 78, Loss: 1.0598604679107666, Accuracy: 0.66015625\n",
      "Batch: 79, Loss: 0.9720151424407959, Accuracy: 0.69921875\n",
      "Batch: 80, Loss: 1.0135504007339478, Accuracy: 0.6591796875\n",
      "Batch: 81, Loss: 1.1751866340637207, Accuracy: 0.607421875\n",
      "Batch: 82, Loss: 1.1132365465164185, Accuracy: 0.630859375\n",
      "Batch: 83, Loss: 0.9808267951011658, Accuracy: 0.69140625\n",
      "Batch: 84, Loss: 1.046303153038025, Accuracy: 0.68359375\n",
      "Batch: 85, Loss: 1.0116369724273682, Accuracy: 0.685546875\n",
      "Batch: 86, Loss: 1.227649211883545, Accuracy: 0.599609375\n",
      "Batch: 87, Loss: 1.000624179840088, Accuracy: 0.6865234375\n",
      "Batch: 88, Loss: 1.1611367464065552, Accuracy: 0.638671875\n",
      "Batch: 89, Loss: 1.140189528465271, Accuracy: 0.640625\n",
      "Batch: 90, Loss: 1.000563383102417, Accuracy: 0.6806640625\n",
      "Batch: 91, Loss: 1.0719995498657227, Accuracy: 0.6494140625\n",
      "Batch: 92, Loss: 1.0730392932891846, Accuracy: 0.6552734375\n",
      "Batch: 93, Loss: 1.039815902709961, Accuracy: 0.6572265625\n",
      "Batch: 94, Loss: 1.0297131538391113, Accuracy: 0.6591796875\n",
      "Batch: 95, Loss: 1.0992579460144043, Accuracy: 0.625\n",
      "Batch: 96, Loss: 1.0591486692428589, Accuracy: 0.662109375\n",
      "Batch: 97, Loss: 0.9562641382217407, Accuracy: 0.6875\n",
      "Batch: 98, Loss: 0.9874288439750671, Accuracy: 0.677734375\n",
      "Batch: 99, Loss: 0.9741175174713135, Accuracy: 0.671875\n",
      "Batch: 100, Loss: 1.0494732856750488, Accuracy: 0.6630859375\n",
      "Batch: 101, Loss: 1.1244533061981201, Accuracy: 0.63671875\n",
      "Batch: 102, Loss: 1.036690354347229, Accuracy: 0.6591796875\n",
      "Batch: 103, Loss: 1.1450488567352295, Accuracy: 0.65234375\n",
      "Batch: 104, Loss: 1.0133447647094727, Accuracy: 0.66796875\n",
      "Batch: 105, Loss: 1.0973010063171387, Accuracy: 0.650390625\n",
      "Batch: 106, Loss: 1.0870856046676636, Accuracy: 0.6572265625\n",
      "Batch: 107, Loss: 1.1341664791107178, Accuracy: 0.6591796875\n",
      "Batch: 108, Loss: 1.1226332187652588, Accuracy: 0.638671875\n",
      "Batch: 109, Loss: 1.2500455379486084, Accuracy: 0.587890625\n",
      "Batch: 110, Loss: 0.9435726404190063, Accuracy: 0.6904296875\n",
      "Batch: 111, Loss: 1.1317081451416016, Accuracy: 0.625\n",
      "Batch: 112, Loss: 1.075456142425537, Accuracy: 0.6533203125\n",
      "Batch: 113, Loss: 1.0915369987487793, Accuracy: 0.6611328125\n",
      "Batch: 114, Loss: 1.1975071430206299, Accuracy: 0.6162109375\n",
      "Batch: 115, Loss: 1.21173095703125, Accuracy: 0.6357421875\n",
      "Batch: 116, Loss: 1.1713483333587646, Accuracy: 0.623046875\n",
      "Batch: 117, Loss: 1.1455228328704834, Accuracy: 0.6474609375\n",
      "Batch: 118, Loss: 0.9781370162963867, Accuracy: 0.685546875\n",
      "Batch: 119, Loss: 0.9711111783981323, Accuracy: 0.693359375\n",
      "Batch: 120, Loss: 1.119859218597412, Accuracy: 0.6328125\n",
      "Batch: 121, Loss: 1.1590588092803955, Accuracy: 0.630859375\n",
      "Batch: 122, Loss: 1.0699844360351562, Accuracy: 0.6640625\n",
      "Batch: 123, Loss: 1.0232728719711304, Accuracy: 0.677734375\n",
      "Batch: 124, Loss: 1.118162751197815, Accuracy: 0.650390625\n",
      "Batch: 125, Loss: 1.1306025981903076, Accuracy: 0.6279296875\n",
      "Batch: 126, Loss: 1.1199589967727661, Accuracy: 0.6328125\n",
      "Batch: 127, Loss: 1.001129150390625, Accuracy: 0.6884765625\n",
      "Batch: 128, Loss: 1.1914403438568115, Accuracy: 0.6240234375\n",
      "Batch: 129, Loss: 1.0457295179367065, Accuracy: 0.6552734375\n",
      "Batch: 130, Loss: 1.2698571681976318, Accuracy: 0.6064453125\n",
      "Batch: 131, Loss: 1.1512527465820312, Accuracy: 0.6240234375\n",
      "Batch: 132, Loss: 1.1644139289855957, Accuracy: 0.634765625\n",
      "Batch: 133, Loss: 1.0340946912765503, Accuracy: 0.658203125\n",
      "Batch: 134, Loss: 1.0860769748687744, Accuracy: 0.634765625\n",
      "Batch: 135, Loss: 1.0230604410171509, Accuracy: 0.67578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 136, Loss: 1.067358374595642, Accuracy: 0.6650390625\n",
      "Batch: 137, Loss: 1.0069297552108765, Accuracy: 0.6552734375\n",
      "Batch: 138, Loss: 0.8974604606628418, Accuracy: 0.685546875\n",
      "Batch: 139, Loss: 0.9758503437042236, Accuracy: 0.6845703125\n",
      "Batch: 140, Loss: 1.073775291442871, Accuracy: 0.6484375\n",
      "Batch: 141, Loss: 1.096421718597412, Accuracy: 0.6396484375\n",
      "Batch: 142, Loss: 1.1237387657165527, Accuracy: 0.6337890625\n",
      "Batch: 143, Loss: 1.0989785194396973, Accuracy: 0.6337890625\n",
      "Batch: 144, Loss: 1.0777819156646729, Accuracy: 0.654296875\n",
      "Batch: 145, Loss: 1.0325452089309692, Accuracy: 0.63671875\n",
      "Batch: 146, Loss: 1.0935747623443604, Accuracy: 0.6337890625\n",
      "Batch: 147, Loss: 1.0734033584594727, Accuracy: 0.6494140625\n",
      "Batch: 148, Loss: 1.1840710639953613, Accuracy: 0.6025390625\n",
      "Batch: 149, Loss: 1.0781794786453247, Accuracy: 0.6513671875\n",
      "Batch: 150, Loss: 1.028367519378662, Accuracy: 0.6572265625\n",
      "Batch: 151, Loss: 0.9368795156478882, Accuracy: 0.703125\n",
      "Epoch 14/90\n",
      "Batch: 1, Loss: 1.2986778020858765, Accuracy: 0.5888671875\n",
      "Batch: 2, Loss: 1.1056653261184692, Accuracy: 0.625\n",
      "Batch: 3, Loss: 1.0316903591156006, Accuracy: 0.646484375\n",
      "Batch: 4, Loss: 0.9504028558731079, Accuracy: 0.6962890625\n",
      "Batch: 5, Loss: 0.9641228914260864, Accuracy: 0.697265625\n",
      "Batch: 6, Loss: 1.066959261894226, Accuracy: 0.650390625\n",
      "Batch: 7, Loss: 1.025890588760376, Accuracy: 0.6591796875\n",
      "Batch: 8, Loss: 0.993215799331665, Accuracy: 0.65625\n",
      "Batch: 9, Loss: 0.9409090280532837, Accuracy: 0.712890625\n",
      "Batch: 10, Loss: 0.9511768817901611, Accuracy: 0.6865234375\n",
      "Batch: 11, Loss: 1.1262503862380981, Accuracy: 0.6240234375\n",
      "Batch: 12, Loss: 1.154384970664978, Accuracy: 0.62890625\n",
      "Batch: 13, Loss: 0.884028434753418, Accuracy: 0.7099609375\n",
      "Batch: 14, Loss: 1.1605403423309326, Accuracy: 0.6171875\n",
      "Batch: 15, Loss: 1.0147490501403809, Accuracy: 0.6982421875\n",
      "Batch: 16, Loss: 1.0114765167236328, Accuracy: 0.66796875\n",
      "Batch: 17, Loss: 1.1156766414642334, Accuracy: 0.6376953125\n",
      "Batch: 18, Loss: 1.0840628147125244, Accuracy: 0.63671875\n",
      "Batch: 19, Loss: 1.157381296157837, Accuracy: 0.625\n",
      "Batch: 20, Loss: 1.0074058771133423, Accuracy: 0.69140625\n",
      "Batch: 21, Loss: 0.990597128868103, Accuracy: 0.6787109375\n",
      "Batch: 22, Loss: 1.119431972503662, Accuracy: 0.6533203125\n",
      "Batch: 23, Loss: 1.0339510440826416, Accuracy: 0.6572265625\n",
      "Batch: 24, Loss: 1.0631580352783203, Accuracy: 0.650390625\n",
      "Batch: 25, Loss: 1.021322250366211, Accuracy: 0.666015625\n",
      "Batch: 26, Loss: 0.9294193983078003, Accuracy: 0.677734375\n",
      "Batch: 27, Loss: 0.9836291670799255, Accuracy: 0.666015625\n",
      "Batch: 28, Loss: 1.0839436054229736, Accuracy: 0.6201171875\n",
      "Batch: 29, Loss: 1.065524935722351, Accuracy: 0.65234375\n",
      "Batch: 30, Loss: 1.0001201629638672, Accuracy: 0.6865234375\n",
      "Batch: 31, Loss: 0.9722778797149658, Accuracy: 0.701171875\n",
      "Batch: 32, Loss: 0.9696946144104004, Accuracy: 0.68359375\n",
      "Batch: 33, Loss: 1.1326961517333984, Accuracy: 0.6279296875\n",
      "Batch: 34, Loss: 1.1913009881973267, Accuracy: 0.61328125\n",
      "Batch: 35, Loss: 1.1157901287078857, Accuracy: 0.6455078125\n",
      "Batch: 36, Loss: 1.114782691001892, Accuracy: 0.65234375\n",
      "Batch: 37, Loss: 1.0454111099243164, Accuracy: 0.6630859375\n",
      "Batch: 38, Loss: 1.0908787250518799, Accuracy: 0.6318359375\n",
      "Batch: 39, Loss: 1.0911387205123901, Accuracy: 0.65234375\n",
      "Batch: 40, Loss: 1.1207160949707031, Accuracy: 0.6689453125\n",
      "Batch: 41, Loss: 1.0736994743347168, Accuracy: 0.65625\n",
      "Batch: 42, Loss: 0.881973922252655, Accuracy: 0.7099609375\n",
      "Batch: 43, Loss: 1.1013230085372925, Accuracy: 0.6416015625\n",
      "Batch: 44, Loss: 1.063585877418518, Accuracy: 0.6474609375\n",
      "Batch: 45, Loss: 0.9446429014205933, Accuracy: 0.68359375\n",
      "Batch: 46, Loss: 1.0401604175567627, Accuracy: 0.67578125\n",
      "Batch: 47, Loss: 1.030386209487915, Accuracy: 0.6748046875\n",
      "Batch: 48, Loss: 0.9498429298400879, Accuracy: 0.693359375\n",
      "Batch: 49, Loss: 1.1740168333053589, Accuracy: 0.6162109375\n",
      "Batch: 50, Loss: 1.102342128753662, Accuracy: 0.654296875\n",
      "Batch: 51, Loss: 1.2047592401504517, Accuracy: 0.6181640625\n",
      "Batch: 52, Loss: 1.1434862613677979, Accuracy: 0.642578125\n",
      "Batch: 53, Loss: 0.9485629200935364, Accuracy: 0.6728515625\n",
      "Batch: 54, Loss: 1.0273079872131348, Accuracy: 0.669921875\n",
      "Batch: 55, Loss: 1.1075150966644287, Accuracy: 0.6201171875\n",
      "Batch: 56, Loss: 1.108949899673462, Accuracy: 0.6455078125\n",
      "Batch: 57, Loss: 1.030295491218567, Accuracy: 0.6728515625\n",
      "Batch: 58, Loss: 1.138078212738037, Accuracy: 0.650390625\n",
      "Batch: 59, Loss: 0.9837944507598877, Accuracy: 0.697265625\n",
      "Batch: 60, Loss: 0.9507501721382141, Accuracy: 0.689453125\n",
      "Batch: 61, Loss: 1.0493512153625488, Accuracy: 0.6572265625\n",
      "Batch: 62, Loss: 1.0154449939727783, Accuracy: 0.662109375\n",
      "Batch: 63, Loss: 1.0365049839019775, Accuracy: 0.6513671875\n",
      "Batch: 64, Loss: 1.0411207675933838, Accuracy: 0.6689453125\n",
      "Batch: 65, Loss: 1.0496118068695068, Accuracy: 0.6748046875\n",
      "Batch: 66, Loss: 1.015997052192688, Accuracy: 0.6669921875\n",
      "Batch: 67, Loss: 1.1300195455551147, Accuracy: 0.6474609375\n",
      "Batch: 68, Loss: 1.1458300352096558, Accuracy: 0.669921875\n",
      "Batch: 69, Loss: 1.06513249874115, Accuracy: 0.662109375\n",
      "Batch: 70, Loss: 1.0529232025146484, Accuracy: 0.6689453125\n",
      "Batch: 71, Loss: 1.0779523849487305, Accuracy: 0.6513671875\n",
      "Batch: 72, Loss: 0.94010990858078, Accuracy: 0.69140625\n",
      "Batch: 73, Loss: 1.034296989440918, Accuracy: 0.6865234375\n",
      "Batch: 74, Loss: 0.9692633152008057, Accuracy: 0.68359375\n",
      "Batch: 75, Loss: 0.9398322701454163, Accuracy: 0.697265625\n",
      "Batch: 76, Loss: 1.0587942600250244, Accuracy: 0.6533203125\n",
      "Batch: 77, Loss: 1.0139636993408203, Accuracy: 0.6572265625\n",
      "Batch: 78, Loss: 1.028530240058899, Accuracy: 0.6806640625\n",
      "Batch: 79, Loss: 0.9393833875656128, Accuracy: 0.716796875\n",
      "Batch: 80, Loss: 0.9978736042976379, Accuracy: 0.673828125\n",
      "Batch: 81, Loss: 1.121506690979004, Accuracy: 0.6181640625\n",
      "Batch: 82, Loss: 1.0739141702651978, Accuracy: 0.654296875\n",
      "Batch: 83, Loss: 0.9436774849891663, Accuracy: 0.7001953125\n",
      "Batch: 84, Loss: 1.0112593173980713, Accuracy: 0.68359375\n",
      "Batch: 85, Loss: 0.9521220922470093, Accuracy: 0.689453125\n",
      "Batch: 86, Loss: 1.1725640296936035, Accuracy: 0.640625\n",
      "Batch: 87, Loss: 0.9707852005958557, Accuracy: 0.697265625\n",
      "Batch: 88, Loss: 1.115108609199524, Accuracy: 0.662109375\n",
      "Batch: 89, Loss: 1.0990571975708008, Accuracy: 0.6591796875\n",
      "Batch: 90, Loss: 0.9947755336761475, Accuracy: 0.6728515625\n",
      "Batch: 91, Loss: 1.065755844116211, Accuracy: 0.6669921875\n",
      "Batch: 92, Loss: 1.046504259109497, Accuracy: 0.6611328125\n",
      "Batch: 93, Loss: 1.003442645072937, Accuracy: 0.681640625\n",
      "Batch: 94, Loss: 0.9813814163208008, Accuracy: 0.6796875\n",
      "Batch: 95, Loss: 1.057591199874878, Accuracy: 0.6396484375\n",
      "Batch: 96, Loss: 1.0551393032073975, Accuracy: 0.662109375\n",
      "Batch: 97, Loss: 0.9177689552307129, Accuracy: 0.685546875\n",
      "Batch: 98, Loss: 0.9493127465248108, Accuracy: 0.7099609375\n",
      "Batch: 99, Loss: 0.9519855380058289, Accuracy: 0.6748046875\n",
      "Batch: 100, Loss: 1.008769154548645, Accuracy: 0.681640625\n",
      "Batch: 101, Loss: 1.0912449359893799, Accuracy: 0.63671875\n",
      "Batch: 102, Loss: 0.9997721910476685, Accuracy: 0.66796875\n",
      "Batch: 103, Loss: 1.1041178703308105, Accuracy: 0.6533203125\n",
      "Batch: 104, Loss: 0.9729626774787903, Accuracy: 0.685546875\n",
      "Batch: 105, Loss: 1.0813897848129272, Accuracy: 0.6455078125\n",
      "Batch: 106, Loss: 1.0114127397537231, Accuracy: 0.681640625\n",
      "Batch: 107, Loss: 1.0950250625610352, Accuracy: 0.650390625\n",
      "Batch: 108, Loss: 1.0555720329284668, Accuracy: 0.6552734375\n",
      "Batch: 109, Loss: 1.18074631690979, Accuracy: 0.6103515625\n",
      "Batch: 110, Loss: 0.9054504632949829, Accuracy: 0.7080078125\n",
      "Batch: 111, Loss: 1.0962810516357422, Accuracy: 0.6318359375\n",
      "Batch: 112, Loss: 1.0216937065124512, Accuracy: 0.6796875\n",
      "Batch: 113, Loss: 1.042811393737793, Accuracy: 0.6748046875\n",
      "Batch: 114, Loss: 1.1757516860961914, Accuracy: 0.6201171875\n",
      "Batch: 115, Loss: 1.1910418272018433, Accuracy: 0.634765625\n",
      "Batch: 116, Loss: 1.1320161819458008, Accuracy: 0.650390625\n",
      "Batch: 117, Loss: 1.1018948554992676, Accuracy: 0.6435546875\n",
      "Batch: 118, Loss: 0.9323481321334839, Accuracy: 0.7041015625\n",
      "Batch: 119, Loss: 0.9516451954841614, Accuracy: 0.7060546875\n",
      "Batch: 120, Loss: 1.1162540912628174, Accuracy: 0.6376953125\n",
      "Batch: 121, Loss: 1.0988621711730957, Accuracy: 0.65234375\n",
      "Batch: 122, Loss: 1.0011332035064697, Accuracy: 0.67578125\n",
      "Batch: 123, Loss: 0.9975667595863342, Accuracy: 0.6953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 124, Loss: 1.1004316806793213, Accuracy: 0.6513671875\n",
      "Batch: 125, Loss: 1.1064271926879883, Accuracy: 0.650390625\n",
      "Batch: 126, Loss: 1.0758295059204102, Accuracy: 0.65625\n",
      "Batch: 127, Loss: 0.9496914148330688, Accuracy: 0.6982421875\n",
      "Batch: 128, Loss: 1.1849074363708496, Accuracy: 0.6279296875\n",
      "Batch: 129, Loss: 1.0036674737930298, Accuracy: 0.6845703125\n",
      "Batch: 130, Loss: 1.2420718669891357, Accuracy: 0.59765625\n",
      "Batch: 131, Loss: 1.139184594154358, Accuracy: 0.626953125\n",
      "Batch: 132, Loss: 1.138822078704834, Accuracy: 0.6513671875\n",
      "Batch: 133, Loss: 0.9866173267364502, Accuracy: 0.6630859375\n",
      "Batch: 134, Loss: 1.0668848752975464, Accuracy: 0.6669921875\n",
      "Batch: 135, Loss: 0.9795700907707214, Accuracy: 0.681640625\n",
      "Batch: 136, Loss: 1.0296967029571533, Accuracy: 0.677734375\n",
      "Batch: 137, Loss: 0.9821131229400635, Accuracy: 0.662109375\n",
      "Batch: 138, Loss: 0.8648943901062012, Accuracy: 0.701171875\n",
      "Batch: 139, Loss: 0.9327940940856934, Accuracy: 0.6962890625\n",
      "Batch: 140, Loss: 1.0412733554840088, Accuracy: 0.6640625\n",
      "Batch: 141, Loss: 1.071101427078247, Accuracy: 0.6513671875\n",
      "Batch: 142, Loss: 1.092284917831421, Accuracy: 0.6533203125\n",
      "Batch: 143, Loss: 1.051142930984497, Accuracy: 0.6533203125\n",
      "Batch: 144, Loss: 1.0415804386138916, Accuracy: 0.6630859375\n",
      "Batch: 145, Loss: 0.9976838827133179, Accuracy: 0.6484375\n",
      "Batch: 146, Loss: 1.066881537437439, Accuracy: 0.650390625\n",
      "Batch: 147, Loss: 1.048281192779541, Accuracy: 0.6748046875\n",
      "Batch: 148, Loss: 1.157875657081604, Accuracy: 0.62890625\n",
      "Batch: 149, Loss: 1.0549509525299072, Accuracy: 0.66015625\n",
      "Batch: 150, Loss: 0.9959362149238586, Accuracy: 0.6650390625\n",
      "Batch: 151, Loss: 0.9057134985923767, Accuracy: 0.71484375\n",
      "Epoch 15/90\n",
      "Batch: 1, Loss: 1.295688509941101, Accuracy: 0.5791015625\n",
      "Batch: 2, Loss: 1.132227897644043, Accuracy: 0.625\n",
      "Batch: 3, Loss: 1.0052456855773926, Accuracy: 0.6630859375\n",
      "Batch: 4, Loss: 0.9315995573997498, Accuracy: 0.7177734375\n",
      "Batch: 5, Loss: 0.9281870126724243, Accuracy: 0.701171875\n",
      "Batch: 6, Loss: 1.0452814102172852, Accuracy: 0.658203125\n",
      "Batch: 7, Loss: 1.0027835369110107, Accuracy: 0.6767578125\n",
      "Batch: 8, Loss: 0.9227540493011475, Accuracy: 0.697265625\n",
      "Batch: 9, Loss: 0.9143784046173096, Accuracy: 0.712890625\n",
      "Batch: 10, Loss: 0.9316893815994263, Accuracy: 0.6953125\n",
      "Batch: 11, Loss: 1.1253553628921509, Accuracy: 0.62109375\n",
      "Batch: 12, Loss: 1.1175975799560547, Accuracy: 0.638671875\n",
      "Batch: 13, Loss: 0.8464021682739258, Accuracy: 0.7265625\n",
      "Batch: 14, Loss: 1.1044824123382568, Accuracy: 0.6328125\n",
      "Batch: 15, Loss: 0.9780338406562805, Accuracy: 0.70703125\n",
      "Batch: 16, Loss: 0.953353762626648, Accuracy: 0.6982421875\n",
      "Batch: 17, Loss: 1.0740809440612793, Accuracy: 0.6474609375\n",
      "Batch: 18, Loss: 1.0535911321640015, Accuracy: 0.6591796875\n",
      "Batch: 19, Loss: 1.112912654876709, Accuracy: 0.6591796875\n",
      "Batch: 20, Loss: 0.9847351312637329, Accuracy: 0.69921875\n",
      "Batch: 21, Loss: 0.9638286828994751, Accuracy: 0.69140625\n",
      "Batch: 22, Loss: 1.104309320449829, Accuracy: 0.6455078125\n",
      "Batch: 23, Loss: 1.0241714715957642, Accuracy: 0.6650390625\n",
      "Batch: 24, Loss: 1.0261693000793457, Accuracy: 0.6513671875\n",
      "Batch: 25, Loss: 1.00445556640625, Accuracy: 0.6669921875\n",
      "Batch: 26, Loss: 0.9055181741714478, Accuracy: 0.70703125\n",
      "Batch: 27, Loss: 0.9573924541473389, Accuracy: 0.6787109375\n",
      "Batch: 28, Loss: 1.0668270587921143, Accuracy: 0.64453125\n",
      "Batch: 29, Loss: 1.0163365602493286, Accuracy: 0.6611328125\n",
      "Batch: 30, Loss: 0.9657929539680481, Accuracy: 0.697265625\n",
      "Batch: 31, Loss: 0.9605022072792053, Accuracy: 0.701171875\n",
      "Batch: 32, Loss: 0.9357361793518066, Accuracy: 0.701171875\n",
      "Batch: 33, Loss: 1.087357997894287, Accuracy: 0.6572265625\n",
      "Batch: 34, Loss: 1.1538615226745605, Accuracy: 0.6337890625\n",
      "Batch: 35, Loss: 1.0958889722824097, Accuracy: 0.6455078125\n",
      "Batch: 36, Loss: 1.0570580959320068, Accuracy: 0.6630859375\n",
      "Batch: 37, Loss: 1.0119147300720215, Accuracy: 0.662109375\n",
      "Batch: 38, Loss: 1.0484799146652222, Accuracy: 0.6689453125\n",
      "Batch: 39, Loss: 1.0392844676971436, Accuracy: 0.662109375\n",
      "Batch: 40, Loss: 1.0802452564239502, Accuracy: 0.671875\n",
      "Batch: 41, Loss: 1.0567362308502197, Accuracy: 0.6748046875\n",
      "Batch: 42, Loss: 0.8509536981582642, Accuracy: 0.7080078125\n",
      "Batch: 43, Loss: 1.073343276977539, Accuracy: 0.65625\n",
      "Batch: 44, Loss: 1.052643060684204, Accuracy: 0.642578125\n",
      "Batch: 45, Loss: 0.9077317118644714, Accuracy: 0.701171875\n",
      "Batch: 46, Loss: 1.0156042575836182, Accuracy: 0.697265625\n",
      "Batch: 47, Loss: 1.0009809732437134, Accuracy: 0.6923828125\n",
      "Batch: 48, Loss: 0.9373016357421875, Accuracy: 0.68359375\n",
      "Batch: 49, Loss: 1.1163198947906494, Accuracy: 0.6259765625\n",
      "Batch: 50, Loss: 1.0726442337036133, Accuracy: 0.6533203125\n",
      "Batch: 51, Loss: 1.1526702642440796, Accuracy: 0.6279296875\n",
      "Batch: 52, Loss: 1.1008661985397339, Accuracy: 0.650390625\n",
      "Batch: 53, Loss: 0.944849967956543, Accuracy: 0.6865234375\n",
      "Batch: 54, Loss: 1.0129296779632568, Accuracy: 0.681640625\n",
      "Batch: 55, Loss: 1.0722341537475586, Accuracy: 0.65234375\n",
      "Batch: 56, Loss: 1.0995910167694092, Accuracy: 0.640625\n",
      "Batch: 57, Loss: 1.0030876398086548, Accuracy: 0.685546875\n",
      "Batch: 58, Loss: 1.085318922996521, Accuracy: 0.6748046875\n",
      "Batch: 59, Loss: 0.9771865010261536, Accuracy: 0.69921875\n",
      "Batch: 60, Loss: 0.9119150638580322, Accuracy: 0.7060546875\n",
      "Batch: 61, Loss: 1.0226545333862305, Accuracy: 0.6669921875\n",
      "Batch: 62, Loss: 0.9809699058532715, Accuracy: 0.685546875\n",
      "Batch: 63, Loss: 1.0230945348739624, Accuracy: 0.6669921875\n",
      "Batch: 64, Loss: 1.0028793811798096, Accuracy: 0.671875\n",
      "Batch: 65, Loss: 1.030303716659546, Accuracy: 0.6884765625\n",
      "Batch: 66, Loss: 0.9692903757095337, Accuracy: 0.69921875\n",
      "Batch: 67, Loss: 1.1166130304336548, Accuracy: 0.6337890625\n",
      "Batch: 68, Loss: 1.1166529655456543, Accuracy: 0.65625\n",
      "Batch: 69, Loss: 1.048076868057251, Accuracy: 0.6640625\n",
      "Batch: 70, Loss: 1.022229790687561, Accuracy: 0.6787109375\n",
      "Batch: 71, Loss: 1.0604872703552246, Accuracy: 0.658203125\n",
      "Batch: 72, Loss: 0.929533064365387, Accuracy: 0.6884765625\n",
      "Batch: 73, Loss: 0.9885873198509216, Accuracy: 0.6923828125\n",
      "Batch: 74, Loss: 0.9564153552055359, Accuracy: 0.6884765625\n",
      "Batch: 75, Loss: 0.9220354557037354, Accuracy: 0.697265625\n",
      "Batch: 76, Loss: 1.0333138704299927, Accuracy: 0.6591796875\n",
      "Batch: 77, Loss: 0.9677746891975403, Accuracy: 0.6943359375\n",
      "Batch: 78, Loss: 0.9852018356323242, Accuracy: 0.6826171875\n",
      "Batch: 79, Loss: 0.9239301085472107, Accuracy: 0.7197265625\n",
      "Batch: 80, Loss: 0.9633269309997559, Accuracy: 0.66796875\n",
      "Batch: 81, Loss: 1.0911445617675781, Accuracy: 0.6279296875\n",
      "Batch: 82, Loss: 1.0430020093917847, Accuracy: 0.64453125\n",
      "Batch: 83, Loss: 0.8959697484970093, Accuracy: 0.7119140625\n",
      "Batch: 84, Loss: 0.9983853101730347, Accuracy: 0.6884765625\n",
      "Batch: 85, Loss: 0.9154422283172607, Accuracy: 0.716796875\n",
      "Batch: 86, Loss: 1.1480872631072998, Accuracy: 0.638671875\n",
      "Batch: 87, Loss: 0.9631459712982178, Accuracy: 0.70703125\n",
      "Batch: 88, Loss: 1.073331356048584, Accuracy: 0.66796875\n",
      "Batch: 89, Loss: 1.0954965353012085, Accuracy: 0.666015625\n",
      "Batch: 90, Loss: 0.934627115726471, Accuracy: 0.6923828125\n",
      "Batch: 91, Loss: 1.0254082679748535, Accuracy: 0.669921875\n",
      "Batch: 92, Loss: 1.0149465799331665, Accuracy: 0.6689453125\n",
      "Batch: 93, Loss: 0.9729752540588379, Accuracy: 0.6875\n",
      "Batch: 94, Loss: 0.9465049505233765, Accuracy: 0.6923828125\n",
      "Batch: 95, Loss: 1.0553913116455078, Accuracy: 0.6533203125\n",
      "Batch: 96, Loss: 1.019228219985962, Accuracy: 0.6650390625\n",
      "Batch: 97, Loss: 0.8804723620414734, Accuracy: 0.705078125\n",
      "Batch: 98, Loss: 0.9258645176887512, Accuracy: 0.7060546875\n",
      "Batch: 99, Loss: 0.9199521541595459, Accuracy: 0.6923828125\n",
      "Batch: 100, Loss: 0.9934805035591125, Accuracy: 0.6845703125\n",
      "Batch: 101, Loss: 1.066912055015564, Accuracy: 0.65625\n",
      "Batch: 102, Loss: 0.9905757308006287, Accuracy: 0.68359375\n",
      "Batch: 103, Loss: 1.0745775699615479, Accuracy: 0.673828125\n",
      "Batch: 104, Loss: 0.9489526748657227, Accuracy: 0.6875\n",
      "Batch: 105, Loss: 1.036089301109314, Accuracy: 0.67578125\n",
      "Batch: 106, Loss: 1.0072518587112427, Accuracy: 0.685546875\n",
      "Batch: 107, Loss: 1.0525031089782715, Accuracy: 0.681640625\n",
      "Batch: 108, Loss: 1.0338349342346191, Accuracy: 0.6669921875\n",
      "Batch: 109, Loss: 1.1638089418411255, Accuracy: 0.6240234375\n",
      "Batch: 110, Loss: 0.8786798715591431, Accuracy: 0.7177734375\n",
      "Batch: 111, Loss: 1.0724233388900757, Accuracy: 0.6328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 112, Loss: 0.9935756921768188, Accuracy: 0.67578125\n",
      "Batch: 113, Loss: 1.0071324110031128, Accuracy: 0.6787109375\n",
      "Batch: 114, Loss: 1.1209492683410645, Accuracy: 0.62109375\n",
      "Batch: 115, Loss: 1.1426005363464355, Accuracy: 0.646484375\n",
      "Batch: 116, Loss: 1.1076686382293701, Accuracy: 0.630859375\n",
      "Batch: 117, Loss: 1.0763527154922485, Accuracy: 0.65234375\n",
      "Batch: 118, Loss: 0.9281079173088074, Accuracy: 0.7080078125\n",
      "Batch: 119, Loss: 0.9347932934761047, Accuracy: 0.7080078125\n",
      "Batch: 120, Loss: 1.0597877502441406, Accuracy: 0.6416015625\n",
      "Batch: 121, Loss: 1.0800129175186157, Accuracy: 0.658203125\n",
      "Batch: 122, Loss: 1.0092871189117432, Accuracy: 0.677734375\n",
      "Batch: 123, Loss: 0.9731730818748474, Accuracy: 0.693359375\n",
      "Batch: 124, Loss: 1.074674367904663, Accuracy: 0.662109375\n",
      "Batch: 125, Loss: 1.0679112672805786, Accuracy: 0.6630859375\n",
      "Batch: 126, Loss: 1.0578467845916748, Accuracy: 0.66015625\n",
      "Batch: 127, Loss: 0.9387847185134888, Accuracy: 0.701171875\n",
      "Batch: 128, Loss: 1.1393344402313232, Accuracy: 0.642578125\n",
      "Batch: 129, Loss: 0.9730409383773804, Accuracy: 0.6943359375\n",
      "Batch: 130, Loss: 1.1969847679138184, Accuracy: 0.60546875\n",
      "Batch: 131, Loss: 1.0921404361724854, Accuracy: 0.6484375\n",
      "Batch: 132, Loss: 1.0929028987884521, Accuracy: 0.6630859375\n",
      "Batch: 133, Loss: 0.9793213605880737, Accuracy: 0.671875\n",
      "Batch: 134, Loss: 1.027937650680542, Accuracy: 0.6455078125\n",
      "Batch: 135, Loss: 0.9528306722640991, Accuracy: 0.7099609375\n",
      "Batch: 136, Loss: 1.0028972625732422, Accuracy: 0.693359375\n",
      "Batch: 137, Loss: 0.971714437007904, Accuracy: 0.66796875\n",
      "Batch: 138, Loss: 0.8568350076675415, Accuracy: 0.7119140625\n",
      "Batch: 139, Loss: 0.9295107126235962, Accuracy: 0.6923828125\n",
      "Batch: 140, Loss: 1.0092523097991943, Accuracy: 0.6669921875\n",
      "Batch: 141, Loss: 1.0586897134780884, Accuracy: 0.6572265625\n",
      "Batch: 142, Loss: 1.0584754943847656, Accuracy: 0.6533203125\n",
      "Batch: 143, Loss: 1.0392671823501587, Accuracy: 0.6484375\n",
      "Batch: 144, Loss: 1.0090017318725586, Accuracy: 0.6923828125\n",
      "Batch: 145, Loss: 0.9585115909576416, Accuracy: 0.6572265625\n",
      "Batch: 146, Loss: 1.0538867712020874, Accuracy: 0.65625\n",
      "Batch: 147, Loss: 1.0313355922698975, Accuracy: 0.666015625\n",
      "Batch: 148, Loss: 1.1390366554260254, Accuracy: 0.6298828125\n",
      "Batch: 149, Loss: 1.0191642045974731, Accuracy: 0.6708984375\n",
      "Batch: 150, Loss: 0.9927157163619995, Accuracy: 0.6806640625\n",
      "Batch: 151, Loss: 0.8757146596908569, Accuracy: 0.7255859375\n",
      "Epoch 16/90\n",
      "Batch: 1, Loss: 1.2975283861160278, Accuracy: 0.5869140625\n",
      "Batch: 2, Loss: 1.0964419841766357, Accuracy: 0.6337890625\n",
      "Batch: 3, Loss: 0.997808575630188, Accuracy: 0.666015625\n",
      "Batch: 4, Loss: 0.8994519114494324, Accuracy: 0.712890625\n",
      "Batch: 5, Loss: 0.901888370513916, Accuracy: 0.7001953125\n",
      "Batch: 6, Loss: 1.0080066919326782, Accuracy: 0.6748046875\n",
      "Batch: 7, Loss: 0.9806299209594727, Accuracy: 0.677734375\n",
      "Batch: 8, Loss: 0.9124146699905396, Accuracy: 0.6884765625\n",
      "Batch: 9, Loss: 0.8916274309158325, Accuracy: 0.716796875\n",
      "Batch: 10, Loss: 0.8968267440795898, Accuracy: 0.7021484375\n",
      "Batch: 11, Loss: 1.0879749059677124, Accuracy: 0.654296875\n",
      "Batch: 12, Loss: 1.0786739587783813, Accuracy: 0.6591796875\n",
      "Batch: 13, Loss: 0.828075110912323, Accuracy: 0.732421875\n",
      "Batch: 14, Loss: 1.0749390125274658, Accuracy: 0.6474609375\n",
      "Batch: 15, Loss: 0.9471555948257446, Accuracy: 0.703125\n",
      "Batch: 16, Loss: 0.9558084011077881, Accuracy: 0.703125\n",
      "Batch: 17, Loss: 1.0570640563964844, Accuracy: 0.669921875\n",
      "Batch: 18, Loss: 1.0158376693725586, Accuracy: 0.6650390625\n",
      "Batch: 19, Loss: 1.0890023708343506, Accuracy: 0.662109375\n",
      "Batch: 20, Loss: 0.9198451638221741, Accuracy: 0.697265625\n",
      "Batch: 21, Loss: 0.9442007541656494, Accuracy: 0.6884765625\n",
      "Batch: 22, Loss: 1.0720795392990112, Accuracy: 0.66015625\n",
      "Batch: 23, Loss: 0.9931603074073792, Accuracy: 0.673828125\n",
      "Batch: 24, Loss: 1.0025864839553833, Accuracy: 0.6650390625\n",
      "Batch: 25, Loss: 0.9754279255867004, Accuracy: 0.6875\n",
      "Batch: 26, Loss: 0.8963972330093384, Accuracy: 0.705078125\n",
      "Batch: 27, Loss: 0.9521287679672241, Accuracy: 0.6806640625\n",
      "Batch: 28, Loss: 1.0590304136276245, Accuracy: 0.640625\n",
      "Batch: 29, Loss: 1.014972448348999, Accuracy: 0.666015625\n",
      "Batch: 30, Loss: 0.9700766801834106, Accuracy: 0.6953125\n",
      "Batch: 31, Loss: 0.9502254128456116, Accuracy: 0.6982421875\n",
      "Batch: 32, Loss: 0.8982205390930176, Accuracy: 0.712890625\n",
      "Batch: 33, Loss: 1.0605440139770508, Accuracy: 0.6689453125\n",
      "Batch: 34, Loss: 1.135066032409668, Accuracy: 0.6337890625\n",
      "Batch: 35, Loss: 1.0527080297470093, Accuracy: 0.658203125\n",
      "Batch: 36, Loss: 1.076330304145813, Accuracy: 0.6611328125\n",
      "Batch: 37, Loss: 0.9840134382247925, Accuracy: 0.69140625\n",
      "Batch: 38, Loss: 1.000254511833191, Accuracy: 0.67578125\n",
      "Batch: 39, Loss: 1.0387496948242188, Accuracy: 0.6728515625\n",
      "Batch: 40, Loss: 1.0613539218902588, Accuracy: 0.6640625\n",
      "Batch: 41, Loss: 1.008925437927246, Accuracy: 0.6796875\n",
      "Batch: 42, Loss: 0.8161909580230713, Accuracy: 0.7314453125\n",
      "Batch: 43, Loss: 1.0497307777404785, Accuracy: 0.65234375\n",
      "Batch: 44, Loss: 1.0345232486724854, Accuracy: 0.6572265625\n",
      "Batch: 45, Loss: 0.8937082290649414, Accuracy: 0.697265625\n",
      "Batch: 46, Loss: 0.9604318737983704, Accuracy: 0.7021484375\n",
      "Batch: 47, Loss: 0.9814062714576721, Accuracy: 0.693359375\n",
      "Batch: 48, Loss: 0.9129729270935059, Accuracy: 0.703125\n",
      "Batch: 49, Loss: 1.104848861694336, Accuracy: 0.6328125\n",
      "Batch: 50, Loss: 1.061616063117981, Accuracy: 0.6611328125\n",
      "Batch: 51, Loss: 1.139986515045166, Accuracy: 0.6337890625\n",
      "Batch: 52, Loss: 1.0746533870697021, Accuracy: 0.662109375\n",
      "Batch: 53, Loss: 0.9106377959251404, Accuracy: 0.6923828125\n",
      "Batch: 54, Loss: 0.9792688488960266, Accuracy: 0.689453125\n",
      "Batch: 55, Loss: 1.046372413635254, Accuracy: 0.6591796875\n",
      "Batch: 56, Loss: 1.072321891784668, Accuracy: 0.6533203125\n",
      "Batch: 57, Loss: 0.9832733869552612, Accuracy: 0.681640625\n",
      "Batch: 58, Loss: 1.0739829540252686, Accuracy: 0.6630859375\n",
      "Batch: 59, Loss: 0.9643509387969971, Accuracy: 0.7041015625\n",
      "Batch: 60, Loss: 0.8987581729888916, Accuracy: 0.7216796875\n",
      "Batch: 61, Loss: 1.0034770965576172, Accuracy: 0.6787109375\n",
      "Batch: 62, Loss: 0.964789867401123, Accuracy: 0.6728515625\n",
      "Batch: 63, Loss: 1.0133105516433716, Accuracy: 0.6630859375\n",
      "Batch: 64, Loss: 0.9905593395233154, Accuracy: 0.673828125\n",
      "Batch: 65, Loss: 1.0054372549057007, Accuracy: 0.6845703125\n",
      "Batch: 66, Loss: 0.960161566734314, Accuracy: 0.693359375\n",
      "Batch: 67, Loss: 1.0762810707092285, Accuracy: 0.658203125\n",
      "Batch: 68, Loss: 1.0816261768341064, Accuracy: 0.6552734375\n",
      "Batch: 69, Loss: 1.0279245376586914, Accuracy: 0.669921875\n",
      "Batch: 70, Loss: 1.0199368000030518, Accuracy: 0.6904296875\n",
      "Batch: 71, Loss: 1.0201959609985352, Accuracy: 0.6806640625\n",
      "Batch: 72, Loss: 0.8933934569358826, Accuracy: 0.703125\n",
      "Batch: 73, Loss: 0.9600957632064819, Accuracy: 0.6982421875\n",
      "Batch: 74, Loss: 0.9161536693572998, Accuracy: 0.712890625\n",
      "Batch: 75, Loss: 0.8661478757858276, Accuracy: 0.708984375\n",
      "Batch: 76, Loss: 1.017214298248291, Accuracy: 0.66796875\n",
      "Batch: 77, Loss: 0.9397773742675781, Accuracy: 0.6982421875\n",
      "Batch: 78, Loss: 0.9609867334365845, Accuracy: 0.6884765625\n",
      "Batch: 79, Loss: 0.8819785118103027, Accuracy: 0.7373046875\n",
      "Batch: 80, Loss: 0.9351672530174255, Accuracy: 0.689453125\n",
      "Batch: 81, Loss: 1.0663108825683594, Accuracy: 0.6474609375\n",
      "Batch: 82, Loss: 1.0185284614562988, Accuracy: 0.67578125\n",
      "Batch: 83, Loss: 0.8945100903511047, Accuracy: 0.7138671875\n",
      "Batch: 84, Loss: 0.9766994118690491, Accuracy: 0.689453125\n",
      "Batch: 85, Loss: 0.9065964221954346, Accuracy: 0.7109375\n",
      "Batch: 86, Loss: 1.1014314889907837, Accuracy: 0.662109375\n",
      "Batch: 87, Loss: 0.9173102974891663, Accuracy: 0.7216796875\n",
      "Batch: 88, Loss: 1.0361461639404297, Accuracy: 0.6845703125\n",
      "Batch: 89, Loss: 1.031794786453247, Accuracy: 0.66796875\n",
      "Batch: 90, Loss: 0.9391972422599792, Accuracy: 0.6982421875\n",
      "Batch: 91, Loss: 0.9953404664993286, Accuracy: 0.673828125\n",
      "Batch: 92, Loss: 0.9850798845291138, Accuracy: 0.6826171875\n",
      "Batch: 93, Loss: 0.9511573314666748, Accuracy: 0.69140625\n",
      "Batch: 94, Loss: 0.9143069982528687, Accuracy: 0.7060546875\n",
      "Batch: 95, Loss: 1.0342237949371338, Accuracy: 0.6552734375\n",
      "Batch: 96, Loss: 0.9908406138420105, Accuracy: 0.671875\n",
      "Batch: 97, Loss: 0.8672318458557129, Accuracy: 0.7109375\n",
      "Batch: 98, Loss: 0.8991155028343201, Accuracy: 0.724609375\n",
      "Batch: 99, Loss: 0.9006859660148621, Accuracy: 0.7041015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 100, Loss: 0.9602817893028259, Accuracy: 0.6923828125\n",
      "Batch: 101, Loss: 1.0356385707855225, Accuracy: 0.6591796875\n",
      "Batch: 102, Loss: 0.976521372795105, Accuracy: 0.681640625\n",
      "Batch: 103, Loss: 1.0401971340179443, Accuracy: 0.671875\n",
      "Batch: 104, Loss: 0.9371981620788574, Accuracy: 0.6826171875\n",
      "Batch: 105, Loss: 1.0142698287963867, Accuracy: 0.6767578125\n",
      "Batch: 106, Loss: 0.9545291662216187, Accuracy: 0.701171875\n",
      "Batch: 107, Loss: 1.0253939628601074, Accuracy: 0.677734375\n",
      "Batch: 108, Loss: 0.9996119737625122, Accuracy: 0.6708984375\n",
      "Batch: 109, Loss: 1.129730463027954, Accuracy: 0.6328125\n",
      "Batch: 110, Loss: 0.8633185625076294, Accuracy: 0.712890625\n",
      "Batch: 111, Loss: 1.0521024465560913, Accuracy: 0.6396484375\n",
      "Batch: 112, Loss: 0.9821859002113342, Accuracy: 0.693359375\n",
      "Batch: 113, Loss: 0.9871901273727417, Accuracy: 0.69140625\n",
      "Batch: 114, Loss: 1.11223566532135, Accuracy: 0.6494140625\n",
      "Batch: 115, Loss: 1.110122799873352, Accuracy: 0.662109375\n",
      "Batch: 116, Loss: 1.058707356452942, Accuracy: 0.6513671875\n",
      "Batch: 117, Loss: 1.0639333724975586, Accuracy: 0.6748046875\n",
      "Batch: 118, Loss: 0.8980392217636108, Accuracy: 0.7109375\n",
      "Batch: 119, Loss: 0.9115037322044373, Accuracy: 0.71875\n",
      "Batch: 120, Loss: 1.0550614595413208, Accuracy: 0.6611328125\n",
      "Batch: 121, Loss: 1.0557291507720947, Accuracy: 0.6728515625\n",
      "Batch: 122, Loss: 0.9623832702636719, Accuracy: 0.681640625\n",
      "Batch: 123, Loss: 0.9566267728805542, Accuracy: 0.7060546875\n",
      "Batch: 124, Loss: 1.0642266273498535, Accuracy: 0.6611328125\n",
      "Batch: 125, Loss: 1.0651278495788574, Accuracy: 0.658203125\n",
      "Batch: 126, Loss: 1.0285561084747314, Accuracy: 0.662109375\n",
      "Batch: 127, Loss: 0.9026334285736084, Accuracy: 0.7265625\n",
      "Batch: 128, Loss: 1.1007014513015747, Accuracy: 0.6611328125\n",
      "Batch: 129, Loss: 0.9600958228111267, Accuracy: 0.685546875\n",
      "Batch: 130, Loss: 1.1861774921417236, Accuracy: 0.6279296875\n",
      "Batch: 131, Loss: 1.0420594215393066, Accuracy: 0.6630859375\n",
      "Batch: 132, Loss: 1.0896427631378174, Accuracy: 0.6552734375\n",
      "Batch: 133, Loss: 0.9791043400764465, Accuracy: 0.66015625\n",
      "Batch: 134, Loss: 1.0160835981369019, Accuracy: 0.669921875\n",
      "Batch: 135, Loss: 0.9131218791007996, Accuracy: 0.7060546875\n",
      "Batch: 136, Loss: 0.9927136898040771, Accuracy: 0.68359375\n",
      "Batch: 137, Loss: 0.9386451244354248, Accuracy: 0.6728515625\n",
      "Batch: 138, Loss: 0.833798348903656, Accuracy: 0.7197265625\n",
      "Batch: 139, Loss: 0.9237020015716553, Accuracy: 0.6904296875\n",
      "Batch: 140, Loss: 0.9956082701683044, Accuracy: 0.6748046875\n",
      "Batch: 141, Loss: 1.032415509223938, Accuracy: 0.677734375\n",
      "Batch: 142, Loss: 1.0344469547271729, Accuracy: 0.6650390625\n",
      "Batch: 143, Loss: 1.0150539875030518, Accuracy: 0.66015625\n",
      "Batch: 144, Loss: 0.997023344039917, Accuracy: 0.6669921875\n",
      "Batch: 145, Loss: 0.9458140134811401, Accuracy: 0.6796875\n",
      "Batch: 146, Loss: 1.0223495960235596, Accuracy: 0.65625\n",
      "Batch: 147, Loss: 1.0193381309509277, Accuracy: 0.6689453125\n",
      "Batch: 148, Loss: 1.1219944953918457, Accuracy: 0.6435546875\n",
      "Batch: 149, Loss: 1.0061054229736328, Accuracy: 0.66796875\n",
      "Batch: 150, Loss: 0.9384382963180542, Accuracy: 0.685546875\n",
      "Batch: 151, Loss: 0.8582456111907959, Accuracy: 0.7216796875\n",
      "Epoch 17/90\n",
      "Batch: 1, Loss: 1.2170848846435547, Accuracy: 0.6298828125\n",
      "Batch: 2, Loss: 1.0733938217163086, Accuracy: 0.6435546875\n",
      "Batch: 3, Loss: 0.9811229705810547, Accuracy: 0.6806640625\n",
      "Batch: 4, Loss: 0.8921202421188354, Accuracy: 0.70703125\n",
      "Batch: 5, Loss: 0.8870209455490112, Accuracy: 0.708984375\n",
      "Batch: 6, Loss: 0.9766085147857666, Accuracy: 0.677734375\n",
      "Batch: 7, Loss: 0.957129716873169, Accuracy: 0.671875\n",
      "Batch: 8, Loss: 0.9046282768249512, Accuracy: 0.685546875\n",
      "Batch: 9, Loss: 0.8696267008781433, Accuracy: 0.7119140625\n",
      "Batch: 10, Loss: 0.8766704201698303, Accuracy: 0.7119140625\n",
      "Batch: 11, Loss: 1.0649824142456055, Accuracy: 0.65625\n",
      "Batch: 12, Loss: 1.0650994777679443, Accuracy: 0.6552734375\n",
      "Batch: 13, Loss: 0.802169919013977, Accuracy: 0.73828125\n",
      "Batch: 14, Loss: 1.0820655822753906, Accuracy: 0.6474609375\n",
      "Batch: 15, Loss: 0.9225635528564453, Accuracy: 0.7197265625\n",
      "Batch: 16, Loss: 0.923080563545227, Accuracy: 0.70703125\n",
      "Batch: 17, Loss: 1.0031074285507202, Accuracy: 0.6748046875\n",
      "Batch: 18, Loss: 0.9965487718582153, Accuracy: 0.6640625\n",
      "Batch: 19, Loss: 1.0577147006988525, Accuracy: 0.671875\n",
      "Batch: 20, Loss: 0.905241847038269, Accuracy: 0.716796875\n",
      "Batch: 21, Loss: 0.9256526231765747, Accuracy: 0.69921875\n",
      "Batch: 22, Loss: 1.0550200939178467, Accuracy: 0.669921875\n",
      "Batch: 23, Loss: 0.9633852243423462, Accuracy: 0.6826171875\n",
      "Batch: 24, Loss: 1.0018701553344727, Accuracy: 0.6630859375\n",
      "Batch: 25, Loss: 0.9696635007858276, Accuracy: 0.673828125\n",
      "Batch: 26, Loss: 0.8419044017791748, Accuracy: 0.7177734375\n",
      "Batch: 27, Loss: 0.9233251810073853, Accuracy: 0.6923828125\n",
      "Batch: 28, Loss: 1.0270272493362427, Accuracy: 0.666015625\n",
      "Batch: 29, Loss: 1.0006191730499268, Accuracy: 0.669921875\n",
      "Batch: 30, Loss: 0.9046529531478882, Accuracy: 0.7158203125\n",
      "Batch: 31, Loss: 0.895893931388855, Accuracy: 0.7158203125\n",
      "Batch: 32, Loss: 0.86695396900177, Accuracy: 0.7158203125\n",
      "Batch: 33, Loss: 1.0272798538208008, Accuracy: 0.669921875\n",
      "Batch: 34, Loss: 1.122398853302002, Accuracy: 0.6357421875\n",
      "Batch: 35, Loss: 1.0011096000671387, Accuracy: 0.673828125\n",
      "Batch: 36, Loss: 1.0326552391052246, Accuracy: 0.666015625\n",
      "Batch: 37, Loss: 0.9838933944702148, Accuracy: 0.6943359375\n",
      "Batch: 38, Loss: 0.9898629188537598, Accuracy: 0.6650390625\n",
      "Batch: 39, Loss: 1.0061310529708862, Accuracy: 0.6796875\n",
      "Batch: 40, Loss: 1.0170645713806152, Accuracy: 0.67578125\n",
      "Batch: 41, Loss: 0.9548361301422119, Accuracy: 0.7060546875\n",
      "Batch: 42, Loss: 0.795979380607605, Accuracy: 0.7412109375\n",
      "Batch: 43, Loss: 1.0227112770080566, Accuracy: 0.6630859375\n",
      "Batch: 44, Loss: 0.9977646470069885, Accuracy: 0.6806640625\n",
      "Batch: 45, Loss: 0.8548450469970703, Accuracy: 0.7080078125\n",
      "Batch: 46, Loss: 0.9492614269256592, Accuracy: 0.7080078125\n",
      "Batch: 47, Loss: 0.9376605749130249, Accuracy: 0.69921875\n",
      "Batch: 48, Loss: 0.8770461082458496, Accuracy: 0.712890625\n",
      "Batch: 49, Loss: 1.0755149126052856, Accuracy: 0.64453125\n",
      "Batch: 50, Loss: 1.0577242374420166, Accuracy: 0.6640625\n",
      "Batch: 51, Loss: 1.0952128171920776, Accuracy: 0.6455078125\n",
      "Batch: 52, Loss: 1.0304367542266846, Accuracy: 0.671875\n",
      "Batch: 53, Loss: 0.893722414970398, Accuracy: 0.701171875\n",
      "Batch: 54, Loss: 0.9602479338645935, Accuracy: 0.68359375\n",
      "Batch: 55, Loss: 1.0376642942428589, Accuracy: 0.654296875\n",
      "Batch: 56, Loss: 1.0152217149734497, Accuracy: 0.658203125\n",
      "Batch: 57, Loss: 0.9749330282211304, Accuracy: 0.689453125\n",
      "Batch: 58, Loss: 1.0431350469589233, Accuracy: 0.67578125\n",
      "Batch: 59, Loss: 0.9524863362312317, Accuracy: 0.69140625\n",
      "Batch: 60, Loss: 0.8710250854492188, Accuracy: 0.7236328125\n",
      "Batch: 61, Loss: 0.9826931953430176, Accuracy: 0.669921875\n",
      "Batch: 62, Loss: 0.9253497123718262, Accuracy: 0.6953125\n",
      "Batch: 63, Loss: 0.9877198934555054, Accuracy: 0.66796875\n",
      "Batch: 64, Loss: 0.9686615467071533, Accuracy: 0.6669921875\n",
      "Batch: 65, Loss: 0.9945049285888672, Accuracy: 0.6806640625\n",
      "Batch: 66, Loss: 0.9468684196472168, Accuracy: 0.7109375\n",
      "Batch: 67, Loss: 1.0475938320159912, Accuracy: 0.6708984375\n",
      "Batch: 68, Loss: 1.0729877948760986, Accuracy: 0.658203125\n",
      "Batch: 69, Loss: 0.9915090799331665, Accuracy: 0.6708984375\n",
      "Batch: 70, Loss: 0.9607459306716919, Accuracy: 0.6982421875\n",
      "Batch: 71, Loss: 1.0012662410736084, Accuracy: 0.6796875\n",
      "Batch: 72, Loss: 0.8902491331100464, Accuracy: 0.69921875\n",
      "Batch: 73, Loss: 0.9127231240272522, Accuracy: 0.705078125\n",
      "Batch: 74, Loss: 0.889481782913208, Accuracy: 0.7216796875\n",
      "Batch: 75, Loss: 0.8703045845031738, Accuracy: 0.7177734375\n",
      "Batch: 76, Loss: 0.9947562217712402, Accuracy: 0.669921875\n",
      "Batch: 77, Loss: 0.9126605987548828, Accuracy: 0.705078125\n",
      "Batch: 78, Loss: 0.9507327079772949, Accuracy: 0.701171875\n",
      "Batch: 79, Loss: 0.8437466621398926, Accuracy: 0.7412109375\n",
      "Batch: 80, Loss: 0.9264959692955017, Accuracy: 0.689453125\n",
      "Batch: 81, Loss: 1.0126227140426636, Accuracy: 0.6611328125\n",
      "Batch: 82, Loss: 0.9937005043029785, Accuracy: 0.6796875\n",
      "Batch: 83, Loss: 0.8523432016372681, Accuracy: 0.7333984375\n",
      "Batch: 84, Loss: 0.9580739736557007, Accuracy: 0.703125\n",
      "Batch: 85, Loss: 0.8840259909629822, Accuracy: 0.71875\n",
      "Batch: 86, Loss: 1.08978271484375, Accuracy: 0.6572265625\n",
      "Batch: 87, Loss: 0.8943926095962524, Accuracy: 0.720703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 88, Loss: 1.0180649757385254, Accuracy: 0.6884765625\n",
      "Batch: 89, Loss: 0.9998664855957031, Accuracy: 0.6806640625\n",
      "Batch: 90, Loss: 0.900465726852417, Accuracy: 0.72265625\n",
      "Batch: 91, Loss: 0.9749845266342163, Accuracy: 0.66796875\n",
      "Batch: 92, Loss: 0.9555928707122803, Accuracy: 0.6787109375\n",
      "Batch: 93, Loss: 0.9328891634941101, Accuracy: 0.7099609375\n",
      "Batch: 94, Loss: 0.9354931116104126, Accuracy: 0.6943359375\n",
      "Batch: 95, Loss: 0.9882299900054932, Accuracy: 0.669921875\n",
      "Batch: 96, Loss: 0.9726316928863525, Accuracy: 0.693359375\n",
      "Batch: 97, Loss: 0.8424839973449707, Accuracy: 0.724609375\n",
      "Batch: 98, Loss: 0.8846262693405151, Accuracy: 0.712890625\n",
      "Batch: 99, Loss: 0.8569912910461426, Accuracy: 0.7314453125\n",
      "Batch: 100, Loss: 0.9335037469863892, Accuracy: 0.7041015625\n",
      "Batch: 101, Loss: 1.026830792427063, Accuracy: 0.671875\n",
      "Batch: 102, Loss: 0.9354352951049805, Accuracy: 0.6875\n",
      "Batch: 103, Loss: 1.0129485130310059, Accuracy: 0.671875\n",
      "Batch: 104, Loss: 0.9178332090377808, Accuracy: 0.703125\n",
      "Batch: 105, Loss: 0.9913897514343262, Accuracy: 0.67578125\n",
      "Batch: 106, Loss: 0.9539822936058044, Accuracy: 0.7001953125\n",
      "Batch: 107, Loss: 1.0013827085494995, Accuracy: 0.6826171875\n",
      "Batch: 108, Loss: 0.9645802974700928, Accuracy: 0.6845703125\n",
      "Batch: 109, Loss: 1.1132137775421143, Accuracy: 0.642578125\n",
      "Batch: 110, Loss: 0.8388538956642151, Accuracy: 0.73046875\n",
      "Batch: 111, Loss: 1.0101505517959595, Accuracy: 0.6591796875\n",
      "Batch: 112, Loss: 0.9507598876953125, Accuracy: 0.70703125\n",
      "Batch: 113, Loss: 0.968908429145813, Accuracy: 0.705078125\n",
      "Batch: 114, Loss: 1.069011926651001, Accuracy: 0.6533203125\n",
      "Batch: 115, Loss: 1.0844087600708008, Accuracy: 0.6484375\n",
      "Batch: 116, Loss: 1.0437558889389038, Accuracy: 0.6708984375\n",
      "Batch: 117, Loss: 1.0328367948532104, Accuracy: 0.6640625\n",
      "Batch: 118, Loss: 0.8871174454689026, Accuracy: 0.70703125\n",
      "Batch: 119, Loss: 0.8716412782669067, Accuracy: 0.7197265625\n",
      "Batch: 120, Loss: 0.9937160015106201, Accuracy: 0.6796875\n",
      "Batch: 121, Loss: 1.0296483039855957, Accuracy: 0.6767578125\n",
      "Batch: 122, Loss: 0.9529298543930054, Accuracy: 0.6904296875\n",
      "Batch: 123, Loss: 0.9477001428604126, Accuracy: 0.705078125\n",
      "Batch: 124, Loss: 1.0139026641845703, Accuracy: 0.6728515625\n",
      "Batch: 125, Loss: 1.0297398567199707, Accuracy: 0.6650390625\n",
      "Batch: 126, Loss: 1.005673885345459, Accuracy: 0.6748046875\n",
      "Batch: 127, Loss: 0.8992869853973389, Accuracy: 0.720703125\n",
      "Batch: 128, Loss: 1.0866317749023438, Accuracy: 0.66796875\n",
      "Batch: 129, Loss: 0.9184737801551819, Accuracy: 0.703125\n",
      "Batch: 130, Loss: 1.1505625247955322, Accuracy: 0.626953125\n",
      "Batch: 131, Loss: 1.0666024684906006, Accuracy: 0.662109375\n",
      "Batch: 132, Loss: 1.0432208776474, Accuracy: 0.6767578125\n",
      "Batch: 133, Loss: 0.9364205002784729, Accuracy: 0.6923828125\n",
      "Batch: 134, Loss: 0.9880180954933167, Accuracy: 0.6806640625\n",
      "Batch: 135, Loss: 0.8872488737106323, Accuracy: 0.7080078125\n",
      "Batch: 136, Loss: 0.9931861162185669, Accuracy: 0.7001953125\n",
      "Batch: 137, Loss: 0.918879508972168, Accuracy: 0.6845703125\n",
      "Batch: 138, Loss: 0.809546947479248, Accuracy: 0.73046875\n",
      "Batch: 139, Loss: 0.8781843185424805, Accuracy: 0.7177734375\n",
      "Batch: 140, Loss: 0.9801645874977112, Accuracy: 0.685546875\n",
      "Batch: 141, Loss: 1.025156855583191, Accuracy: 0.6728515625\n",
      "Batch: 142, Loss: 1.0093822479248047, Accuracy: 0.6796875\n",
      "Batch: 143, Loss: 0.984635591506958, Accuracy: 0.6748046875\n",
      "Batch: 144, Loss: 0.9722558259963989, Accuracy: 0.69140625\n",
      "Batch: 145, Loss: 0.9482159614562988, Accuracy: 0.6767578125\n",
      "Batch: 146, Loss: 0.9934219121932983, Accuracy: 0.6826171875\n",
      "Batch: 147, Loss: 0.9620362520217896, Accuracy: 0.6982421875\n",
      "Batch: 148, Loss: 1.087243914604187, Accuracy: 0.646484375\n",
      "Batch: 149, Loss: 0.9610215425491333, Accuracy: 0.6845703125\n",
      "Batch: 150, Loss: 0.8888462781906128, Accuracy: 0.7041015625\n",
      "Batch: 151, Loss: 0.8188229203224182, Accuracy: 0.7294921875\n",
      "Epoch 18/90\n",
      "Batch: 1, Loss: 1.2073054313659668, Accuracy: 0.60546875\n",
      "Batch: 2, Loss: 1.053997278213501, Accuracy: 0.6474609375\n",
      "Batch: 3, Loss: 0.9327720403671265, Accuracy: 0.6806640625\n",
      "Batch: 4, Loss: 0.8326857089996338, Accuracy: 0.734375\n",
      "Batch: 5, Loss: 0.8451964855194092, Accuracy: 0.716796875\n",
      "Batch: 6, Loss: 0.9788018465042114, Accuracy: 0.689453125\n",
      "Batch: 7, Loss: 0.9382648468017578, Accuracy: 0.6962890625\n",
      "Batch: 8, Loss: 0.8868831992149353, Accuracy: 0.69921875\n",
      "Batch: 9, Loss: 0.8826277256011963, Accuracy: 0.7197265625\n",
      "Batch: 10, Loss: 0.856263279914856, Accuracy: 0.7197265625\n",
      "Batch: 11, Loss: 1.0371779203414917, Accuracy: 0.6650390625\n",
      "Batch: 12, Loss: 1.0399469137191772, Accuracy: 0.6591796875\n",
      "Batch: 13, Loss: 0.7748175859451294, Accuracy: 0.748046875\n",
      "Batch: 14, Loss: 1.0406363010406494, Accuracy: 0.666015625\n",
      "Batch: 15, Loss: 0.8854882717132568, Accuracy: 0.720703125\n",
      "Batch: 16, Loss: 0.9040369987487793, Accuracy: 0.7236328125\n",
      "Batch: 17, Loss: 1.0111018419265747, Accuracy: 0.6796875\n",
      "Batch: 18, Loss: 0.9576399922370911, Accuracy: 0.6865234375\n",
      "Batch: 19, Loss: 1.0313231945037842, Accuracy: 0.6865234375\n",
      "Batch: 20, Loss: 0.8835859894752502, Accuracy: 0.72265625\n",
      "Batch: 21, Loss: 0.8874267339706421, Accuracy: 0.7060546875\n",
      "Batch: 22, Loss: 1.0031973123550415, Accuracy: 0.677734375\n",
      "Batch: 23, Loss: 0.9593380689620972, Accuracy: 0.6982421875\n",
      "Batch: 24, Loss: 0.9684610366821289, Accuracy: 0.6806640625\n",
      "Batch: 25, Loss: 0.9704238176345825, Accuracy: 0.6748046875\n",
      "Batch: 26, Loss: 0.8140178322792053, Accuracy: 0.71484375\n",
      "Batch: 27, Loss: 0.8775404691696167, Accuracy: 0.6875\n",
      "Batch: 28, Loss: 1.008387565612793, Accuracy: 0.6572265625\n",
      "Batch: 29, Loss: 0.9733991622924805, Accuracy: 0.6787109375\n",
      "Batch: 30, Loss: 0.8984068036079407, Accuracy: 0.7158203125\n",
      "Batch: 31, Loss: 0.8900983929634094, Accuracy: 0.7177734375\n",
      "Batch: 32, Loss: 0.8553814888000488, Accuracy: 0.7099609375\n",
      "Batch: 33, Loss: 1.0062503814697266, Accuracy: 0.6865234375\n",
      "Batch: 34, Loss: 1.082003116607666, Accuracy: 0.6533203125\n",
      "Batch: 35, Loss: 1.0049452781677246, Accuracy: 0.6689453125\n",
      "Batch: 36, Loss: 1.0214402675628662, Accuracy: 0.677734375\n",
      "Batch: 37, Loss: 0.941299319267273, Accuracy: 0.6875\n",
      "Batch: 38, Loss: 0.9968432784080505, Accuracy: 0.6787109375\n",
      "Batch: 39, Loss: 0.9795236587524414, Accuracy: 0.689453125\n",
      "Batch: 40, Loss: 0.9963195323944092, Accuracy: 0.685546875\n",
      "Batch: 41, Loss: 0.9507668018341064, Accuracy: 0.6982421875\n",
      "Batch: 42, Loss: 0.7515430450439453, Accuracy: 0.73046875\n",
      "Batch: 43, Loss: 0.9840652942657471, Accuracy: 0.67578125\n",
      "Batch: 44, Loss: 0.9804290533065796, Accuracy: 0.6796875\n",
      "Batch: 45, Loss: 0.8657792210578918, Accuracy: 0.7138671875\n",
      "Batch: 46, Loss: 0.9414761066436768, Accuracy: 0.7001953125\n",
      "Batch: 47, Loss: 0.9057904481887817, Accuracy: 0.7265625\n",
      "Batch: 48, Loss: 0.8598872423171997, Accuracy: 0.71484375\n",
      "Batch: 49, Loss: 1.0545728206634521, Accuracy: 0.6416015625\n",
      "Batch: 50, Loss: 0.9974160194396973, Accuracy: 0.6728515625\n",
      "Batch: 51, Loss: 1.0575956106185913, Accuracy: 0.6484375\n",
      "Batch: 52, Loss: 1.00394868850708, Accuracy: 0.6767578125\n",
      "Batch: 53, Loss: 0.8761862516403198, Accuracy: 0.7060546875\n",
      "Batch: 54, Loss: 0.9424175024032593, Accuracy: 0.6875\n",
      "Batch: 55, Loss: 1.0203428268432617, Accuracy: 0.65234375\n",
      "Batch: 56, Loss: 1.016746997833252, Accuracy: 0.6689453125\n",
      "Batch: 57, Loss: 0.9415905475616455, Accuracy: 0.6923828125\n",
      "Batch: 58, Loss: 1.011549472808838, Accuracy: 0.69921875\n",
      "Batch: 59, Loss: 0.9060988426208496, Accuracy: 0.7080078125\n",
      "Batch: 60, Loss: 0.858971893787384, Accuracy: 0.712890625\n",
      "Batch: 61, Loss: 0.9758750200271606, Accuracy: 0.6796875\n",
      "Batch: 62, Loss: 0.9145733714103699, Accuracy: 0.6865234375\n",
      "Batch: 63, Loss: 0.9475775957107544, Accuracy: 0.685546875\n",
      "Batch: 64, Loss: 0.9482139348983765, Accuracy: 0.689453125\n",
      "Batch: 65, Loss: 0.9561392068862915, Accuracy: 0.685546875\n",
      "Batch: 66, Loss: 0.9255169034004211, Accuracy: 0.71484375\n",
      "Batch: 67, Loss: 1.0087757110595703, Accuracy: 0.6865234375\n",
      "Batch: 68, Loss: 1.0217351913452148, Accuracy: 0.669921875\n",
      "Batch: 69, Loss: 0.976017415523529, Accuracy: 0.6923828125\n",
      "Batch: 70, Loss: 0.9471397399902344, Accuracy: 0.701171875\n",
      "Batch: 71, Loss: 0.9929646253585815, Accuracy: 0.6728515625\n",
      "Batch: 72, Loss: 0.8298971652984619, Accuracy: 0.73046875\n",
      "Batch: 73, Loss: 0.9084724187850952, Accuracy: 0.71484375\n",
      "Batch: 74, Loss: 0.8687819242477417, Accuracy: 0.73046875\n",
      "Batch: 75, Loss: 0.8383747339248657, Accuracy: 0.7265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 76, Loss: 0.9647672176361084, Accuracy: 0.6787109375\n",
      "Batch: 77, Loss: 0.8919663429260254, Accuracy: 0.7060546875\n",
      "Batch: 78, Loss: 0.9184198379516602, Accuracy: 0.705078125\n",
      "Batch: 79, Loss: 0.8419902324676514, Accuracy: 0.748046875\n",
      "Batch: 80, Loss: 0.9024439454078674, Accuracy: 0.6962890625\n",
      "Batch: 81, Loss: 1.01261568069458, Accuracy: 0.66015625\n",
      "Batch: 82, Loss: 0.948672890663147, Accuracy: 0.6953125\n",
      "Batch: 83, Loss: 0.8524429798126221, Accuracy: 0.734375\n",
      "Batch: 84, Loss: 0.9277202486991882, Accuracy: 0.716796875\n",
      "Batch: 85, Loss: 0.8754631280899048, Accuracy: 0.7265625\n",
      "Batch: 86, Loss: 1.0518240928649902, Accuracy: 0.6494140625\n",
      "Batch: 87, Loss: 0.8640905618667603, Accuracy: 0.7333984375\n",
      "Batch: 88, Loss: 0.9925441145896912, Accuracy: 0.6953125\n",
      "Batch: 89, Loss: 0.9696611762046814, Accuracy: 0.6923828125\n",
      "Batch: 90, Loss: 0.8800462484359741, Accuracy: 0.724609375\n",
      "Batch: 91, Loss: 0.9187772274017334, Accuracy: 0.701171875\n",
      "Batch: 92, Loss: 0.9338973760604858, Accuracy: 0.697265625\n",
      "Batch: 93, Loss: 0.9138820171356201, Accuracy: 0.689453125\n",
      "Batch: 94, Loss: 0.9170464277267456, Accuracy: 0.69921875\n",
      "Batch: 95, Loss: 0.964910626411438, Accuracy: 0.6728515625\n",
      "Batch: 96, Loss: 0.9129351377487183, Accuracy: 0.6962890625\n",
      "Batch: 97, Loss: 0.8192588090896606, Accuracy: 0.7236328125\n",
      "Batch: 98, Loss: 0.8458208441734314, Accuracy: 0.72265625\n",
      "Batch: 99, Loss: 0.8644862174987793, Accuracy: 0.7041015625\n",
      "Batch: 100, Loss: 0.9219181537628174, Accuracy: 0.716796875\n",
      "Batch: 101, Loss: 0.9786677360534668, Accuracy: 0.68359375\n",
      "Batch: 102, Loss: 0.894395112991333, Accuracy: 0.7216796875\n",
      "Batch: 103, Loss: 0.9855103492736816, Accuracy: 0.69140625\n",
      "Batch: 104, Loss: 0.8767105340957642, Accuracy: 0.6962890625\n",
      "Batch: 105, Loss: 0.9760140180587769, Accuracy: 0.6923828125\n",
      "Batch: 106, Loss: 0.8879386186599731, Accuracy: 0.73046875\n",
      "Batch: 107, Loss: 0.964163064956665, Accuracy: 0.7021484375\n",
      "Batch: 108, Loss: 0.9422517418861389, Accuracy: 0.689453125\n",
      "Batch: 109, Loss: 1.0854581594467163, Accuracy: 0.6435546875\n",
      "Batch: 110, Loss: 0.8281615972518921, Accuracy: 0.7353515625\n",
      "Batch: 111, Loss: 1.000070333480835, Accuracy: 0.6689453125\n",
      "Batch: 112, Loss: 0.9434059858322144, Accuracy: 0.697265625\n",
      "Batch: 113, Loss: 0.9581823348999023, Accuracy: 0.70703125\n",
      "Batch: 114, Loss: 1.0420321226119995, Accuracy: 0.6591796875\n",
      "Batch: 115, Loss: 1.0636625289916992, Accuracy: 0.658203125\n",
      "Batch: 116, Loss: 1.0196093320846558, Accuracy: 0.650390625\n",
      "Batch: 117, Loss: 1.0051742792129517, Accuracy: 0.681640625\n",
      "Batch: 118, Loss: 0.8705011606216431, Accuracy: 0.7158203125\n",
      "Batch: 119, Loss: 0.8696630597114563, Accuracy: 0.724609375\n",
      "Batch: 120, Loss: 0.9874131679534912, Accuracy: 0.6708984375\n",
      "Batch: 121, Loss: 0.9917092323303223, Accuracy: 0.671875\n",
      "Batch: 122, Loss: 0.8915740847587585, Accuracy: 0.705078125\n",
      "Batch: 123, Loss: 0.8949534893035889, Accuracy: 0.7158203125\n",
      "Batch: 124, Loss: 0.9922597408294678, Accuracy: 0.67578125\n",
      "Batch: 125, Loss: 0.9894860982894897, Accuracy: 0.6787109375\n",
      "Batch: 126, Loss: 0.9652276039123535, Accuracy: 0.6796875\n",
      "Batch: 127, Loss: 0.8425588607788086, Accuracy: 0.7236328125\n",
      "Batch: 128, Loss: 1.060644268989563, Accuracy: 0.671875\n",
      "Batch: 129, Loss: 0.9022314548492432, Accuracy: 0.7099609375\n",
      "Batch: 130, Loss: 1.1112911701202393, Accuracy: 0.6455078125\n",
      "Batch: 131, Loss: 0.9951937198638916, Accuracy: 0.681640625\n",
      "Batch: 132, Loss: 1.0328491926193237, Accuracy: 0.671875\n",
      "Batch: 133, Loss: 0.8935230374336243, Accuracy: 0.705078125\n",
      "Batch: 134, Loss: 0.9868083596229553, Accuracy: 0.673828125\n",
      "Batch: 135, Loss: 0.8662024736404419, Accuracy: 0.720703125\n",
      "Batch: 136, Loss: 0.9326410889625549, Accuracy: 0.701171875\n",
      "Batch: 137, Loss: 0.9209261536598206, Accuracy: 0.6923828125\n",
      "Batch: 138, Loss: 0.8009377121925354, Accuracy: 0.7373046875\n",
      "Batch: 139, Loss: 0.8618491291999817, Accuracy: 0.71484375\n",
      "Batch: 140, Loss: 0.9286513328552246, Accuracy: 0.708984375\n",
      "Batch: 141, Loss: 0.9860787391662598, Accuracy: 0.6884765625\n",
      "Batch: 142, Loss: 0.9676014184951782, Accuracy: 0.6875\n",
      "Batch: 143, Loss: 0.9576581716537476, Accuracy: 0.69140625\n",
      "Batch: 144, Loss: 0.9603984355926514, Accuracy: 0.697265625\n",
      "Batch: 145, Loss: 0.8981218934059143, Accuracy: 0.6923828125\n",
      "Batch: 146, Loss: 0.947922945022583, Accuracy: 0.689453125\n",
      "Batch: 147, Loss: 0.979991614818573, Accuracy: 0.6904296875\n",
      "Batch: 148, Loss: 1.0550130605697632, Accuracy: 0.6572265625\n",
      "Batch: 149, Loss: 0.9110314249992371, Accuracy: 0.6943359375\n",
      "Batch: 150, Loss: 0.8953239321708679, Accuracy: 0.69140625\n",
      "Batch: 151, Loss: 0.8102322816848755, Accuracy: 0.7412109375\n",
      "Epoch 19/90\n",
      "Batch: 1, Loss: 1.170076847076416, Accuracy: 0.62890625\n",
      "Batch: 2, Loss: 1.0291614532470703, Accuracy: 0.6416015625\n",
      "Batch: 3, Loss: 0.9298608303070068, Accuracy: 0.6962890625\n",
      "Batch: 4, Loss: 0.8393037915229797, Accuracy: 0.7138671875\n",
      "Batch: 5, Loss: 0.8345440626144409, Accuracy: 0.7392578125\n",
      "Batch: 6, Loss: 0.9417724013328552, Accuracy: 0.6962890625\n",
      "Batch: 7, Loss: 0.9233577251434326, Accuracy: 0.6982421875\n",
      "Batch: 8, Loss: 0.8554248809814453, Accuracy: 0.7216796875\n",
      "Batch: 9, Loss: 0.820257306098938, Accuracy: 0.734375\n",
      "Batch: 10, Loss: 0.8393271565437317, Accuracy: 0.7216796875\n",
      "Batch: 11, Loss: 1.0057876110076904, Accuracy: 0.673828125\n",
      "Batch: 12, Loss: 0.996559739112854, Accuracy: 0.669921875\n",
      "Batch: 13, Loss: 0.7917885780334473, Accuracy: 0.7392578125\n",
      "Batch: 14, Loss: 1.0214009284973145, Accuracy: 0.669921875\n",
      "Batch: 15, Loss: 0.897581934928894, Accuracy: 0.71875\n",
      "Batch: 16, Loss: 0.8668385148048401, Accuracy: 0.734375\n",
      "Batch: 17, Loss: 0.9542100429534912, Accuracy: 0.6962890625\n",
      "Batch: 18, Loss: 0.9747327566146851, Accuracy: 0.6796875\n",
      "Batch: 19, Loss: 0.9867846369743347, Accuracy: 0.68359375\n",
      "Batch: 20, Loss: 0.8792539834976196, Accuracy: 0.7158203125\n",
      "Batch: 21, Loss: 0.8800843358039856, Accuracy: 0.7109375\n",
      "Batch: 22, Loss: 1.028214693069458, Accuracy: 0.681640625\n",
      "Batch: 23, Loss: 0.9352452158927917, Accuracy: 0.6884765625\n",
      "Batch: 24, Loss: 0.9375249147415161, Accuracy: 0.6787109375\n",
      "Batch: 25, Loss: 0.9043058156967163, Accuracy: 0.7060546875\n",
      "Batch: 26, Loss: 0.8096228837966919, Accuracy: 0.72265625\n",
      "Batch: 27, Loss: 0.8619533777236938, Accuracy: 0.69140625\n",
      "Batch: 28, Loss: 0.9610990881919861, Accuracy: 0.673828125\n",
      "Batch: 29, Loss: 0.9559860229492188, Accuracy: 0.68359375\n",
      "Batch: 30, Loss: 0.8749023675918579, Accuracy: 0.7158203125\n",
      "Batch: 31, Loss: 0.8704742193222046, Accuracy: 0.716796875\n",
      "Batch: 32, Loss: 0.8290290832519531, Accuracy: 0.728515625\n",
      "Batch: 33, Loss: 0.9887387752532959, Accuracy: 0.681640625\n",
      "Batch: 34, Loss: 1.0678144693374634, Accuracy: 0.66796875\n",
      "Batch: 35, Loss: 0.9648932814598083, Accuracy: 0.6806640625\n",
      "Batch: 36, Loss: 0.9796162843704224, Accuracy: 0.6982421875\n",
      "Batch: 37, Loss: 0.9250589609146118, Accuracy: 0.7041015625\n",
      "Batch: 38, Loss: 0.9527106881141663, Accuracy: 0.671875\n",
      "Batch: 39, Loss: 0.9571083188056946, Accuracy: 0.6923828125\n",
      "Batch: 40, Loss: 0.9690908193588257, Accuracy: 0.69140625\n",
      "Batch: 41, Loss: 0.9247928857803345, Accuracy: 0.697265625\n",
      "Batch: 42, Loss: 0.7523183226585388, Accuracy: 0.7490234375\n",
      "Batch: 43, Loss: 0.9938135147094727, Accuracy: 0.6689453125\n",
      "Batch: 44, Loss: 0.9487993717193604, Accuracy: 0.69140625\n",
      "Batch: 45, Loss: 0.848522424697876, Accuracy: 0.7197265625\n",
      "Batch: 46, Loss: 0.8956813812255859, Accuracy: 0.724609375\n",
      "Batch: 47, Loss: 0.9032387733459473, Accuracy: 0.740234375\n",
      "Batch: 48, Loss: 0.8513568043708801, Accuracy: 0.7080078125\n",
      "Batch: 49, Loss: 1.0132558345794678, Accuracy: 0.6796875\n",
      "Batch: 50, Loss: 0.9723658561706543, Accuracy: 0.6826171875\n",
      "Batch: 51, Loss: 1.0282669067382812, Accuracy: 0.662109375\n",
      "Batch: 52, Loss: 0.9778297543525696, Accuracy: 0.689453125\n",
      "Batch: 53, Loss: 0.8335132598876953, Accuracy: 0.708984375\n",
      "Batch: 54, Loss: 0.9224740862846375, Accuracy: 0.6962890625\n",
      "Batch: 55, Loss: 1.0263285636901855, Accuracy: 0.6630859375\n",
      "Batch: 56, Loss: 1.0031349658966064, Accuracy: 0.6796875\n",
      "Batch: 57, Loss: 0.9156508445739746, Accuracy: 0.7060546875\n",
      "Batch: 58, Loss: 0.9916205406188965, Accuracy: 0.705078125\n",
      "Batch: 59, Loss: 0.8859697580337524, Accuracy: 0.7216796875\n",
      "Batch: 60, Loss: 0.8374559879302979, Accuracy: 0.7314453125\n",
      "Batch: 61, Loss: 0.9282718300819397, Accuracy: 0.69921875\n",
      "Batch: 62, Loss: 0.9028447270393372, Accuracy: 0.7099609375\n",
      "Batch: 63, Loss: 0.9367130994796753, Accuracy: 0.7041015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 64, Loss: 0.9154281616210938, Accuracy: 0.697265625\n",
      "Batch: 65, Loss: 0.947726845741272, Accuracy: 0.6962890625\n",
      "Batch: 66, Loss: 0.8960128426551819, Accuracy: 0.7216796875\n",
      "Batch: 67, Loss: 1.0273754596710205, Accuracy: 0.68359375\n",
      "Batch: 68, Loss: 0.9855525493621826, Accuracy: 0.6953125\n",
      "Batch: 69, Loss: 0.9570935964584351, Accuracy: 0.6826171875\n",
      "Batch: 70, Loss: 0.9347277879714966, Accuracy: 0.7197265625\n",
      "Batch: 71, Loss: 0.9928752183914185, Accuracy: 0.6728515625\n",
      "Batch: 72, Loss: 0.824841320514679, Accuracy: 0.7197265625\n",
      "Batch: 73, Loss: 0.8933885097503662, Accuracy: 0.7119140625\n",
      "Batch: 74, Loss: 0.8493785858154297, Accuracy: 0.7392578125\n",
      "Batch: 75, Loss: 0.815394401550293, Accuracy: 0.7451171875\n",
      "Batch: 76, Loss: 0.9274489879608154, Accuracy: 0.697265625\n",
      "Batch: 77, Loss: 0.867957592010498, Accuracy: 0.7177734375\n",
      "Batch: 78, Loss: 0.9005302786827087, Accuracy: 0.703125\n",
      "Batch: 79, Loss: 0.8057175874710083, Accuracy: 0.7587890625\n",
      "Batch: 80, Loss: 0.8867090940475464, Accuracy: 0.703125\n",
      "Batch: 81, Loss: 0.9802693128585815, Accuracy: 0.666015625\n",
      "Batch: 82, Loss: 0.9443339705467224, Accuracy: 0.703125\n",
      "Batch: 83, Loss: 0.8034719824790955, Accuracy: 0.7470703125\n",
      "Batch: 84, Loss: 0.8990432024002075, Accuracy: 0.72265625\n",
      "Batch: 85, Loss: 0.836871862411499, Accuracy: 0.736328125\n",
      "Batch: 86, Loss: 1.032698392868042, Accuracy: 0.67578125\n",
      "Batch: 87, Loss: 0.8369808197021484, Accuracy: 0.7412109375\n",
      "Batch: 88, Loss: 0.9655519723892212, Accuracy: 0.6982421875\n",
      "Batch: 89, Loss: 0.9709703922271729, Accuracy: 0.69140625\n",
      "Batch: 90, Loss: 0.8651223182678223, Accuracy: 0.72265625\n",
      "Batch: 91, Loss: 0.9246928691864014, Accuracy: 0.6943359375\n",
      "Batch: 92, Loss: 0.9226441979408264, Accuracy: 0.708984375\n",
      "Batch: 93, Loss: 0.8887568712234497, Accuracy: 0.7119140625\n",
      "Batch: 94, Loss: 0.8740584254264832, Accuracy: 0.7109375\n",
      "Batch: 95, Loss: 0.9662891626358032, Accuracy: 0.6708984375\n",
      "Batch: 96, Loss: 0.9302377700805664, Accuracy: 0.689453125\n",
      "Batch: 97, Loss: 0.7929835319519043, Accuracy: 0.732421875\n",
      "Batch: 98, Loss: 0.8541658520698547, Accuracy: 0.7314453125\n",
      "Batch: 99, Loss: 0.8369818925857544, Accuracy: 0.7236328125\n",
      "Batch: 100, Loss: 0.889036238193512, Accuracy: 0.71484375\n",
      "Batch: 101, Loss: 0.9602686166763306, Accuracy: 0.6982421875\n",
      "Batch: 102, Loss: 0.9002443552017212, Accuracy: 0.7060546875\n",
      "Batch: 103, Loss: 0.9578781723976135, Accuracy: 0.697265625\n",
      "Batch: 104, Loss: 0.8688380718231201, Accuracy: 0.7109375\n",
      "Batch: 105, Loss: 0.9386690855026245, Accuracy: 0.6767578125\n",
      "Batch: 106, Loss: 0.8860201835632324, Accuracy: 0.7265625\n",
      "Batch: 107, Loss: 0.9475692510604858, Accuracy: 0.6982421875\n",
      "Batch: 108, Loss: 0.9246375560760498, Accuracy: 0.68359375\n",
      "Batch: 109, Loss: 1.0393216609954834, Accuracy: 0.66015625\n",
      "Batch: 110, Loss: 0.8194823265075684, Accuracy: 0.734375\n",
      "Batch: 111, Loss: 0.9684357643127441, Accuracy: 0.6826171875\n",
      "Batch: 112, Loss: 0.9099215269088745, Accuracy: 0.716796875\n",
      "Batch: 113, Loss: 0.9223318099975586, Accuracy: 0.708984375\n",
      "Batch: 114, Loss: 1.00848388671875, Accuracy: 0.669921875\n",
      "Batch: 115, Loss: 1.0444716215133667, Accuracy: 0.669921875\n",
      "Batch: 116, Loss: 0.9683298468589783, Accuracy: 0.685546875\n",
      "Batch: 117, Loss: 0.9842654466629028, Accuracy: 0.693359375\n",
      "Batch: 118, Loss: 0.8402348160743713, Accuracy: 0.732421875\n",
      "Batch: 119, Loss: 0.826850414276123, Accuracy: 0.7255859375\n",
      "Batch: 120, Loss: 0.9670527577400208, Accuracy: 0.6904296875\n",
      "Batch: 121, Loss: 0.9750683903694153, Accuracy: 0.6953125\n",
      "Batch: 122, Loss: 0.9045846462249756, Accuracy: 0.7119140625\n",
      "Batch: 123, Loss: 0.878576397895813, Accuracy: 0.734375\n",
      "Batch: 124, Loss: 0.9446642398834229, Accuracy: 0.7001953125\n",
      "Batch: 125, Loss: 0.967391848564148, Accuracy: 0.67578125\n",
      "Batch: 126, Loss: 0.9463334083557129, Accuracy: 0.705078125\n",
      "Batch: 127, Loss: 0.8420511484146118, Accuracy: 0.7421875\n",
      "Batch: 128, Loss: 1.0343652963638306, Accuracy: 0.6728515625\n",
      "Batch: 129, Loss: 0.8855088949203491, Accuracy: 0.72265625\n",
      "Batch: 130, Loss: 1.0761466026306152, Accuracy: 0.6435546875\n",
      "Batch: 131, Loss: 0.97525954246521, Accuracy: 0.6748046875\n",
      "Batch: 132, Loss: 0.9842018485069275, Accuracy: 0.693359375\n",
      "Batch: 133, Loss: 0.8985311388969421, Accuracy: 0.6962890625\n",
      "Batch: 134, Loss: 0.9641071557998657, Accuracy: 0.673828125\n",
      "Batch: 135, Loss: 0.851187527179718, Accuracy: 0.732421875\n",
      "Batch: 136, Loss: 0.9431325197219849, Accuracy: 0.7060546875\n",
      "Batch: 137, Loss: 0.8984813690185547, Accuracy: 0.6982421875\n",
      "Batch: 138, Loss: 0.7859360575675964, Accuracy: 0.7451171875\n",
      "Batch: 139, Loss: 0.8534513115882874, Accuracy: 0.7275390625\n",
      "Batch: 140, Loss: 0.9117639064788818, Accuracy: 0.701171875\n",
      "Batch: 141, Loss: 0.9762861728668213, Accuracy: 0.697265625\n",
      "Batch: 142, Loss: 0.9690203070640564, Accuracy: 0.6865234375\n",
      "Batch: 143, Loss: 0.9300398826599121, Accuracy: 0.693359375\n",
      "Batch: 144, Loss: 0.9380029439926147, Accuracy: 0.6904296875\n",
      "Batch: 145, Loss: 0.872525691986084, Accuracy: 0.7060546875\n",
      "Batch: 146, Loss: 0.9271742105484009, Accuracy: 0.693359375\n",
      "Batch: 147, Loss: 0.9485422968864441, Accuracy: 0.6953125\n",
      "Batch: 148, Loss: 1.0417332649230957, Accuracy: 0.6572265625\n",
      "Batch: 149, Loss: 0.9076253771781921, Accuracy: 0.7001953125\n",
      "Batch: 150, Loss: 0.8781239986419678, Accuracy: 0.7255859375\n",
      "Batch: 151, Loss: 0.8056421279907227, Accuracy: 0.7412109375\n",
      "Epoch 20/90\n",
      "Batch: 1, Loss: 1.1361157894134521, Accuracy: 0.6318359375\n",
      "Batch: 2, Loss: 0.989266037940979, Accuracy: 0.658203125\n",
      "Batch: 3, Loss: 0.8874408006668091, Accuracy: 0.6923828125\n",
      "Batch: 4, Loss: 0.7923945188522339, Accuracy: 0.7353515625\n",
      "Batch: 5, Loss: 0.8228126764297485, Accuracy: 0.73046875\n",
      "Batch: 6, Loss: 0.9188560247421265, Accuracy: 0.69921875\n",
      "Batch: 7, Loss: 0.8884954452514648, Accuracy: 0.6865234375\n",
      "Batch: 8, Loss: 0.8511601686477661, Accuracy: 0.716796875\n",
      "Batch: 9, Loss: 0.8155947923660278, Accuracy: 0.732421875\n",
      "Batch: 10, Loss: 0.8016782999038696, Accuracy: 0.74609375\n",
      "Batch: 11, Loss: 1.0030548572540283, Accuracy: 0.666015625\n",
      "Batch: 12, Loss: 0.9891897439956665, Accuracy: 0.6748046875\n",
      "Batch: 13, Loss: 0.7575181722640991, Accuracy: 0.7421875\n",
      "Batch: 14, Loss: 0.9883502721786499, Accuracy: 0.681640625\n",
      "Batch: 15, Loss: 0.8658833503723145, Accuracy: 0.7275390625\n",
      "Batch: 16, Loss: 0.8537883758544922, Accuracy: 0.732421875\n",
      "Batch: 17, Loss: 0.9604759812355042, Accuracy: 0.6708984375\n",
      "Batch: 18, Loss: 0.9358737468719482, Accuracy: 0.6923828125\n",
      "Batch: 19, Loss: 0.9617447853088379, Accuracy: 0.703125\n",
      "Batch: 20, Loss: 0.8150802850723267, Accuracy: 0.740234375\n",
      "Batch: 21, Loss: 0.8679551482200623, Accuracy: 0.72265625\n",
      "Batch: 22, Loss: 0.9840230941772461, Accuracy: 0.7001953125\n",
      "Batch: 23, Loss: 0.9461528658866882, Accuracy: 0.6923828125\n",
      "Batch: 24, Loss: 0.9233337640762329, Accuracy: 0.689453125\n",
      "Batch: 25, Loss: 0.9189801216125488, Accuracy: 0.7001953125\n",
      "Batch: 26, Loss: 0.804438054561615, Accuracy: 0.73046875\n",
      "Batch: 27, Loss: 0.875116229057312, Accuracy: 0.685546875\n",
      "Batch: 28, Loss: 0.9522100687026978, Accuracy: 0.6748046875\n",
      "Batch: 29, Loss: 0.9379528164863586, Accuracy: 0.6923828125\n",
      "Batch: 30, Loss: 0.8630478382110596, Accuracy: 0.7314453125\n",
      "Batch: 31, Loss: 0.8350081443786621, Accuracy: 0.728515625\n",
      "Batch: 32, Loss: 0.8242530226707458, Accuracy: 0.7275390625\n",
      "Batch: 33, Loss: 0.9490259885787964, Accuracy: 0.6923828125\n",
      "Batch: 34, Loss: 1.0359582901000977, Accuracy: 0.6796875\n",
      "Batch: 35, Loss: 0.9299032688140869, Accuracy: 0.6953125\n",
      "Batch: 36, Loss: 0.9498039484024048, Accuracy: 0.7080078125\n",
      "Batch: 37, Loss: 0.8931650519371033, Accuracy: 0.7158203125\n",
      "Batch: 38, Loss: 0.9240413904190063, Accuracy: 0.697265625\n",
      "Batch: 39, Loss: 0.9447985887527466, Accuracy: 0.6865234375\n",
      "Batch: 40, Loss: 0.9667707681655884, Accuracy: 0.6953125\n",
      "Batch: 41, Loss: 0.9127128720283508, Accuracy: 0.7109375\n",
      "Batch: 42, Loss: 0.7287055850028992, Accuracy: 0.755859375\n",
      "Batch: 43, Loss: 0.9682393074035645, Accuracy: 0.6748046875\n",
      "Batch: 44, Loss: 0.9248180389404297, Accuracy: 0.69140625\n",
      "Batch: 45, Loss: 0.834678053855896, Accuracy: 0.7294921875\n",
      "Batch: 46, Loss: 0.9041444063186646, Accuracy: 0.7109375\n",
      "Batch: 47, Loss: 0.8962063789367676, Accuracy: 0.7197265625\n",
      "Batch: 48, Loss: 0.7988858222961426, Accuracy: 0.736328125\n",
      "Batch: 49, Loss: 0.9755430221557617, Accuracy: 0.6787109375\n",
      "Batch: 50, Loss: 0.9541066288948059, Accuracy: 0.693359375\n",
      "Batch: 51, Loss: 1.0006226301193237, Accuracy: 0.66796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 52, Loss: 0.9447793960571289, Accuracy: 0.693359375\n",
      "Batch: 53, Loss: 0.8315335512161255, Accuracy: 0.7236328125\n",
      "Batch: 54, Loss: 0.8699890375137329, Accuracy: 0.708984375\n",
      "Batch: 55, Loss: 0.9950491786003113, Accuracy: 0.6767578125\n",
      "Batch: 56, Loss: 0.9934889674186707, Accuracy: 0.666015625\n",
      "Batch: 57, Loss: 0.9026640057563782, Accuracy: 0.705078125\n",
      "Batch: 58, Loss: 0.9670867919921875, Accuracy: 0.6904296875\n",
      "Batch: 59, Loss: 0.8907957673072815, Accuracy: 0.712890625\n",
      "Batch: 60, Loss: 0.8311412334442139, Accuracy: 0.732421875\n",
      "Batch: 61, Loss: 0.9174810647964478, Accuracy: 0.7001953125\n",
      "Batch: 62, Loss: 0.8772456645965576, Accuracy: 0.7119140625\n",
      "Batch: 63, Loss: 0.9201669692993164, Accuracy: 0.69921875\n",
      "Batch: 64, Loss: 0.9107609987258911, Accuracy: 0.6943359375\n",
      "Batch: 65, Loss: 0.9320069551467896, Accuracy: 0.7041015625\n",
      "Batch: 66, Loss: 0.8899493217468262, Accuracy: 0.716796875\n",
      "Batch: 67, Loss: 0.9986845850944519, Accuracy: 0.6787109375\n",
      "Batch: 68, Loss: 0.9733596444129944, Accuracy: 0.68359375\n",
      "Batch: 69, Loss: 0.916289746761322, Accuracy: 0.712890625\n",
      "Batch: 70, Loss: 0.8891540765762329, Accuracy: 0.7294921875\n",
      "Batch: 71, Loss: 0.9438785314559937, Accuracy: 0.7001953125\n",
      "Batch: 72, Loss: 0.822026252746582, Accuracy: 0.7255859375\n",
      "Batch: 73, Loss: 0.8676490783691406, Accuracy: 0.716796875\n",
      "Batch: 74, Loss: 0.8266000747680664, Accuracy: 0.748046875\n",
      "Batch: 75, Loss: 0.7925649881362915, Accuracy: 0.74609375\n",
      "Batch: 76, Loss: 0.900294840335846, Accuracy: 0.7021484375\n",
      "Batch: 77, Loss: 0.8509859442710876, Accuracy: 0.7177734375\n",
      "Batch: 78, Loss: 0.876374363899231, Accuracy: 0.7275390625\n",
      "Batch: 79, Loss: 0.8172694444656372, Accuracy: 0.740234375\n",
      "Batch: 80, Loss: 0.8579652905464172, Accuracy: 0.716796875\n",
      "Batch: 81, Loss: 0.9585459232330322, Accuracy: 0.669921875\n",
      "Batch: 82, Loss: 0.9177467823028564, Accuracy: 0.69140625\n",
      "Batch: 83, Loss: 0.7968093752861023, Accuracy: 0.7509765625\n",
      "Batch: 84, Loss: 0.8882184624671936, Accuracy: 0.716796875\n",
      "Batch: 85, Loss: 0.8199428915977478, Accuracy: 0.7548828125\n",
      "Batch: 86, Loss: 1.0005226135253906, Accuracy: 0.6787109375\n",
      "Batch: 87, Loss: 0.8449822068214417, Accuracy: 0.734375\n",
      "Batch: 88, Loss: 0.9332879185676575, Accuracy: 0.7109375\n",
      "Batch: 89, Loss: 0.9398880004882812, Accuracy: 0.701171875\n",
      "Batch: 90, Loss: 0.8557088971138, Accuracy: 0.7314453125\n",
      "Batch: 91, Loss: 0.8911994695663452, Accuracy: 0.7001953125\n",
      "Batch: 92, Loss: 0.9170055985450745, Accuracy: 0.7080078125\n",
      "Batch: 93, Loss: 0.8815069794654846, Accuracy: 0.7109375\n",
      "Batch: 94, Loss: 0.8720475435256958, Accuracy: 0.716796875\n",
      "Batch: 95, Loss: 0.9262042045593262, Accuracy: 0.6845703125\n",
      "Batch: 96, Loss: 0.9034078121185303, Accuracy: 0.7060546875\n",
      "Batch: 97, Loss: 0.7746113538742065, Accuracy: 0.744140625\n",
      "Batch: 98, Loss: 0.8460369110107422, Accuracy: 0.728515625\n",
      "Batch: 99, Loss: 0.81646728515625, Accuracy: 0.724609375\n",
      "Batch: 100, Loss: 0.8805128335952759, Accuracy: 0.7099609375\n",
      "Batch: 101, Loss: 0.9425461292266846, Accuracy: 0.6904296875\n",
      "Batch: 102, Loss: 0.8638964295387268, Accuracy: 0.7158203125\n",
      "Batch: 103, Loss: 0.9345077276229858, Accuracy: 0.689453125\n",
      "Batch: 104, Loss: 0.86473548412323, Accuracy: 0.71484375\n",
      "Batch: 105, Loss: 0.9269084930419922, Accuracy: 0.6845703125\n",
      "Batch: 106, Loss: 0.8684141635894775, Accuracy: 0.73046875\n",
      "Batch: 107, Loss: 0.9015463590621948, Accuracy: 0.72265625\n",
      "Batch: 108, Loss: 0.9012764096260071, Accuracy: 0.703125\n",
      "Batch: 109, Loss: 1.0191650390625, Accuracy: 0.66796875\n",
      "Batch: 110, Loss: 0.8081629276275635, Accuracy: 0.7255859375\n",
      "Batch: 111, Loss: 0.98385089635849, Accuracy: 0.666015625\n",
      "Batch: 112, Loss: 0.8802759647369385, Accuracy: 0.7177734375\n",
      "Batch: 113, Loss: 0.9013490676879883, Accuracy: 0.7109375\n",
      "Batch: 114, Loss: 0.9831371307373047, Accuracy: 0.66796875\n",
      "Batch: 115, Loss: 1.027018666267395, Accuracy: 0.6767578125\n",
      "Batch: 116, Loss: 0.9488303661346436, Accuracy: 0.697265625\n",
      "Batch: 117, Loss: 0.9612339735031128, Accuracy: 0.6826171875\n",
      "Batch: 118, Loss: 0.8392654657363892, Accuracy: 0.73046875\n",
      "Batch: 119, Loss: 0.8126211166381836, Accuracy: 0.740234375\n",
      "Batch: 120, Loss: 0.9611780643463135, Accuracy: 0.6767578125\n",
      "Batch: 121, Loss: 0.9681980609893799, Accuracy: 0.6904296875\n",
      "Batch: 122, Loss: 0.8892315626144409, Accuracy: 0.7060546875\n",
      "Batch: 123, Loss: 0.8512820601463318, Accuracy: 0.73046875\n",
      "Batch: 124, Loss: 0.9674859046936035, Accuracy: 0.6875\n",
      "Batch: 125, Loss: 0.9570809602737427, Accuracy: 0.6904296875\n",
      "Batch: 126, Loss: 0.9430299997329712, Accuracy: 0.708984375\n",
      "Batch: 127, Loss: 0.8267890810966492, Accuracy: 0.7373046875\n",
      "Batch: 128, Loss: 0.9955555200576782, Accuracy: 0.689453125\n",
      "Batch: 129, Loss: 0.857866644859314, Accuracy: 0.71875\n",
      "Batch: 130, Loss: 1.0715011358261108, Accuracy: 0.65625\n",
      "Batch: 131, Loss: 0.9226553440093994, Accuracy: 0.693359375\n",
      "Batch: 132, Loss: 0.9731220602989197, Accuracy: 0.6923828125\n",
      "Batch: 133, Loss: 0.8546393513679504, Accuracy: 0.7041015625\n",
      "Batch: 134, Loss: 0.9161372184753418, Accuracy: 0.697265625\n",
      "Batch: 135, Loss: 0.8372083902359009, Accuracy: 0.7275390625\n",
      "Batch: 136, Loss: 0.9125613570213318, Accuracy: 0.7060546875\n",
      "Batch: 137, Loss: 0.8566920757293701, Accuracy: 0.7099609375\n",
      "Batch: 138, Loss: 0.7560166120529175, Accuracy: 0.7451171875\n",
      "Batch: 139, Loss: 0.8449163436889648, Accuracy: 0.71484375\n",
      "Batch: 140, Loss: 0.8891600370407104, Accuracy: 0.720703125\n",
      "Batch: 141, Loss: 0.9472447633743286, Accuracy: 0.6953125\n",
      "Batch: 142, Loss: 0.9333057403564453, Accuracy: 0.69140625\n",
      "Batch: 143, Loss: 0.9086263179779053, Accuracy: 0.7041015625\n",
      "Batch: 144, Loss: 0.9021168947219849, Accuracy: 0.7041015625\n",
      "Batch: 145, Loss: 0.8560448884963989, Accuracy: 0.705078125\n",
      "Batch: 146, Loss: 0.9159744381904602, Accuracy: 0.7041015625\n",
      "Batch: 147, Loss: 0.9145044088363647, Accuracy: 0.7119140625\n",
      "Batch: 148, Loss: 1.013197898864746, Accuracy: 0.662109375\n",
      "Batch: 149, Loss: 0.868179440498352, Accuracy: 0.724609375\n",
      "Batch: 150, Loss: 0.847549319267273, Accuracy: 0.7197265625\n",
      "Batch: 151, Loss: 0.78492271900177, Accuracy: 0.7529296875\n",
      "Saved Weights at epoch 20 to file Weights_20.h5\n",
      "Epoch 21/90\n",
      "Batch: 1, Loss: 1.1113864183425903, Accuracy: 0.6298828125\n",
      "Batch: 2, Loss: 0.9930292367935181, Accuracy: 0.6650390625\n",
      "Batch: 3, Loss: 0.8682918548583984, Accuracy: 0.71484375\n",
      "Batch: 4, Loss: 0.8000914454460144, Accuracy: 0.73828125\n",
      "Batch: 5, Loss: 0.8135340809822083, Accuracy: 0.7255859375\n",
      "Batch: 6, Loss: 0.9046258330345154, Accuracy: 0.7158203125\n",
      "Batch: 7, Loss: 0.9011471271514893, Accuracy: 0.6865234375\n",
      "Batch: 8, Loss: 0.8344609141349792, Accuracy: 0.7255859375\n",
      "Batch: 9, Loss: 0.811673104763031, Accuracy: 0.7470703125\n",
      "Batch: 10, Loss: 0.8058537244796753, Accuracy: 0.7392578125\n",
      "Batch: 11, Loss: 1.0033583641052246, Accuracy: 0.6796875\n",
      "Batch: 12, Loss: 0.9689769744873047, Accuracy: 0.6767578125\n",
      "Batch: 13, Loss: 0.7535316348075867, Accuracy: 0.7470703125\n",
      "Batch: 14, Loss: 0.9771749973297119, Accuracy: 0.6796875\n",
      "Batch: 15, Loss: 0.8608863353729248, Accuracy: 0.732421875\n",
      "Batch: 16, Loss: 0.8296037912368774, Accuracy: 0.7421875\n",
      "Batch: 17, Loss: 0.9153772592544556, Accuracy: 0.7021484375\n",
      "Batch: 18, Loss: 0.9135171175003052, Accuracy: 0.701171875\n",
      "Batch: 19, Loss: 0.9431279897689819, Accuracy: 0.703125\n",
      "Batch: 20, Loss: 0.8210842609405518, Accuracy: 0.7353515625\n",
      "Batch: 21, Loss: 0.8388251066207886, Accuracy: 0.7314453125\n",
      "Batch: 22, Loss: 0.9824236631393433, Accuracy: 0.69921875\n",
      "Batch: 23, Loss: 0.9012248516082764, Accuracy: 0.6982421875\n",
      "Batch: 24, Loss: 0.8951100707054138, Accuracy: 0.685546875\n",
      "Batch: 25, Loss: 0.8854897022247314, Accuracy: 0.712890625\n",
      "Batch: 26, Loss: 0.7929001450538635, Accuracy: 0.72265625\n",
      "Batch: 27, Loss: 0.8468490839004517, Accuracy: 0.6982421875\n",
      "Batch: 28, Loss: 0.9232501983642578, Accuracy: 0.6943359375\n",
      "Batch: 29, Loss: 0.9093749523162842, Accuracy: 0.693359375\n",
      "Batch: 30, Loss: 0.8122200965881348, Accuracy: 0.7294921875\n",
      "Batch: 31, Loss: 0.8370270729064941, Accuracy: 0.736328125\n",
      "Batch: 32, Loss: 0.7848984003067017, Accuracy: 0.7431640625\n",
      "Batch: 33, Loss: 0.9455432891845703, Accuracy: 0.701171875\n",
      "Batch: 34, Loss: 1.0501805543899536, Accuracy: 0.662109375\n",
      "Batch: 35, Loss: 0.9238515496253967, Accuracy: 0.69921875\n",
      "Batch: 36, Loss: 0.9498467445373535, Accuracy: 0.7041015625\n",
      "Batch: 37, Loss: 0.8751206398010254, Accuracy: 0.716796875\n",
      "Batch: 38, Loss: 0.9081485867500305, Accuracy: 0.7041015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 39, Loss: 0.9147081971168518, Accuracy: 0.7001953125\n",
      "Batch: 40, Loss: 0.9204980134963989, Accuracy: 0.708984375\n",
      "Batch: 41, Loss: 0.8703932762145996, Accuracy: 0.7333984375\n",
      "Batch: 42, Loss: 0.6869035959243774, Accuracy: 0.7734375\n",
      "Batch: 43, Loss: 0.9460629224777222, Accuracy: 0.693359375\n",
      "Batch: 44, Loss: 0.9168592691421509, Accuracy: 0.6875\n",
      "Batch: 45, Loss: 0.8215723037719727, Accuracy: 0.728515625\n",
      "Batch: 46, Loss: 0.8751193881034851, Accuracy: 0.716796875\n",
      "Batch: 47, Loss: 0.8299946784973145, Accuracy: 0.73828125\n",
      "Batch: 48, Loss: 0.774465799331665, Accuracy: 0.740234375\n",
      "Batch: 49, Loss: 0.9593777656555176, Accuracy: 0.6748046875\n",
      "Batch: 50, Loss: 0.9345577955245972, Accuracy: 0.6962890625\n",
      "Batch: 51, Loss: 0.9832517504692078, Accuracy: 0.6767578125\n",
      "Batch: 52, Loss: 0.9165623784065247, Accuracy: 0.7001953125\n",
      "Batch: 53, Loss: 0.8112609386444092, Accuracy: 0.734375\n",
      "Batch: 54, Loss: 0.8444573879241943, Accuracy: 0.720703125\n",
      "Batch: 55, Loss: 0.9630363583564758, Accuracy: 0.68359375\n",
      "Batch: 56, Loss: 0.9422378540039062, Accuracy: 0.69140625\n",
      "Batch: 57, Loss: 0.8649696111679077, Accuracy: 0.7275390625\n",
      "Batch: 58, Loss: 0.9405494332313538, Accuracy: 0.69921875\n",
      "Batch: 59, Loss: 0.850549578666687, Accuracy: 0.7197265625\n",
      "Batch: 60, Loss: 0.7995396852493286, Accuracy: 0.7431640625\n",
      "Batch: 61, Loss: 0.9415046572685242, Accuracy: 0.6953125\n",
      "Batch: 62, Loss: 0.8687063455581665, Accuracy: 0.703125\n",
      "Batch: 63, Loss: 0.9068009853363037, Accuracy: 0.7119140625\n",
      "Batch: 64, Loss: 0.913664698600769, Accuracy: 0.693359375\n",
      "Batch: 65, Loss: 0.9020994901657104, Accuracy: 0.697265625\n",
      "Batch: 66, Loss: 0.8579497337341309, Accuracy: 0.734375\n",
      "Batch: 67, Loss: 0.9557244777679443, Accuracy: 0.7080078125\n",
      "Batch: 68, Loss: 0.9752846360206604, Accuracy: 0.7060546875\n",
      "Batch: 69, Loss: 0.8953245282173157, Accuracy: 0.705078125\n",
      "Batch: 70, Loss: 0.8547261953353882, Accuracy: 0.732421875\n",
      "Batch: 71, Loss: 0.9221302270889282, Accuracy: 0.7041015625\n",
      "Batch: 72, Loss: 0.805008053779602, Accuracy: 0.7353515625\n",
      "Batch: 73, Loss: 0.8431493043899536, Accuracy: 0.732421875\n",
      "Batch: 74, Loss: 0.8295100927352905, Accuracy: 0.7509765625\n",
      "Batch: 75, Loss: 0.7709412574768066, Accuracy: 0.74609375\n",
      "Batch: 76, Loss: 0.868742048740387, Accuracy: 0.716796875\n",
      "Batch: 77, Loss: 0.840538740158081, Accuracy: 0.72265625\n",
      "Batch: 78, Loss: 0.8672205209732056, Accuracy: 0.71484375\n",
      "Batch: 79, Loss: 0.7859572172164917, Accuracy: 0.7587890625\n",
      "Batch: 80, Loss: 0.8348804116249084, Accuracy: 0.7265625\n",
      "Batch: 81, Loss: 0.9251959323883057, Accuracy: 0.6875\n",
      "Batch: 82, Loss: 0.8828595876693726, Accuracy: 0.70703125\n",
      "Batch: 83, Loss: 0.7549731731414795, Accuracy: 0.7568359375\n",
      "Batch: 84, Loss: 0.8555073142051697, Accuracy: 0.7177734375\n",
      "Batch: 85, Loss: 0.8014812469482422, Accuracy: 0.7431640625\n",
      "Batch: 86, Loss: 0.9751613736152649, Accuracy: 0.69140625\n",
      "Batch: 87, Loss: 0.8302567601203918, Accuracy: 0.7373046875\n",
      "Batch: 88, Loss: 0.9213283061981201, Accuracy: 0.701171875\n",
      "Batch: 89, Loss: 0.9024635553359985, Accuracy: 0.70703125\n",
      "Batch: 90, Loss: 0.8393774628639221, Accuracy: 0.7373046875\n",
      "Batch: 91, Loss: 0.8601958155632019, Accuracy: 0.7109375\n",
      "Batch: 92, Loss: 0.8753081560134888, Accuracy: 0.7021484375\n",
      "Batch: 93, Loss: 0.858623743057251, Accuracy: 0.7177734375\n",
      "Batch: 94, Loss: 0.8522652983665466, Accuracy: 0.72265625\n",
      "Batch: 95, Loss: 0.9358086585998535, Accuracy: 0.6748046875\n",
      "Batch: 96, Loss: 0.8705016374588013, Accuracy: 0.7265625\n",
      "Batch: 97, Loss: 0.7593140006065369, Accuracy: 0.7431640625\n",
      "Batch: 98, Loss: 0.7934761643409729, Accuracy: 0.7421875\n",
      "Batch: 99, Loss: 0.818466067314148, Accuracy: 0.7216796875\n",
      "Batch: 100, Loss: 0.8523156046867371, Accuracy: 0.732421875\n",
      "Batch: 101, Loss: 0.9272558093070984, Accuracy: 0.689453125\n",
      "Batch: 102, Loss: 0.856535017490387, Accuracy: 0.72265625\n",
      "Batch: 103, Loss: 0.8971028923988342, Accuracy: 0.712890625\n",
      "Batch: 104, Loss: 0.8388901948928833, Accuracy: 0.728515625\n",
      "Batch: 105, Loss: 0.9238797426223755, Accuracy: 0.6923828125\n",
      "Batch: 106, Loss: 0.8417746424674988, Accuracy: 0.728515625\n",
      "Batch: 107, Loss: 0.8644050359725952, Accuracy: 0.71875\n",
      "Batch: 108, Loss: 0.8864288330078125, Accuracy: 0.7021484375\n",
      "Batch: 109, Loss: 0.9779862761497498, Accuracy: 0.6767578125\n",
      "Batch: 110, Loss: 0.8066142797470093, Accuracy: 0.732421875\n",
      "Batch: 111, Loss: 0.9155617952346802, Accuracy: 0.712890625\n",
      "Batch: 112, Loss: 0.8681207895278931, Accuracy: 0.7197265625\n",
      "Batch: 113, Loss: 0.8751050233840942, Accuracy: 0.7236328125\n",
      "Batch: 114, Loss: 0.958183765411377, Accuracy: 0.69140625\n",
      "Batch: 115, Loss: 0.9967095255851746, Accuracy: 0.6806640625\n",
      "Batch: 116, Loss: 0.9365129470825195, Accuracy: 0.697265625\n",
      "Batch: 117, Loss: 0.945040225982666, Accuracy: 0.7021484375\n",
      "Batch: 118, Loss: 0.8151391744613647, Accuracy: 0.73046875\n",
      "Batch: 119, Loss: 0.7843837738037109, Accuracy: 0.75\n",
      "Batch: 120, Loss: 0.9156219363212585, Accuracy: 0.701171875\n",
      "Batch: 121, Loss: 0.930153489112854, Accuracy: 0.693359375\n",
      "Batch: 122, Loss: 0.8548016548156738, Accuracy: 0.7294921875\n",
      "Batch: 123, Loss: 0.8179757595062256, Accuracy: 0.7470703125\n",
      "Batch: 124, Loss: 0.9218418598175049, Accuracy: 0.6865234375\n",
      "Batch: 125, Loss: 0.9276453852653503, Accuracy: 0.7041015625\n",
      "Batch: 126, Loss: 0.9045677185058594, Accuracy: 0.7080078125\n",
      "Batch: 127, Loss: 0.7726578712463379, Accuracy: 0.7509765625\n",
      "Batch: 128, Loss: 0.9869929552078247, Accuracy: 0.6875\n",
      "Batch: 129, Loss: 0.8364537954330444, Accuracy: 0.7353515625\n",
      "Batch: 130, Loss: 1.0373878479003906, Accuracy: 0.6640625\n",
      "Batch: 131, Loss: 0.9237526655197144, Accuracy: 0.7021484375\n",
      "Batch: 132, Loss: 0.9288754463195801, Accuracy: 0.708984375\n",
      "Batch: 133, Loss: 0.847174346446991, Accuracy: 0.7255859375\n",
      "Batch: 134, Loss: 0.9069226384162903, Accuracy: 0.6962890625\n",
      "Batch: 135, Loss: 0.7846997976303101, Accuracy: 0.7470703125\n",
      "Batch: 136, Loss: 0.9049729108810425, Accuracy: 0.7041015625\n",
      "Batch: 137, Loss: 0.8681772351264954, Accuracy: 0.6982421875\n",
      "Batch: 138, Loss: 0.764409065246582, Accuracy: 0.7373046875\n",
      "Batch: 139, Loss: 0.8210948705673218, Accuracy: 0.72265625\n",
      "Batch: 140, Loss: 0.896986722946167, Accuracy: 0.7080078125\n",
      "Batch: 141, Loss: 0.9451839327812195, Accuracy: 0.6962890625\n",
      "Batch: 142, Loss: 0.9333946704864502, Accuracy: 0.69921875\n",
      "Batch: 143, Loss: 0.8694677352905273, Accuracy: 0.720703125\n",
      "Batch: 144, Loss: 0.8819171190261841, Accuracy: 0.7099609375\n",
      "Batch: 145, Loss: 0.8282535076141357, Accuracy: 0.7099609375\n",
      "Batch: 146, Loss: 0.8911514282226562, Accuracy: 0.712890625\n",
      "Batch: 147, Loss: 0.8960157632827759, Accuracy: 0.708984375\n",
      "Batch: 148, Loss: 0.9735540151596069, Accuracy: 0.68359375\n",
      "Batch: 149, Loss: 0.8610526323318481, Accuracy: 0.7353515625\n",
      "Batch: 150, Loss: 0.8211299180984497, Accuracy: 0.728515625\n",
      "Batch: 151, Loss: 0.7567332983016968, Accuracy: 0.7587890625\n",
      "Epoch 22/90\n",
      "Batch: 1, Loss: 1.1258749961853027, Accuracy: 0.6298828125\n",
      "Batch: 2, Loss: 0.9865509271621704, Accuracy: 0.6416015625\n",
      "Batch: 3, Loss: 0.842231035232544, Accuracy: 0.712890625\n",
      "Batch: 4, Loss: 0.7954227924346924, Accuracy: 0.7431640625\n",
      "Batch: 5, Loss: 0.7935985326766968, Accuracy: 0.73828125\n",
      "Batch: 6, Loss: 0.8870019316673279, Accuracy: 0.708984375\n",
      "Batch: 7, Loss: 0.8782166242599487, Accuracy: 0.703125\n",
      "Batch: 8, Loss: 0.828983724117279, Accuracy: 0.7216796875\n",
      "Batch: 9, Loss: 0.7685362100601196, Accuracy: 0.744140625\n",
      "Batch: 10, Loss: 0.7780377864837646, Accuracy: 0.7294921875\n",
      "Batch: 11, Loss: 0.9654523134231567, Accuracy: 0.677734375\n",
      "Batch: 12, Loss: 0.9418432116508484, Accuracy: 0.693359375\n",
      "Batch: 13, Loss: 0.7229633331298828, Accuracy: 0.7724609375\n",
      "Batch: 14, Loss: 0.9552128911018372, Accuracy: 0.6806640625\n",
      "Batch: 15, Loss: 0.8340628147125244, Accuracy: 0.736328125\n",
      "Batch: 16, Loss: 0.8377436399459839, Accuracy: 0.724609375\n",
      "Batch: 17, Loss: 0.9019602537155151, Accuracy: 0.7099609375\n",
      "Batch: 18, Loss: 0.8801131844520569, Accuracy: 0.712890625\n",
      "Batch: 19, Loss: 0.9137126207351685, Accuracy: 0.7080078125\n",
      "Batch: 20, Loss: 0.8006108999252319, Accuracy: 0.7451171875\n",
      "Batch: 21, Loss: 0.816739022731781, Accuracy: 0.7255859375\n",
      "Batch: 22, Loss: 0.9416618347167969, Accuracy: 0.70703125\n",
      "Batch: 23, Loss: 0.908979058265686, Accuracy: 0.693359375\n",
      "Batch: 24, Loss: 0.8734914064407349, Accuracy: 0.69921875\n",
      "Batch: 25, Loss: 0.8705688714981079, Accuracy: 0.720703125\n",
      "Batch: 26, Loss: 0.7466597557067871, Accuracy: 0.7470703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 27, Loss: 0.7995361685752869, Accuracy: 0.701171875\n",
      "Batch: 28, Loss: 0.8955856561660767, Accuracy: 0.7001953125\n",
      "Batch: 29, Loss: 0.8819681406021118, Accuracy: 0.720703125\n",
      "Batch: 30, Loss: 0.8075168132781982, Accuracy: 0.7421875\n",
      "Batch: 31, Loss: 0.7977313995361328, Accuracy: 0.736328125\n",
      "Batch: 32, Loss: 0.7773552536964417, Accuracy: 0.74609375\n",
      "Batch: 33, Loss: 0.8984618782997131, Accuracy: 0.701171875\n",
      "Batch: 34, Loss: 0.9968284368515015, Accuracy: 0.6884765625\n",
      "Batch: 35, Loss: 0.9083974361419678, Accuracy: 0.7041015625\n",
      "Batch: 36, Loss: 0.9193648099899292, Accuracy: 0.7158203125\n",
      "Batch: 37, Loss: 0.8514481782913208, Accuracy: 0.7294921875\n",
      "Batch: 38, Loss: 0.8604220151901245, Accuracy: 0.7177734375\n",
      "Batch: 39, Loss: 0.9110416769981384, Accuracy: 0.7021484375\n",
      "Batch: 40, Loss: 0.8876059651374817, Accuracy: 0.7158203125\n",
      "Batch: 41, Loss: 0.8398926258087158, Accuracy: 0.7294921875\n",
      "Batch: 42, Loss: 0.7049555778503418, Accuracy: 0.765625\n",
      "Batch: 43, Loss: 0.9000751376152039, Accuracy: 0.701171875\n",
      "Batch: 44, Loss: 0.8644561767578125, Accuracy: 0.7021484375\n",
      "Batch: 45, Loss: 0.7985484600067139, Accuracy: 0.740234375\n",
      "Batch: 46, Loss: 0.8689233064651489, Accuracy: 0.7265625\n",
      "Batch: 47, Loss: 0.8236598372459412, Accuracy: 0.748046875\n",
      "Batch: 48, Loss: 0.7562669515609741, Accuracy: 0.74609375\n",
      "Batch: 49, Loss: 0.9274730682373047, Accuracy: 0.6982421875\n",
      "Batch: 50, Loss: 0.8955923318862915, Accuracy: 0.701171875\n",
      "Batch: 51, Loss: 0.9259897470474243, Accuracy: 0.703125\n",
      "Batch: 52, Loss: 0.9098870754241943, Accuracy: 0.712890625\n",
      "Batch: 53, Loss: 0.7876570820808411, Accuracy: 0.7333984375\n",
      "Batch: 54, Loss: 0.8472031950950623, Accuracy: 0.7216796875\n",
      "Batch: 55, Loss: 0.9701363444328308, Accuracy: 0.68359375\n",
      "Batch: 56, Loss: 0.9264252781867981, Accuracy: 0.71875\n",
      "Batch: 57, Loss: 0.8334445953369141, Accuracy: 0.732421875\n",
      "Batch: 58, Loss: 0.9177998304367065, Accuracy: 0.708984375\n",
      "Batch: 59, Loss: 0.862862765789032, Accuracy: 0.7216796875\n",
      "Batch: 60, Loss: 0.7743776440620422, Accuracy: 0.7470703125\n",
      "Batch: 61, Loss: 0.8783457279205322, Accuracy: 0.6982421875\n",
      "Batch: 62, Loss: 0.8306950330734253, Accuracy: 0.7353515625\n",
      "Batch: 63, Loss: 0.8826355338096619, Accuracy: 0.720703125\n",
      "Batch: 64, Loss: 0.8588728904724121, Accuracy: 0.7138671875\n",
      "Batch: 65, Loss: 0.8697490692138672, Accuracy: 0.7255859375\n",
      "Batch: 66, Loss: 0.8271675705909729, Accuracy: 0.7490234375\n",
      "Batch: 67, Loss: 0.9295266270637512, Accuracy: 0.7119140625\n",
      "Batch: 68, Loss: 0.9508160352706909, Accuracy: 0.716796875\n",
      "Batch: 69, Loss: 0.8806804418563843, Accuracy: 0.70703125\n",
      "Batch: 70, Loss: 0.8794842958450317, Accuracy: 0.734375\n",
      "Batch: 71, Loss: 0.929263710975647, Accuracy: 0.6865234375\n",
      "Batch: 72, Loss: 0.8051338195800781, Accuracy: 0.74609375\n",
      "Batch: 73, Loss: 0.8210070133209229, Accuracy: 0.736328125\n",
      "Batch: 74, Loss: 0.7968582510948181, Accuracy: 0.7509765625\n",
      "Batch: 75, Loss: 0.7737023234367371, Accuracy: 0.75390625\n",
      "Batch: 76, Loss: 0.8746230006217957, Accuracy: 0.724609375\n",
      "Batch: 77, Loss: 0.8270643949508667, Accuracy: 0.736328125\n",
      "Batch: 78, Loss: 0.827612578868866, Accuracy: 0.73046875\n",
      "Batch: 79, Loss: 0.756092369556427, Accuracy: 0.7666015625\n",
      "Batch: 80, Loss: 0.8055430054664612, Accuracy: 0.72265625\n",
      "Batch: 81, Loss: 0.9428137540817261, Accuracy: 0.6787109375\n",
      "Batch: 82, Loss: 0.8589934706687927, Accuracy: 0.7060546875\n",
      "Batch: 83, Loss: 0.7379149794578552, Accuracy: 0.765625\n",
      "Batch: 84, Loss: 0.8330532908439636, Accuracy: 0.7353515625\n",
      "Batch: 85, Loss: 0.7791498899459839, Accuracy: 0.7529296875\n",
      "Batch: 86, Loss: 0.9504795074462891, Accuracy: 0.7060546875\n",
      "Batch: 87, Loss: 0.7863660454750061, Accuracy: 0.7470703125\n",
      "Batch: 88, Loss: 0.9086780548095703, Accuracy: 0.716796875\n",
      "Batch: 89, Loss: 0.898865818977356, Accuracy: 0.7197265625\n",
      "Batch: 90, Loss: 0.8203250765800476, Accuracy: 0.73046875\n",
      "Batch: 91, Loss: 0.8603106737136841, Accuracy: 0.7177734375\n",
      "Batch: 92, Loss: 0.8700695037841797, Accuracy: 0.7060546875\n",
      "Batch: 93, Loss: 0.8641567230224609, Accuracy: 0.7265625\n",
      "Batch: 94, Loss: 0.8360419869422913, Accuracy: 0.708984375\n",
      "Batch: 95, Loss: 0.8873277902603149, Accuracy: 0.685546875\n",
      "Batch: 96, Loss: 0.8638226389884949, Accuracy: 0.720703125\n",
      "Batch: 97, Loss: 0.7268078327178955, Accuracy: 0.75\n",
      "Batch: 98, Loss: 0.7659999132156372, Accuracy: 0.7412109375\n",
      "Batch: 99, Loss: 0.7935014963150024, Accuracy: 0.7314453125\n",
      "Batch: 100, Loss: 0.8415258526802063, Accuracy: 0.7216796875\n",
      "Batch: 101, Loss: 0.9199684858322144, Accuracy: 0.693359375\n",
      "Batch: 102, Loss: 0.8413524627685547, Accuracy: 0.720703125\n",
      "Batch: 103, Loss: 0.8926942348480225, Accuracy: 0.708984375\n",
      "Batch: 104, Loss: 0.8263615965843201, Accuracy: 0.732421875\n",
      "Batch: 105, Loss: 0.8727059364318848, Accuracy: 0.7177734375\n",
      "Batch: 106, Loss: 0.7960794568061829, Accuracy: 0.7626953125\n",
      "Batch: 107, Loss: 0.8786672353744507, Accuracy: 0.7158203125\n",
      "Batch: 108, Loss: 0.8350095748901367, Accuracy: 0.724609375\n",
      "Batch: 109, Loss: 0.9732460975646973, Accuracy: 0.677734375\n",
      "Batch: 110, Loss: 0.7782543897628784, Accuracy: 0.74609375\n",
      "Batch: 111, Loss: 0.9198195338249207, Accuracy: 0.6953125\n",
      "Batch: 112, Loss: 0.8206897974014282, Accuracy: 0.7412109375\n",
      "Batch: 113, Loss: 0.8518719673156738, Accuracy: 0.72265625\n",
      "Batch: 114, Loss: 0.9421395063400269, Accuracy: 0.6826171875\n",
      "Batch: 115, Loss: 0.9702494144439697, Accuracy: 0.6884765625\n",
      "Batch: 116, Loss: 0.8995211124420166, Accuracy: 0.6962890625\n",
      "Batch: 117, Loss: 0.9121665954589844, Accuracy: 0.712890625\n",
      "Batch: 118, Loss: 0.7942199110984802, Accuracy: 0.7314453125\n",
      "Batch: 119, Loss: 0.7450309991836548, Accuracy: 0.7568359375\n",
      "Batch: 120, Loss: 0.8789918422698975, Accuracy: 0.7138671875\n",
      "Batch: 121, Loss: 0.9374183416366577, Accuracy: 0.701171875\n",
      "Batch: 122, Loss: 0.8364698886871338, Accuracy: 0.7314453125\n",
      "Batch: 123, Loss: 0.8182299137115479, Accuracy: 0.7333984375\n",
      "Batch: 124, Loss: 0.9136127829551697, Accuracy: 0.6982421875\n",
      "Batch: 125, Loss: 0.8955139517784119, Accuracy: 0.7138671875\n",
      "Batch: 126, Loss: 0.8875887393951416, Accuracy: 0.716796875\n",
      "Batch: 127, Loss: 0.7462115287780762, Accuracy: 0.759765625\n",
      "Batch: 128, Loss: 0.9467151165008545, Accuracy: 0.712890625\n",
      "Batch: 129, Loss: 0.8131505250930786, Accuracy: 0.7490234375\n",
      "Batch: 130, Loss: 1.041387677192688, Accuracy: 0.66796875\n",
      "Batch: 131, Loss: 0.8995658159255981, Accuracy: 0.689453125\n",
      "Batch: 132, Loss: 0.9113060235977173, Accuracy: 0.6953125\n",
      "Batch: 133, Loss: 0.8285346627235413, Accuracy: 0.7255859375\n",
      "Batch: 134, Loss: 0.8777498602867126, Accuracy: 0.71875\n",
      "Batch: 135, Loss: 0.8033066987991333, Accuracy: 0.73828125\n",
      "Batch: 136, Loss: 0.8507357239723206, Accuracy: 0.728515625\n",
      "Batch: 137, Loss: 0.8268724679946899, Accuracy: 0.72265625\n",
      "Batch: 138, Loss: 0.7429866790771484, Accuracy: 0.7451171875\n",
      "Batch: 139, Loss: 0.7924091815948486, Accuracy: 0.7412109375\n",
      "Batch: 140, Loss: 0.8641117215156555, Accuracy: 0.7177734375\n",
      "Batch: 141, Loss: 0.9131662249565125, Accuracy: 0.703125\n",
      "Batch: 142, Loss: 0.9230070114135742, Accuracy: 0.701171875\n",
      "Batch: 143, Loss: 0.8798149824142456, Accuracy: 0.720703125\n",
      "Batch: 144, Loss: 0.8789150714874268, Accuracy: 0.7138671875\n",
      "Batch: 145, Loss: 0.8213176727294922, Accuracy: 0.708984375\n",
      "Batch: 146, Loss: 0.880042552947998, Accuracy: 0.71484375\n",
      "Batch: 147, Loss: 0.8473975658416748, Accuracy: 0.7158203125\n",
      "Batch: 148, Loss: 0.9463691711425781, Accuracy: 0.7041015625\n",
      "Batch: 149, Loss: 0.8389695286750793, Accuracy: 0.71875\n",
      "Batch: 150, Loss: 0.8130938410758972, Accuracy: 0.7265625\n",
      "Batch: 151, Loss: 0.756605863571167, Accuracy: 0.751953125\n",
      "Epoch 23/90\n",
      "Batch: 1, Loss: 1.081063985824585, Accuracy: 0.654296875\n",
      "Batch: 2, Loss: 0.9785614013671875, Accuracy: 0.662109375\n",
      "Batch: 3, Loss: 0.8481688499450684, Accuracy: 0.712890625\n",
      "Batch: 4, Loss: 0.7730284929275513, Accuracy: 0.744140625\n",
      "Batch: 5, Loss: 0.7689840197563171, Accuracy: 0.7431640625\n",
      "Batch: 6, Loss: 0.8455147743225098, Accuracy: 0.7275390625\n",
      "Batch: 7, Loss: 0.8530328273773193, Accuracy: 0.7177734375\n",
      "Batch: 8, Loss: 0.8052831888198853, Accuracy: 0.7294921875\n",
      "Batch: 9, Loss: 0.7796086072921753, Accuracy: 0.75\n",
      "Batch: 10, Loss: 0.7647147178649902, Accuracy: 0.734375\n",
      "Batch: 11, Loss: 0.9402466416358948, Accuracy: 0.6865234375\n",
      "Batch: 12, Loss: 0.9387415647506714, Accuracy: 0.681640625\n",
      "Batch: 13, Loss: 0.7028640508651733, Accuracy: 0.775390625\n",
      "Batch: 14, Loss: 0.9368181824684143, Accuracy: 0.69140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 15, Loss: 0.8017938733100891, Accuracy: 0.7470703125\n",
      "Batch: 16, Loss: 0.8148658275604248, Accuracy: 0.7470703125\n",
      "Batch: 17, Loss: 0.8771859407424927, Accuracy: 0.71875\n",
      "Batch: 18, Loss: 0.8654440641403198, Accuracy: 0.71875\n",
      "Batch: 19, Loss: 0.8920402526855469, Accuracy: 0.7109375\n",
      "Batch: 20, Loss: 0.7991510033607483, Accuracy: 0.7529296875\n",
      "Batch: 21, Loss: 0.8061505556106567, Accuracy: 0.7412109375\n",
      "Batch: 22, Loss: 0.9165302515029907, Accuracy: 0.69140625\n",
      "Batch: 23, Loss: 0.8884918689727783, Accuracy: 0.703125\n",
      "Batch: 24, Loss: 0.8810276985168457, Accuracy: 0.701171875\n",
      "Batch: 25, Loss: 0.8379480838775635, Accuracy: 0.7138671875\n",
      "Batch: 26, Loss: 0.743760347366333, Accuracy: 0.75\n",
      "Batch: 27, Loss: 0.818545937538147, Accuracy: 0.705078125\n",
      "Batch: 28, Loss: 0.8859515190124512, Accuracy: 0.6982421875\n",
      "Batch: 29, Loss: 0.8654758930206299, Accuracy: 0.7158203125\n",
      "Batch: 30, Loss: 0.7519057393074036, Accuracy: 0.763671875\n",
      "Batch: 31, Loss: 0.7907145023345947, Accuracy: 0.7490234375\n",
      "Batch: 32, Loss: 0.7397149801254272, Accuracy: 0.7568359375\n",
      "Batch: 33, Loss: 0.9012157917022705, Accuracy: 0.7080078125\n",
      "Batch: 34, Loss: 0.9782162308692932, Accuracy: 0.6845703125\n",
      "Batch: 35, Loss: 0.8639053106307983, Accuracy: 0.7109375\n",
      "Batch: 36, Loss: 0.9037272930145264, Accuracy: 0.7197265625\n",
      "Batch: 37, Loss: 0.8477050065994263, Accuracy: 0.7236328125\n",
      "Batch: 38, Loss: 0.8566104769706726, Accuracy: 0.7177734375\n",
      "Batch: 39, Loss: 0.852858304977417, Accuracy: 0.724609375\n",
      "Batch: 40, Loss: 0.8712633848190308, Accuracy: 0.7099609375\n",
      "Batch: 41, Loss: 0.8195222616195679, Accuracy: 0.740234375\n",
      "Batch: 42, Loss: 0.6679348349571228, Accuracy: 0.76953125\n",
      "Batch: 43, Loss: 0.890753448009491, Accuracy: 0.7119140625\n",
      "Batch: 44, Loss: 0.8534551858901978, Accuracy: 0.7158203125\n",
      "Batch: 45, Loss: 0.793838620185852, Accuracy: 0.736328125\n",
      "Batch: 46, Loss: 0.8260754942893982, Accuracy: 0.7333984375\n",
      "Batch: 47, Loss: 0.8126025795936584, Accuracy: 0.748046875\n",
      "Batch: 48, Loss: 0.7715775966644287, Accuracy: 0.7333984375\n",
      "Batch: 49, Loss: 0.955681324005127, Accuracy: 0.6884765625\n",
      "Batch: 50, Loss: 0.9017693996429443, Accuracy: 0.7138671875\n",
      "Batch: 51, Loss: 0.9131147861480713, Accuracy: 0.6962890625\n",
      "Batch: 52, Loss: 0.8670386075973511, Accuracy: 0.7265625\n",
      "Batch: 53, Loss: 0.7739933133125305, Accuracy: 0.7470703125\n",
      "Batch: 54, Loss: 0.8342634439468384, Accuracy: 0.728515625\n",
      "Batch: 55, Loss: 0.9167741537094116, Accuracy: 0.6826171875\n",
      "Batch: 56, Loss: 0.9181094169616699, Accuracy: 0.701171875\n",
      "Batch: 57, Loss: 0.8379023671150208, Accuracy: 0.7265625\n",
      "Batch: 58, Loss: 0.8885223865509033, Accuracy: 0.736328125\n",
      "Batch: 59, Loss: 0.8238921165466309, Accuracy: 0.7333984375\n",
      "Batch: 60, Loss: 0.7582261562347412, Accuracy: 0.7509765625\n",
      "Batch: 61, Loss: 0.8510739803314209, Accuracy: 0.7080078125\n",
      "Batch: 62, Loss: 0.8159207701683044, Accuracy: 0.7412109375\n",
      "Batch: 63, Loss: 0.8776212930679321, Accuracy: 0.7177734375\n",
      "Batch: 64, Loss: 0.8642768263816833, Accuracy: 0.7099609375\n",
      "Batch: 65, Loss: 0.8553847074508667, Accuracy: 0.734375\n",
      "Batch: 66, Loss: 0.8045105934143066, Accuracy: 0.7421875\n",
      "Batch: 67, Loss: 0.9285162091255188, Accuracy: 0.7119140625\n",
      "Batch: 68, Loss: 0.9049849510192871, Accuracy: 0.712890625\n",
      "Batch: 69, Loss: 0.8624032735824585, Accuracy: 0.7177734375\n",
      "Batch: 70, Loss: 0.8286909461021423, Accuracy: 0.7451171875\n",
      "Batch: 71, Loss: 0.88148033618927, Accuracy: 0.7060546875\n",
      "Batch: 72, Loss: 0.7773144245147705, Accuracy: 0.7451171875\n",
      "Batch: 73, Loss: 0.8167049884796143, Accuracy: 0.7470703125\n",
      "Batch: 74, Loss: 0.7651462554931641, Accuracy: 0.7666015625\n",
      "Batch: 75, Loss: 0.7439321279525757, Accuracy: 0.767578125\n",
      "Batch: 76, Loss: 0.8458224534988403, Accuracy: 0.716796875\n",
      "Batch: 77, Loss: 0.7823566794395447, Accuracy: 0.748046875\n",
      "Batch: 78, Loss: 0.7840274572372437, Accuracy: 0.73828125\n",
      "Batch: 79, Loss: 0.7527843713760376, Accuracy: 0.771484375\n",
      "Batch: 80, Loss: 0.804871678352356, Accuracy: 0.7314453125\n",
      "Batch: 81, Loss: 0.9023289680480957, Accuracy: 0.6865234375\n",
      "Batch: 82, Loss: 0.8557169437408447, Accuracy: 0.7216796875\n",
      "Batch: 83, Loss: 0.7194743752479553, Accuracy: 0.7666015625\n",
      "Batch: 84, Loss: 0.8278397917747498, Accuracy: 0.7373046875\n",
      "Batch: 85, Loss: 0.783765435218811, Accuracy: 0.7568359375\n",
      "Batch: 86, Loss: 0.9820235371589661, Accuracy: 0.6943359375\n",
      "Batch: 87, Loss: 0.7895484566688538, Accuracy: 0.76171875\n",
      "Batch: 88, Loss: 0.8653460741043091, Accuracy: 0.734375\n",
      "Batch: 89, Loss: 0.8745303153991699, Accuracy: 0.7265625\n",
      "Batch: 90, Loss: 0.8180767297744751, Accuracy: 0.7412109375\n",
      "Batch: 91, Loss: 0.8471605777740479, Accuracy: 0.71875\n",
      "Batch: 92, Loss: 0.835708737373352, Accuracy: 0.72265625\n",
      "Batch: 93, Loss: 0.8104790449142456, Accuracy: 0.740234375\n",
      "Batch: 94, Loss: 0.8125933408737183, Accuracy: 0.7353515625\n",
      "Batch: 95, Loss: 0.879292368888855, Accuracy: 0.693359375\n",
      "Batch: 96, Loss: 0.8447310924530029, Accuracy: 0.7138671875\n",
      "Batch: 97, Loss: 0.7205240726470947, Accuracy: 0.7666015625\n",
      "Batch: 98, Loss: 0.7898650169372559, Accuracy: 0.7421875\n",
      "Batch: 99, Loss: 0.7865102291107178, Accuracy: 0.736328125\n",
      "Batch: 100, Loss: 0.8365581035614014, Accuracy: 0.748046875\n",
      "Batch: 101, Loss: 0.8856642246246338, Accuracy: 0.703125\n",
      "Batch: 102, Loss: 0.8338310122489929, Accuracy: 0.728515625\n",
      "Batch: 103, Loss: 0.8984118103981018, Accuracy: 0.71875\n",
      "Batch: 104, Loss: 0.7987993955612183, Accuracy: 0.7314453125\n",
      "Batch: 105, Loss: 0.863462507724762, Accuracy: 0.728515625\n",
      "Batch: 106, Loss: 0.7877368330955505, Accuracy: 0.75\n",
      "Batch: 107, Loss: 0.8461170792579651, Accuracy: 0.7353515625\n",
      "Batch: 108, Loss: 0.8746551275253296, Accuracy: 0.7060546875\n",
      "Batch: 109, Loss: 0.915178656578064, Accuracy: 0.6953125\n",
      "Batch: 110, Loss: 0.7613630890846252, Accuracy: 0.744140625\n",
      "Batch: 111, Loss: 0.8926971554756165, Accuracy: 0.7021484375\n",
      "Batch: 112, Loss: 0.8339399099349976, Accuracy: 0.7294921875\n",
      "Batch: 113, Loss: 0.8217746615409851, Accuracy: 0.7412109375\n",
      "Batch: 114, Loss: 0.9089723229408264, Accuracy: 0.69921875\n",
      "Batch: 115, Loss: 0.9479361772537231, Accuracy: 0.697265625\n",
      "Batch: 116, Loss: 0.9015846252441406, Accuracy: 0.6875\n",
      "Batch: 117, Loss: 0.8812394142150879, Accuracy: 0.7158203125\n",
      "Batch: 118, Loss: 0.7587171792984009, Accuracy: 0.7529296875\n",
      "Batch: 119, Loss: 0.7439296245574951, Accuracy: 0.755859375\n",
      "Batch: 120, Loss: 0.8818177580833435, Accuracy: 0.7001953125\n",
      "Batch: 121, Loss: 0.8959879279136658, Accuracy: 0.7197265625\n",
      "Batch: 122, Loss: 0.825305700302124, Accuracy: 0.73828125\n",
      "Batch: 123, Loss: 0.7994856238365173, Accuracy: 0.7490234375\n",
      "Batch: 124, Loss: 0.8915362358093262, Accuracy: 0.7109375\n",
      "Batch: 125, Loss: 0.8973469138145447, Accuracy: 0.69921875\n",
      "Batch: 126, Loss: 0.8960838317871094, Accuracy: 0.71484375\n",
      "Batch: 127, Loss: 0.7420461177825928, Accuracy: 0.76171875\n",
      "Batch: 128, Loss: 0.9430837035179138, Accuracy: 0.7138671875\n",
      "Batch: 129, Loss: 0.789505124092102, Accuracy: 0.736328125\n",
      "Batch: 130, Loss: 1.0067217350006104, Accuracy: 0.658203125\n",
      "Batch: 131, Loss: 0.8933159708976746, Accuracy: 0.7197265625\n",
      "Batch: 132, Loss: 0.9136380553245544, Accuracy: 0.7080078125\n",
      "Batch: 133, Loss: 0.8164747953414917, Accuracy: 0.7294921875\n",
      "Batch: 134, Loss: 0.8919800519943237, Accuracy: 0.7119140625\n",
      "Batch: 135, Loss: 0.754654586315155, Accuracy: 0.7646484375\n",
      "Batch: 136, Loss: 0.869468092918396, Accuracy: 0.7060546875\n",
      "Batch: 137, Loss: 0.835340678691864, Accuracy: 0.72265625\n",
      "Batch: 138, Loss: 0.7366600036621094, Accuracy: 0.7578125\n",
      "Batch: 139, Loss: 0.8063234090805054, Accuracy: 0.736328125\n",
      "Batch: 140, Loss: 0.8580839037895203, Accuracy: 0.7275390625\n",
      "Batch: 141, Loss: 0.9095534086227417, Accuracy: 0.712890625\n",
      "Batch: 142, Loss: 0.8935400247573853, Accuracy: 0.708984375\n",
      "Batch: 143, Loss: 0.8551872968673706, Accuracy: 0.716796875\n",
      "Batch: 144, Loss: 0.8557308912277222, Accuracy: 0.740234375\n",
      "Batch: 145, Loss: 0.8002555966377258, Accuracy: 0.720703125\n",
      "Batch: 146, Loss: 0.8631141185760498, Accuracy: 0.7080078125\n",
      "Batch: 147, Loss: 0.8479599952697754, Accuracy: 0.7255859375\n",
      "Batch: 148, Loss: 0.9227781295776367, Accuracy: 0.697265625\n"
     ]
    }
   ],
   "source": [
    "file = open(os.path.join(data_directory, data_file), mode = 'r')\n",
    "data = file.read()\n",
    "file.close()\n",
    "if __name__ == \"__main__\":\n",
    "    training_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv(os.path.join(data_directory, \"log.csv\"))\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
